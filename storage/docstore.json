{"docstore/metadata": {"4c867a15-7333-4433-8660-75a9971a48d0": {"doc_hash": "66e3fb2246810e71081417d5c1be5bc77103201e79c0eebfad470b0f312f9b10"}, "9eecf876-8edd-4976-942d-f267b8e272cd": {"doc_hash": "63bc7d6a752b12c8c1e4628b012d897dc8118f6aeadb32e16cf1d3829606d041"}, "39c7e2a6-7dad-4643-ad5b-631d01345809": {"doc_hash": "b003cf6ca69eaaf907e4008ff6da8d637bebb8af12c0fc85788a261422fbf3c9"}, "ffec7c77-c935-4014-8123-9f14cae9e412": {"doc_hash": "7c800bbb8839d60ead68330aabb50f1bf2fc0e262635a43eaeeff90aae3814d2"}, "9b31f9b1-8d0d-482e-948b-2873365655ee": {"doc_hash": "553472b7e37f352fb872c015c99e4d42aab3a3fee0f6fad880943cc92f78378a"}, "ce1e3f57-da81-43f6-b33b-19366426affd": {"doc_hash": "a87bc9e5ad500e01e4a5d6889c29504a70aaf2de0442dfa12d3a6655586d4ee6"}, "52b69969-d9a4-4493-9a79-a0fd69886a11": {"doc_hash": "a7f8253c248b93a666e038278f6319f9a2a5d1d7fcd65a8d6154f85eefbd73e1"}, "ec4f7de8-a525-4137-8097-a46db8ccf40b": {"doc_hash": "e6cb0c3715ab899f3cc2e86c1019a5ae4340ace801d5ed46e5cb0095fb734408"}, "1b86be2e-ba5a-4cf7-b8d7-656f737199a9": {"doc_hash": "958e2813b9271d03b10d8b527a2517227181c3fdf3b709e14f82e1573bc8ab14"}, "02df2dd5-8010-47da-9e0a-8832d599e6c6": {"doc_hash": "3e4ee7bfae158c01d1a25bdefd303066c146f4f807ba1df42c887db3faabf0ce"}, "9244f2d2-7882-46d5-95a1-c87ddfdf246a": {"doc_hash": "d587f6f6319dcd13c5ab666cca36d4e0200a469d4455731717bf4c58d34953f2"}, "f5e77c29-a785-486d-9081-1a8cf68d1b0a": {"doc_hash": "88bb258c5b23699920e91d8f0c6670388e4c310ffbb6020cb2a35e8aa91df1d3"}, "2d62d1b5-f409-4e2e-86a6-3faed4e22fdb": {"doc_hash": "9e1210cb5f3bc09781aecb839c4c81ec7ab6ad643545c67c1bb8582ed8ed6780"}, "b802cc3f-ede2-4b5b-9bc7-51720a3b84b1": {"doc_hash": "b6ae0bcec522b97a26e388d4cbad7b516a69835a2b319229a5702054da2cdf27"}, "e1eead87-5cc0-4e45-8604-ff161f28436b": {"doc_hash": "72f9ff6da3cde3e1eb4d4a91497e186e570635b03785723afe0afbbe798fce30"}, "1be368dc-8171-48d0-9f32-5df4b4621216": {"doc_hash": "2a9bd0cf28cb085b7598c8d3b151b20de7830fcbb9443f6fbb64d42712b3cdd8"}, "9fafd1cc-5dec-484e-80de-d76f4f032286": {"doc_hash": "855608d882c70d799ade64e301c33ea89540d3b6ffc870ff48d9072d1fcf2db0"}, "ed35cb3c-7cc2-4ebe-b442-cc76a3597c09": {"doc_hash": "f60939c21d82eb5f9626db8c76c03ae577cb160a370e26d6ce2b810d4caae7bd"}, "96e89d07-6776-4a2b-8f25-1495a5d3d9bd": {"doc_hash": "af8c0b9c1f8dbb19b1790db01aa80133671d153bbeda5a55e68ad7c73b886dda"}, "37742a01-b463-4f05-a75f-69ffff56c3c8": {"doc_hash": "cdf14a262d87a9607fc4c17fad43634a8e5928c58e4ee864724b51e6dee53db2"}, "13c5b288-b69c-4a12-98d0-2184704a8ffa": {"doc_hash": "c893e0a828d51d539489b307a61e5aef77015e636e010ce4b5d9b23a74ffb955"}, "771fd1a7-aba3-4cd8-a469-479d8e06d5b0": {"doc_hash": "783c81ed06b496f597c7e44e198a7aeb780bc1dc0d38e53f734752f4031cfd50"}, "874bcad2-0af1-4d4d-bb73-de0a9f650877": {"doc_hash": "861d4d17eb09391d4aa5f0afff04a40348f6e0c0c6245cef165816ff2e74bc51"}, "8bc292b3-b332-4641-a20a-4165264e75cd": {"doc_hash": "993d9c2aa9bb68cc39081426dc87dba98db27171b71d60840009c6181d03a5c5"}, "9e776274-16bd-4c03-be9e-06951fdd6840": {"doc_hash": "f28997ab8ddd35174b3fdc9375d7bdb35fc7ad49682a453486810f0c80eaf341"}, "bf4015a4-688e-45d5-b06f-848040748b50": {"doc_hash": "f301b68cbbaffb556e8ad4a414d5c817609fb42d53ab5d8f1e0d743d348520b8"}, "d61065d3-5978-4ea2-a71a-800593e6d194": {"doc_hash": "c1dcfd5505402d3f1e03d53bda9952ab36426ba38c6b3e53cc2b821aabd47a3d"}, "25fd9180-9e92-4751-bf45-67fa2a55fa5b": {"doc_hash": "d03e21cf09b539f8943b859f1d0f4599901b4962fbd8e33c27a3acc9d2b2eb10"}, "5b031e53-fc0a-42b0-90a8-7b6af3c7f6fc": {"doc_hash": "2eb115ce1dd86e3db0ea1d7673359de8210f0a42e915761d9e481e3f46cbda96"}, "6f3b60b2-cf8b-4e9e-bea3-8b79cbbedc44": {"doc_hash": "799bd0e52ef613a9f555cdb42c101f5afc6e7029a1c2822bf61037ee07f0eb90"}, "e51e61dc-4775-4092-89ba-ba106e9ea195": {"doc_hash": "ed52f82228fcf6e4f52bddc17f0f7889b15b013a82ff1b3877ccaafe8f2c6768"}, "46abce09-9df9-40e1-8e60-79d47fb41249": {"doc_hash": "6e47bf88cb3245b46ab702547a1fcda9e57bc831639be3b39d83fe83c2c2105d"}, "e8b9a63a-5f7e-459f-b1e8-f2edf9bf5b13": {"doc_hash": "58cee734f0a7a12a15efbada88de8ed138798292d3d33794af81ee5e552d21c5"}, "6809b276-7611-49e6-bc9e-fdc5e7be0947": {"doc_hash": "987c5544c41282e64c5986021f968648043d9f2c2ff761a6c31c1f1eb40ef905"}, "51559604-c485-4ab4-b411-fdd6b07403f0": {"doc_hash": "d3439b9b9f5469059e1743b5866fbd1c1f9da99b1acdb93b0b162df726fdf8bc"}, "81b1ed45-53ec-4d4f-964e-c8b3710c74f4": {"doc_hash": "efa3140bf1b13c7b48aec1ddb4d48b5419d48e09dd8185172d5deec95847563d"}, "87559ecc-656a-4dc5-92c0-148f8822b7a6": {"doc_hash": "7fce9723b4b566e3056c25595642bdaf5b8f64933ee18b5b4c2774fddb50be8e"}, "06586e8a-8a6a-4e03-ae7c-2d8df7de7c1e": {"doc_hash": "878d4533539c619c78f01aa544383fbc6e663f8891a612aa20885b3836d364e5"}, "7fc5ec28-604b-4ff6-afcd-f7b8669324cf": {"doc_hash": "346130275e6e6a094576a4225623adfb479cb2db7d610cffa15d3cd66e634738"}, "4eafe54c-fd90-4aa0-9076-ef9c2a0b8e7c": {"doc_hash": "cf40b62adb3b555306979d4a28478e0f5f107e50e4696b2955cf60a2b7745bc2"}, "21697785-e327-41c2-b03a-a63076741202": {"doc_hash": "c263403a73555e1c95bd3fa2a1edb65e34071d244c03a8af9fcf8a641aa1c900"}, "1603ca4d-306c-4cc8-a474-c53a6acaca15": {"doc_hash": "62f1b02d960ae3b18280f83440630860d0bfacfbc079246225ca15d4d3704f3b"}, "ea0c0693-a8e8-41fe-b791-f41b93751783": {"doc_hash": "082032475ec74f16744b3a8b829b5bbc20ef76850ab5fb33c0cc5c6154a05645"}, "76cd22bb-5e22-4f4b-a2b8-6a3aedfc1251": {"doc_hash": "977aa1a535f0c54a3e5faaf4f3519400a1c31b4dd56dafbd95ad3ef7aa22b432"}, "a82967b8-0af1-420b-b31a-69e5926056af": {"doc_hash": "f3d92f3e0d1896d4bf78383e38cca0e9ed1f65221684674f5c0a73b6effb08e3"}, "d65469f0-18ad-4463-b3cd-efc7458b2ae2": {"doc_hash": "260c3b24ba2d6f0e9cd4e4cafdd8547eb58133efa72e48eda4d0349b5c5c95cb"}, "f99ee3d8-306f-46f5-8127-9c130e41f98b": {"doc_hash": "6b966144dd8a602b059a58fe790c965e887b57cd96618e8d5e545f8daa28fbd1"}, "d2ce21d7-2cd9-4304-8a1f-56c51e5ae0ec": {"doc_hash": "6870675d016b187470f9153c8e717e3897f11c35aec4b73b5b301d3bbecca98b"}, "79dccfb0-80b7-442d-b0a0-f6389d3e3b26": {"doc_hash": "0860023c67f922b5cb75949c1c77d1dfee9a278a8b88e45698f2528b7a27c65f"}, "3b40464a-3690-4528-96d9-71883a115406": {"doc_hash": "4899390925f6c0c544f0b94cf5013fc4b66b37d333c4370a5e29a86ee299a974"}, "1d454cf8-bb93-49fb-bddb-9418a839d7a2": {"doc_hash": "424cdef82163da654fbb2187224f3df67feebb7970074d412e8f47b7196b5143"}, "39be01c2-7f61-4b70-b6d6-3e5c3e2b177a": {"doc_hash": "085c5e6f490e6080f12e8da3f67fd3a14439b1fd552d45b6a4c0395f96ad1922"}, "9ff247bb-d7c2-4131-87b6-136a0185fc9a": {"doc_hash": "aa47377971eaba438fada69fc5e7adb86f577971d5cdb117e6ae06340d36033d"}, "e34b4270-d575-49f6-be14-28025f4ca4cf": {"doc_hash": "5fe9a068ef78355a13182b65877dcbeccae0ff5ef2297af7615274cf5261027d"}, "fbb92196-11e5-4708-9624-f8fffae173c7": {"doc_hash": "a59af4a29ee6465c355ceb9f8fa3d197cda50b885f74e2deb578646763353c20"}, "f9d7a343-51ea-433b-bc71-f74e8acca8a1": {"doc_hash": "0f170954cd6e72e24b0467177f684394ff4793c144e4ed867dba5eaf674a43a4"}, "5711c4a1-b557-47c1-bc7c-0813fbc488f2": {"doc_hash": "da6bc42ccd3dd49f8d57b3a2671949077a67231c026922026e9b75ff13596e75"}, "ccb4ab73-f4cf-4728-8c7e-8d31ee1688b0": {"doc_hash": "bab5191e2ccc7dbb622e3838c6f884f87100bc8f6bb051b21eed67d1d6b4850a", "ref_doc_id": "4c867a15-7333-4433-8660-75a9971a48d0"}, "8f37f7ab-bc1f-4112-8ea3-4a3cb9ebcc08": {"doc_hash": "bc489d6d254eee527cd51c10deaac6ce18c9625dd2d6af38ed4183090d58bc9d", "ref_doc_id": "4c867a15-7333-4433-8660-75a9971a48d0"}, "e79a93c4-cba1-43a2-b714-8a7881352d11": {"doc_hash": "4e0b74f38f480c5031afe550d7cfb0a23a23f97f08a7c9edec94d6ab6020bea2", "ref_doc_id": "9eecf876-8edd-4976-942d-f267b8e272cd"}, "58d4fa7c-d448-49da-a6b8-a5372bc336c6": {"doc_hash": "e05f86a6228f65148ee91226279ab1db5813a4c1443c9166c9f671f5933b7b1c", "ref_doc_id": "9eecf876-8edd-4976-942d-f267b8e272cd"}, "a4f9ec63-d393-45d7-8f25-26856a884f9a": {"doc_hash": "720a8afa1db3e44bf2be6f7c3a2f95369d5fdd77534703cc59324e8627a035f5", "ref_doc_id": "9eecf876-8edd-4976-942d-f267b8e272cd"}, "53791395-7c37-4fb1-81f4-35d52e297ca3": {"doc_hash": "644c1a744d87a59fb1691a0bc5dcf4e5d1e0eb8e413f547cec137f357f25321b", "ref_doc_id": "9eecf876-8edd-4976-942d-f267b8e272cd"}, "85923b04-5b0f-4d9d-aa26-04168ac9b8f3": {"doc_hash": "1622f7987645b2a63d96e6c29729d316c95d6f6fac78cc778f28163c16484584", "ref_doc_id": "39c7e2a6-7dad-4643-ad5b-631d01345809"}, "16cde075-4c30-4361-b0c0-1c2405bd7236": {"doc_hash": "05a38f8ed482b80add886e0e5a43f06ae676daf24d31042ce91e394001d40b1f", "ref_doc_id": "39c7e2a6-7dad-4643-ad5b-631d01345809"}, "422b49d4-44c0-432c-8868-0a3ae51bf76c": {"doc_hash": "4918ef107e95bcad94db7ec037515d3984a2eb420a8da641e6d8a20deac93794", "ref_doc_id": "ffec7c77-c935-4014-8123-9f14cae9e412"}, "9eb9889a-cd93-45e4-b8c0-5d370e6161eb": {"doc_hash": "9f9c677640a8f6d1f0ef697912b10093af661290abc11e28c06a2fec9fd347b9", "ref_doc_id": "ffec7c77-c935-4014-8123-9f14cae9e412"}, "0c696ece-b278-4082-9bac-7a2cba011e16": {"doc_hash": "665418a7f72001af20f86018bbb280eada38fa5c8391e0d20f03e8e0aea6087c", "ref_doc_id": "9b31f9b1-8d0d-482e-948b-2873365655ee"}, "330f38e4-4d83-4f60-b74e-3e4e9a345ae8": {"doc_hash": "73920310140b4c736f3bdeefe7721bec4ec7bdf9d40ad25f5916e28edf444152", "ref_doc_id": "9b31f9b1-8d0d-482e-948b-2873365655ee"}, "8fb17a11-6d73-4ab3-ad3a-28b9f1f948b7": {"doc_hash": "0535c1f431f481424254e834d9d40cebc98cb8d1009616ae565c6acd00a4e9c5", "ref_doc_id": "ce1e3f57-da81-43f6-b33b-19366426affd"}, "33d0cea3-8e84-48f1-b071-80f2fe06638b": {"doc_hash": "6e4428f0994dc858dddb45716e8927e4cdedc1d044538ce900c3a91f3ee002ec", "ref_doc_id": "ce1e3f57-da81-43f6-b33b-19366426affd"}, "24170805-97f6-460a-9dae-d806d9a8867f": {"doc_hash": "607035725104ffb96eaf0cac64375398e0d7cc3c38399cef1b422c87d4cbb377", "ref_doc_id": "52b69969-d9a4-4493-9a79-a0fd69886a11"}, "bfa94f5c-b2d3-4d2a-83da-1a501ebc6c14": {"doc_hash": "d9a437606891c7f6b4c4cb5396f4e6846f81c1e89ceed254ae52189bb7064680", "ref_doc_id": "52b69969-d9a4-4493-9a79-a0fd69886a11"}, "4c0b1d9e-a335-4225-b57b-70396c168bbc": {"doc_hash": "528e2c1846603c092af336ec0dbaec1e8a1c11a86653affe40f7aa8e4859aaa7", "ref_doc_id": "ec4f7de8-a525-4137-8097-a46db8ccf40b"}, "a4a161ae-a5a3-4db9-997a-8d5a242f4c7b": {"doc_hash": "ced4c5115a7856a590f56ce1841e765e81aec2b0829ef8a8eb6b43bbbf949aa4", "ref_doc_id": "ec4f7de8-a525-4137-8097-a46db8ccf40b"}, "1bde052c-9e9c-433d-a451-eabb12cb61a3": {"doc_hash": "89342b15f8ee472a6a007b795a91ce5bba221e5abc633fae8df3d9bfaa8e72d8", "ref_doc_id": "1b86be2e-ba5a-4cf7-b8d7-656f737199a9"}, "9b9e6492-51c4-4f50-ae34-beb5a03e22cf": {"doc_hash": "4c8846ac33f746b21985563a0b4ac0ccefad688791bb33f1bfa48690ac4664cf", "ref_doc_id": "1b86be2e-ba5a-4cf7-b8d7-656f737199a9"}, "5e5695ef-427a-4bbd-aa3f-5433f52f1d35": {"doc_hash": "634998572f42c80772ae881b2ed1ecb8f323516849f1efa44a39bda7b422cf23", "ref_doc_id": "02df2dd5-8010-47da-9e0a-8832d599e6c6"}, "df255d4d-3e3f-4ee7-8b8b-2dc3bf375e8e": {"doc_hash": "0dcc713f223676aa9e2f66b228cefdbe79b5d4beb748883501ec4883bab2dc1a", "ref_doc_id": "02df2dd5-8010-47da-9e0a-8832d599e6c6"}, "82171b36-dd0f-47fe-ade1-a51a512af9dd": {"doc_hash": "5779dbd66edc7c9d9b99766a8bf5381edb7fedaceb0d95a55aaf8697d23ca42a", "ref_doc_id": "9244f2d2-7882-46d5-95a1-c87ddfdf246a"}, "9b4dad63-8b6f-4aa6-a130-53d444270946": {"doc_hash": "931bf32822d58d3ca0b4fe34372fc80c8a9564fcf64c46929c57d0b77f59f91b", "ref_doc_id": "9244f2d2-7882-46d5-95a1-c87ddfdf246a"}, "75ed95ba-39fd-4939-9797-0f6910e64349": {"doc_hash": "fe3a63185f8cb43d1d49aa1e62e832e65d19d5fc8181c3600e2dcee239544c23", "ref_doc_id": "f5e77c29-a785-486d-9081-1a8cf68d1b0a"}, "63173a7c-e3e0-4293-a638-cfa868fcc985": {"doc_hash": "41adbf5fba435fcb9b4404e3850eb9aede0ccd1d72ef1107fdeac8e0f7affa16", "ref_doc_id": "f5e77c29-a785-486d-9081-1a8cf68d1b0a"}, "99eaaee5-5cca-4b6c-b84d-cbc6bffa4424": {"doc_hash": "9e1210cb5f3bc09781aecb839c4c81ec7ab6ad643545c67c1bb8582ed8ed6780", "ref_doc_id": "2d62d1b5-f409-4e2e-86a6-3faed4e22fdb"}, "89a6e40b-542c-41f4-a4d1-192b4ed73239": {"doc_hash": "1d32377d8679742fa5ef84391f91aa52ca75690bf93bd70da60e0b0e9e55d296", "ref_doc_id": "b802cc3f-ede2-4b5b-9bc7-51720a3b84b1"}, "7b106e53-4279-4fc1-b0f6-28189d4c0b7b": {"doc_hash": "c103a0d9619c5e57cf58d37108c6810b46849289af10896ef34623d8759f1a9c", "ref_doc_id": "b802cc3f-ede2-4b5b-9bc7-51720a3b84b1"}, "1e7b4340-7f30-43db-88f1-5b638b793622": {"doc_hash": "8c06a406cbc6940affa4dad7d7ed152f2237ccd438f0c8f499a037e83d6ccb70", "ref_doc_id": "b802cc3f-ede2-4b5b-9bc7-51720a3b84b1"}, "eabc83f4-e161-4fc5-9588-9a73cfce6a7b": {"doc_hash": "95e599565e25a36bdb35a09007afeb3450e29bfc91af6e9c0316abce18012411", "ref_doc_id": "b802cc3f-ede2-4b5b-9bc7-51720a3b84b1"}, "a6940ea4-f77e-43d4-88ba-d6f88b2f8e90": {"doc_hash": "a5f48445c159dd33d1614674d690f67b47f1f3183d4168644e47e2681a50760f", "ref_doc_id": "e1eead87-5cc0-4e45-8604-ff161f28436b"}, "46033e39-3299-49c0-92c3-155dd1f40bc4": {"doc_hash": "5a172f0668947301fec52eb0c4f78cb90ae43301b8f207d9374a0610ea368bbd", "ref_doc_id": "e1eead87-5cc0-4e45-8604-ff161f28436b"}, "94db492c-82c1-475f-b794-d39935776411": {"doc_hash": "dbed0dca93d5964de914c0de7cc0f584ad11f15eb5a6b305a874ef1a4629498d", "ref_doc_id": "e1eead87-5cc0-4e45-8604-ff161f28436b"}, "e32a3b9e-4ff8-408d-a65b-0294eae9a8a2": {"doc_hash": "6eea9e965f48a6f11d23043a8da298b6483363e8a99e3c8a67358843539b50ac", "ref_doc_id": "e1eead87-5cc0-4e45-8604-ff161f28436b"}, "5556c5fe-7bf4-451d-afb1-08ab0a2e5bf0": {"doc_hash": "2a9bd0cf28cb085b7598c8d3b151b20de7830fcbb9443f6fbb64d42712b3cdd8", "ref_doc_id": "1be368dc-8171-48d0-9f32-5df4b4621216"}, "7ffc471a-ff29-4dc5-bc87-5414f017c679": {"doc_hash": "d87de81ae30e3916985cd60b7fdebfac3c2e0563751ee031c3079770ac7dfb02", "ref_doc_id": "9fafd1cc-5dec-484e-80de-d76f4f032286"}, "bb254241-ad3c-4e10-9538-f1079529729c": {"doc_hash": "f42c7ae2606dda677ffaa50d67598411560c0571b406bad4d62674f516cd7114", "ref_doc_id": "9fafd1cc-5dec-484e-80de-d76f4f032286"}, "84ce8a0b-a1d9-48af-b48b-9ffde148b56d": {"doc_hash": "c96f490ff0490b1c295a0627bc6894f679ad084e4ddf97c5d22bf329d4110e6e", "ref_doc_id": "ed35cb3c-7cc2-4ebe-b442-cc76a3597c09"}, "230db994-13d4-4703-8389-15e8977abd76": {"doc_hash": "3e3d6dc00762ad3073651a60c6616e8a3eeadb0d83330667c46c540024648f76", "ref_doc_id": "ed35cb3c-7cc2-4ebe-b442-cc76a3597c09"}, "1a7875d2-4f14-4337-b1d8-5b9f22c234a4": {"doc_hash": "af8c0b9c1f8dbb19b1790db01aa80133671d153bbeda5a55e68ad7c73b886dda", "ref_doc_id": "96e89d07-6776-4a2b-8f25-1495a5d3d9bd"}, "d5eaa846-da0c-4ca1-b0bc-a43ec8be473b": {"doc_hash": "cdf14a262d87a9607fc4c17fad43634a8e5928c58e4ee864724b51e6dee53db2", "ref_doc_id": "37742a01-b463-4f05-a75f-69ffff56c3c8"}, "97f94ff1-4d90-401e-950f-abd9f8964468": {"doc_hash": "c893e0a828d51d539489b307a61e5aef77015e636e010ce4b5d9b23a74ffb955", "ref_doc_id": "13c5b288-b69c-4a12-98d0-2184704a8ffa"}, "cd9da190-03cb-4f21-8692-b74130ddb1d8": {"doc_hash": "8934caf9a1ed4125528cfd497f9e0574b2ea8193d79a00352c36346a4a743329", "ref_doc_id": "771fd1a7-aba3-4cd8-a469-479d8e06d5b0"}, "baa7cd62-fa8d-44d4-becf-5e21b28227c8": {"doc_hash": "658649d9c82358d42a7f0270b079416e4d7c05e9354e5db6380fc5ead0388947", "ref_doc_id": "771fd1a7-aba3-4cd8-a469-479d8e06d5b0"}, "790d2455-bfcb-4ef0-8fe5-749e944aca72": {"doc_hash": "861d4d17eb09391d4aa5f0afff04a40348f6e0c0c6245cef165816ff2e74bc51", "ref_doc_id": "874bcad2-0af1-4d4d-bb73-de0a9f650877"}, "ee452ccc-e4e6-459f-af91-2f027131de88": {"doc_hash": "993d9c2aa9bb68cc39081426dc87dba98db27171b71d60840009c6181d03a5c5", "ref_doc_id": "8bc292b3-b332-4641-a20a-4165264e75cd"}, "d2cc267d-0857-4b85-8424-7f72dfcc921c": {"doc_hash": "f28997ab8ddd35174b3fdc9375d7bdb35fc7ad49682a453486810f0c80eaf341", "ref_doc_id": "9e776274-16bd-4c03-be9e-06951fdd6840"}, "3255bb20-0b87-467b-931f-867432d1b6ed": {"doc_hash": "f301b68cbbaffb556e8ad4a414d5c817609fb42d53ab5d8f1e0d743d348520b8", "ref_doc_id": "bf4015a4-688e-45d5-b06f-848040748b50"}, "6f9c3c9c-aa65-41a6-8770-948af122fcc7": {"doc_hash": "c1dcfd5505402d3f1e03d53bda9952ab36426ba38c6b3e53cc2b821aabd47a3d", "ref_doc_id": "d61065d3-5978-4ea2-a71a-800593e6d194"}, "6e02578c-a8d6-4106-8c49-680424d2b012": {"doc_hash": "d03e21cf09b539f8943b859f1d0f4599901b4962fbd8e33c27a3acc9d2b2eb10", "ref_doc_id": "25fd9180-9e92-4751-bf45-67fa2a55fa5b"}, "e7e672e9-15c1-45d1-b332-c08ca00bb845": {"doc_hash": "bcf0945e55212d33a9808b586dcf0ccf937bf9b7bd21aba83c2411a9acd3f55e", "ref_doc_id": "5b031e53-fc0a-42b0-90a8-7b6af3c7f6fc"}, "a3e266ae-b709-4f6a-940a-6162370134b7": {"doc_hash": "629dc1b3c22f88a3265df9ad9e6c62c7cb36830506a0ec795ce6c47fa5711e21", "ref_doc_id": "5b031e53-fc0a-42b0-90a8-7b6af3c7f6fc"}, "8f917f38-bf31-48e4-a709-f49fc3aa13df": {"doc_hash": "799bd0e52ef613a9f555cdb42c101f5afc6e7029a1c2822bf61037ee07f0eb90", "ref_doc_id": "6f3b60b2-cf8b-4e9e-bea3-8b79cbbedc44"}, "d71b5356-6861-4804-b8d5-d988f6458a72": {"doc_hash": "662eaafa7e07501f8541190bc1f985d8b2308f1eef82d9757a0c0c75d46f62cf", "ref_doc_id": "e51e61dc-4775-4092-89ba-ba106e9ea195"}, "01b85b0e-2535-4b86-a458-c9972eaa514b": {"doc_hash": "6fd23d18cab2591617703b5e14ba90783af140f1bee7ec6fabff92e1d5d91f23", "ref_doc_id": "e51e61dc-4775-4092-89ba-ba106e9ea195"}, "4b14341c-f212-4b7e-a6bc-dc467e506941": {"doc_hash": "6e47bf88cb3245b46ab702547a1fcda9e57bc831639be3b39d83fe83c2c2105d", "ref_doc_id": "46abce09-9df9-40e1-8e60-79d47fb41249"}, "e88d3de8-7a69-4d76-b8ff-c7c80ac87df3": {"doc_hash": "58cee734f0a7a12a15efbada88de8ed138798292d3d33794af81ee5e552d21c5", "ref_doc_id": "e8b9a63a-5f7e-459f-b1e8-f2edf9bf5b13"}, "66ddb73e-075c-4912-845f-bdd630210707": {"doc_hash": "4a0ce2958aa702d970de9e755b8614e4f489dfc18a6f1475f550b2581ebe0c6e", "ref_doc_id": "6809b276-7611-49e6-bc9e-fdc5e7be0947"}, "ffdd2dd1-6d94-40ff-95b1-ac2e021c119a": {"doc_hash": "34a696eeef08ee6ffe87dfd6c75d17c6fe7ed3bb94b5b358e0968462cb8ccb5f", "ref_doc_id": "6809b276-7611-49e6-bc9e-fdc5e7be0947"}, "05477283-841c-443c-8f86-ebfa3b5c7b98": {"doc_hash": "4a65c273e93a5c88c4ba2a12edb57c70a05db8b236f6c10d0056535991864ef9", "ref_doc_id": "51559604-c485-4ab4-b411-fdd6b07403f0"}, "b48194d5-d11d-4f9a-bf0f-599bbd487609": {"doc_hash": "624fb3570204eeda9964c6c276a8dfc158a3df2a47c51cd3e65dbbdc2eebf5a2", "ref_doc_id": "51559604-c485-4ab4-b411-fdd6b07403f0"}, "f94e9797-7fd0-4702-9962-35075371ee67": {"doc_hash": "e2d2affe1c98e932aea1da0680cc82f8813ca4da498e087f51019846cdd8b468", "ref_doc_id": "81b1ed45-53ec-4d4f-964e-c8b3710c74f4"}, "7a391145-e9c3-4c3c-8444-4040a3386554": {"doc_hash": "69b562afdea52998740b99bbaeb9c71d99cd7ff64651b96bf66079be72033741", "ref_doc_id": "81b1ed45-53ec-4d4f-964e-c8b3710c74f4"}, "e1caf5fa-9447-440c-b5ce-0b98853dc981": {"doc_hash": "95aeaa6ad98d2d899f746c4036a262fd20cd6a2a9c828cb331bee77469efc764", "ref_doc_id": "87559ecc-656a-4dc5-92c0-148f8822b7a6"}, "eb87dc4d-65df-44ee-85ba-ddf448529c95": {"doc_hash": "f3242af34cf741b00c17edffe3a66dda102195eed5633945a8157e56bb84435b", "ref_doc_id": "87559ecc-656a-4dc5-92c0-148f8822b7a6"}, "9e018c06-d969-4f39-b6bd-798d297e6f40": {"doc_hash": "ce577d915d55becbb03b95057fd21d8c1e117ab39863c1bbba3ca43fdbc1972b", "ref_doc_id": "06586e8a-8a6a-4e03-ae7c-2d8df7de7c1e"}, "6ddcb469-5551-4223-8cdd-b61e862b8319": {"doc_hash": "e3bb5db6d0a34712676afd4916f21b828bf225e9973f822be7e44b078e28d7fd", "ref_doc_id": "06586e8a-8a6a-4e03-ae7c-2d8df7de7c1e"}, "1746a0f2-5303-4a83-be16-181a530a3aaa": {"doc_hash": "1c2dd49795eca639166f6d668b906fea01d59cbbb210674fcaaa4418ee8da12b", "ref_doc_id": "7fc5ec28-604b-4ff6-afcd-f7b8669324cf"}, "1711ac87-e7fc-4dc0-a3af-3ee7036a5773": {"doc_hash": "6c287ab920fc0f36fbd1f9bde6907d480f795c7b028c9fe19b12cdfc2e79f249", "ref_doc_id": "7fc5ec28-604b-4ff6-afcd-f7b8669324cf"}, "6b8ca492-29db-4816-bd92-42b8463a8d9d": {"doc_hash": "5e89231d9eb53a38d66b5b86ff544b33b2c25fa16b9c2233810090e5205ef76e", "ref_doc_id": "4eafe54c-fd90-4aa0-9076-ef9c2a0b8e7c"}, "fbb33a9b-c3cd-4b10-b323-414adbda9687": {"doc_hash": "134b0d96f1e01618ae22363f1b0b52e322b3e39b7813ce7967120ff2e5a590fd", "ref_doc_id": "4eafe54c-fd90-4aa0-9076-ef9c2a0b8e7c"}, "6b82165a-ca1d-40d3-8a74-d9d81e1228c2": {"doc_hash": "41358c92d9e131c71ad6a1d093744e89010a9f1d44536d1f9f917df1791bdfcc", "ref_doc_id": "21697785-e327-41c2-b03a-a63076741202"}, "a8826a7f-f45b-4dd6-99d5-15b3ef486087": {"doc_hash": "d51804883e482b4d488772f5eef2a4b8ebc05110bbe3bbfeb5d2cefae7df3ab0", "ref_doc_id": "21697785-e327-41c2-b03a-a63076741202"}, "f470a065-f1dc-48c8-b92a-6d81bcd8bdc8": {"doc_hash": "96a36ee65440ce891985761f69632484824f51b520bcf2d212475bcc6741eb5b", "ref_doc_id": "1603ca4d-306c-4cc8-a474-c53a6acaca15"}, "7717a054-7765-4f3b-a93d-d9fb974f63fb": {"doc_hash": "221fa363b24a2a31d87c077a4e8246934d63b93f594f36584985e3904f742ae9", "ref_doc_id": "1603ca4d-306c-4cc8-a474-c53a6acaca15"}, "b0d91fca-a784-46df-98b6-7d524c01fc4b": {"doc_hash": "bf48ae9979f39afca0d1bcc31e70edde96b4e6b1c304d368806295e71d0f6bc9", "ref_doc_id": "ea0c0693-a8e8-41fe-b791-f41b93751783"}, "a6b2a505-336d-410c-93a5-ac1a38b9545b": {"doc_hash": "e35f507595dd118c186939cf78cecde8828497a1474a13d0c79d406c39607f91", "ref_doc_id": "ea0c0693-a8e8-41fe-b791-f41b93751783"}, "59fc7953-5d16-49bd-876f-bc12fb632852": {"doc_hash": "2e673707fdd2783f04f07fc804d80a04966624c5f3930f7be0e6d56ef68f1ccf", "ref_doc_id": "76cd22bb-5e22-4f4b-a2b8-6a3aedfc1251"}, "b0195244-309c-4d0b-bb6e-7123ce608d59": {"doc_hash": "b764e7492e39234b4457f2bfee33c1c7f5f1a74763a30db289ef1e136f6aa885", "ref_doc_id": "76cd22bb-5e22-4f4b-a2b8-6a3aedfc1251"}, "9a705649-f52b-4351-8ba8-9c2ba0e30be1": {"doc_hash": "fad5a2cf73bd6922172b237f73837d610098442397e71a92475b34937e01c69f", "ref_doc_id": "a82967b8-0af1-420b-b31a-69e5926056af"}, "a34b6df1-536f-4cac-9ccd-621177d91adf": {"doc_hash": "27b73832ec209737c8f3c8d49e9076f46bab5f1f588d36cfeac174e881f51167", "ref_doc_id": "a82967b8-0af1-420b-b31a-69e5926056af"}, "487e4822-1caa-4da9-bdf7-78e0ca55bc58": {"doc_hash": "cfd364d41beed96b53d65cdcfca9596a4c0555c6683316dd1dbabb35ee2fcec6", "ref_doc_id": "d65469f0-18ad-4463-b3cd-efc7458b2ae2"}, "5a305d34-b402-47cb-ba8c-e22e3be75b4f": {"doc_hash": "626b2d9f3901675e3d446dc438393fb6debbf7df684e3ec4cc3698507d2fe5d2", "ref_doc_id": "d65469f0-18ad-4463-b3cd-efc7458b2ae2"}, "efbf24c8-a732-4a96-a908-67eb778b1e3b": {"doc_hash": "d273a6f1b5816f281f759d537dfd94e621138c31d554258b8d7bb74546ce5898", "ref_doc_id": "f99ee3d8-306f-46f5-8127-9c130e41f98b"}, "c4066044-45e0-485b-a89e-a1c4eea953e5": {"doc_hash": "a14800ac906772bdb09716cff8454653d9a584bf18d832817c4c786b51549e12", "ref_doc_id": "f99ee3d8-306f-46f5-8127-9c130e41f98b"}, "b4261d8f-28da-401b-a2ee-d06496b2b169": {"doc_hash": "6870675d016b187470f9153c8e717e3897f11c35aec4b73b5b301d3bbecca98b", "ref_doc_id": "d2ce21d7-2cd9-4304-8a1f-56c51e5ae0ec"}, "7565716e-580d-4be1-aacb-d68019f1ee23": {"doc_hash": "0860023c67f922b5cb75949c1c77d1dfee9a278a8b88e45698f2528b7a27c65f", "ref_doc_id": "79dccfb0-80b7-442d-b0a0-f6389d3e3b26"}, "d24f858d-bec1-4ba5-bb52-b13f7bf13bcc": {"doc_hash": "dc58ef62a2fc2a3c0dd597da8979db5813876f3f5ed2697321c2e9d7bfece076", "ref_doc_id": "3b40464a-3690-4528-96d9-71883a115406"}, "3fbaf8ce-f2f4-46b6-9743-754e40985125": {"doc_hash": "8df3e30f0ae9a5aca835eb37a5f1dcf77ebde3f384ce20e2b1eebe9b269b1894", "ref_doc_id": "3b40464a-3690-4528-96d9-71883a115406"}, "6547c014-35c6-41e0-beb2-1a4b0a085596": {"doc_hash": "424cdef82163da654fbb2187224f3df67feebb7970074d412e8f47b7196b5143", "ref_doc_id": "1d454cf8-bb93-49fb-bddb-9418a839d7a2"}, "50c866ab-b5d5-41bb-89e2-0b273215addc": {"doc_hash": "085c5e6f490e6080f12e8da3f67fd3a14439b1fd552d45b6a4c0395f96ad1922", "ref_doc_id": "39be01c2-7f61-4b70-b6d6-3e5c3e2b177a"}, "fb8eecb3-edd1-462e-9c2b-d3725e0ddb5a": {"doc_hash": "a4dcfe8ec84d4a298b499eaf20933107ac4c4a510c67daef227eb707b11af252", "ref_doc_id": "9ff247bb-d7c2-4131-87b6-136a0185fc9a"}, "257ed513-2bac-45b2-9539-fd2ec9f43218": {"doc_hash": "61d752178febdb8f3ec23da40bb265f6c5041082c6b9c8a9f8391e1539e946e0", "ref_doc_id": "9ff247bb-d7c2-4131-87b6-136a0185fc9a"}, "df51b3cf-6a98-4392-8ecc-f121bc091627": {"doc_hash": "5fe9a068ef78355a13182b65877dcbeccae0ff5ef2297af7615274cf5261027d", "ref_doc_id": "e34b4270-d575-49f6-be14-28025f4ca4cf"}, "6d2856e2-c2fb-4b34-b3c3-263ec767fe06": {"doc_hash": "7f67ab3fe183282bdcd0d6454b3aec5081b31e4943c16a84107232c7ae1a27e6", "ref_doc_id": "fbb92196-11e5-4708-9624-f8fffae173c7"}, "87598038-a9b1-4891-a603-53c0dff65563": {"doc_hash": "6e2760c27b3993e97e08b4be2d0c71c319526403f39f1e7f5872c0685ffb4a1e", "ref_doc_id": "fbb92196-11e5-4708-9624-f8fffae173c7"}, "5d667156-26f3-438b-9c53-9ebcede322d7": {"doc_hash": "0f170954cd6e72e24b0467177f684394ff4793c144e4ed867dba5eaf674a43a4", "ref_doc_id": "f9d7a343-51ea-433b-bc71-f74e8acca8a1"}, "67e044ac-6f53-449c-997f-738182179214": {"doc_hash": "16ac984bd48765ef80973e5ad2a35186bd94e6eb3a0461874a45bc7c599f8fa4", "ref_doc_id": "5711c4a1-b557-47c1-bc7c-0813fbc488f2"}, "235f97ed-81f1-4fe0-8555-869c816eb649": {"doc_hash": "9834119bd2792710f205a73f28c086ffb8320c8ebd824dcc0c24aa7c78ed3ff9", "ref_doc_id": "5711c4a1-b557-47c1-bc7c-0813fbc488f2"}}, "docstore/data": {"ccb4ab73-f4cf-4728-8c7e-8d31ee1688b0": {"__data__": {"id_": "ccb4ab73-f4cf-4728-8c7e-8d31ee1688b0", "embedding": null, "metadata": {"page_label": "1", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4c867a15-7333-4433-8660-75a9971a48d0", "node_type": null, "metadata": {"page_label": "1", "file_name": "2210.03629.pdf"}, "hash": "66e3fb2246810e71081417d5c1be5bc77103201e79c0eebfad470b0f312f9b10"}, "3": {"node_id": "8f37f7ab-bc1f-4112-8ea3-4a3cb9ebcc08", "node_type": null, "metadata": {"page_label": "1", "file_name": "2210.03629.pdf"}, "hash": "bc489d6d254eee527cd51c10deaac6ce18c9625dd2d6af38ed4183090d58bc9d"}}, "hash": "bab5191e2ccc7dbb622e3838c6f884f87100bc8f6bb051b21eed67d1d6b4850a", "text": "Published as a conference paper at ICLR 2023\nREAC T: S YNERGIZING REASONING AND ACTING IN\nLANGUAGE MODELS\nShunyu Yao\u0003*,1, Jeffrey Zhao2, Dian Yu2, Nan Du2, Izhak Shafran2, Karthik Narasimhan1, Yuan Cao2\n1Department of Computer Science, Princeton University\n2Google Research, Brain team\n1{shunyuy,karthikn}@princeton.edu\n2{jeffreyzhao,dianyu,dunan,izhak,yuancao}@google.com\nABSTRACT\nWhile large language models (LLMs) have demonstrated impressive performance\nacross tasks in language understanding and interactive decision making, their\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action\nplan generation) have primarily been studied as separate topics. In this paper, we\nexplore the use of LLMs to generate both reasoning traces and task-speci\ufb01c actions\nin an interleaved manner, allowing for greater synergy between the two: reasoning\ntraces help the model induce, track, and update action plans as well as handle\nexceptions, while actions allow it to interface with and gather additional information\nfrom external sources such as knowledge bases or environments. We apply our\napproach, named ReAct , to a diverse set of language and decision making tasks\nand demonstrate its effectiveness over state-of-the-art baselines in addition to\nimproved human interpretability and trustworthiness. Concretely, on question\nanswering (HotpotQA) and fact veri\ufb01cation (Fever), ReAct overcomes prevalent\nissues of hallucination and error propagation in chain-of-thought reasoning by\ninteracting with a simple Wikipedia API, and generating human-like task-solving\ntrajectories that are more interpretable than baselines without reasoning traces.\nFurthermore, on two interactive decision making benchmarks (ALFWorld and\nWebShop), ReAct outperforms imitation and reinforcement learning methods by\nan absolute success rate of 34% and 10% respectively, while being prompted with\nonly one or two in-context examples.\n1 I NTRODUCTION\nA unique feature of human intelligence is the ability to seamlessly combine task-oriented actions with\nverbal reasoning (or inner speech, Alderson-Day & Fernyhough, 2015), which has been theorized to\nplay an important role in human cognition for enabling self-regulation or strategization (Vygotsky,\n1987; Luria, 1965; Fernyhough, 2010) and maintaining a working memory (Baddeley, 1992). Con-\nsider the example of cooking up a dish in the kitchen. Between any two speci\ufb01c actions, we may\nreason in language in order to track progress (\u201cnow that everything is cut, I should heat up the pot of\nwater\u201d), to handle exceptions or adjust the plan according to the situation (\u201cI don\u2019t have salt, so let\nme use soy sauce and pepper instead\u201d), and to realize when external information is needed (\u201chow do\nI prepare dough? Let me search on the Internet\u201d). We may also act (open a cookbook to read the\nrecipe, open the fridge, check ingredients) to support the reasoning and to answer questions (\u201cWhat\ndish can I make right now?\u201d). This tight synergy between \u201cacting\u201d and \u201creasoning\u201d allows humans\nto learn new tasks quickly and perform robust decision making or reasoning, even under previously\nunseen circumstances or facing information uncertainties.\nRecent results have hinted at the possibility of combining verbal reasoning with interactive decision\nmaking in autonomous systems. On one hand, properly prompted large language models (LLMs)\nhave demonstrated emergent capabilities to carry out several steps of reasoning traces to derive\n\u0003Work during Google internship. Projet page with code: https://react-lm.github.io/", "start_char_idx": 0, "end_char_idx": 3558, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8f37f7ab-bc1f-4112-8ea3-4a3cb9ebcc08": {"__data__": {"id_": "8f37f7ab-bc1f-4112-8ea3-4a3cb9ebcc08", "embedding": null, "metadata": {"page_label": "1", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4c867a15-7333-4433-8660-75a9971a48d0", "node_type": null, "metadata": {"page_label": "1", "file_name": "2210.03629.pdf"}, "hash": "66e3fb2246810e71081417d5c1be5bc77103201e79c0eebfad470b0f312f9b10"}, "2": {"node_id": "ccb4ab73-f4cf-4728-8c7e-8d31ee1688b0", "node_type": null, "metadata": {"page_label": "1", "file_name": "2210.03629.pdf"}, "hash": "bab5191e2ccc7dbb622e3838c6f884f87100bc8f6bb051b21eed67d1d6b4850a"}}, "hash": "bc489d6d254eee527cd51c10deaac6ce18c9625dd2d6af38ed4183090d58bc9d", "text": "internship. Projet page with code: https://react-lm.github.io/ .\n1arXiv:2210.03629v3  [cs.CL]  10 Mar 2023", "start_char_idx": 3496, "end_char_idx": 3602, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e79a93c4-cba1-43a2-b714-8a7881352d11": {"__data__": {"id_": "e79a93c4-cba1-43a2-b714-8a7881352d11", "embedding": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9eecf876-8edd-4976-942d-f267b8e272cd", "node_type": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "hash": "63bc7d6a752b12c8c1e4628b012d897dc8118f6aeadb32e16cf1d3829606d041"}, "3": {"node_id": "58d4fa7c-d448-49da-a6b8-a5372bc336c6", "node_type": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "hash": "e05f86a6228f65148ee91226279ab1db5813a4c1443c9166c9f671f5933b7b1c"}}, "hash": "4e0b74f38f480c5031afe550d7cfb0a23a23f97f08a7c9edec94d6ab6020bea2", "text": "Published as a conference paper at ICLR 2023 $FW\u0003\u0014\u001d\u00037KLQN>)LUVW\u0003,\u0003QHHG\u0003WR\u0003ILQG\u0003D\u0003SHSSHU\u0003VKDNHU\u0011\u0011\u0011PRUH\u0003OLNHO\\\u0003WR\u0003DSSHDU\u0003LQ\u0003FDELQHWV\u0003\u000b\u0014\u0010\u0019\f\u000f\u0003FRXQWHUWRSV\u0003\u000b\u0014\u0010\u0016\f\u000f\u0003\u0011\u0011\u0011\u0003@$FW\u0003\u0015\u001d\u0003*R\u0003WR\u0003FDELQHW\u0003\u0014\u00032EV\u0003\u0015\u001d\u00032Q\u0003WKH\u0003FDELQHW\u0003\u0014\u000f\u0003\\RX\u0003VHH\u0003D\u0003YDVH\u0003\u0015\u0011\u0003\u000b+HUH\u0003WKH\u0003DJHQW\u0003JR\u0003WR\u0003FDELQHW\u0003\u0014\u000f\u0003WKHQ\u0003FDELQHW\u0003\u0015\u000f\u0003\u0016\u000f\u0003WKHQ\u0003FRXQWHUWRS\u0003\u0014\u0003DQG\u0003\u0015\f$FW\u0003\u0019\u001d\u0003*R\u0003WR\u0003FRXQWHUWRS\u0003\u0016\u00032EV\u0003\u0019\u001d\u00032Q\u0003WKH\u0003FRXQWHUWRS\u0003\u0016\u000f\u0003\\RX\u0003VHH\u0003D\u0003DSSOH\u0003\u0014\u000f\u0003D\u0003EUHDG\u0003\u0014\u000f\u0003\u0011\u0011\u0011\u0011\u0011\u0011\u0003D\u0003SHSSHU\u0003VKDNHU\u0003\u0014\u000f\u0003DQG\u0003D\u0003YDVH\u0003\u0016\u0011$FW\u0003\u001a\u001d\u00037DNH\u0003SHSSHU\u0003VKDNHU\u0003\u0014\u0003IURP\u0003FRXQWHUWRS\u0003\u0016\u00032EV\u0003\u001a\u001d\u0003<RX\u0003SLFN\u0003XS\u0003WKH\u0003SHSSHU\u0003VKDNHU\u0003\u0014\u0003IURP\u0003WKH\u0003FRXQWHUWRS\u0003\u0016\u0011\u0003$FW\u0003\u001b\u001d\u00037KLQN>1RZ\u0003,\u0003ILQG\u0003D\u0003SHSSHU\u0003VKDNHU\u0003\u0014\u0011\u00031H[W\u000f\u0003,\u0003QHHG\u0003WR\u0003SXW\u0003LW\u0003LQ\u0012RQ\u0003GUDZHU\u0003\u0014\u0011@$FW\u0003\u001c\u001d\u0003*R\u0003WR\u0003GUDZHU\u0003\u0014\u00032EV\u0003\u001c\u001d\u0003'UDZHU\u0003\u0014\u0003LV\u0003FORVHG\u0011\u0003$FW\u0003\u0014\u0013\u001d\u00032SHQ\u0003GUDZHU\u0003\u0014\u00032EV\u0003\u0014\u0013\u001d\u0003<RX\u0003RSHQ\u0003'UDZHU\u0003\u0014\u0003\u00aa$FW\u0003\u0014\u0014\u001d\u00033XW\u0003SHSSHU\u0003VKDNHU\u0003\u0014\u0003LQ\u0012RQ\u0003GUDZHU\u0003\u0014\u00032EV\u0003\u0014\u0014\u001d\u0003<RX\u0003SXW\u0003SHSSHU\u0003VKDNHU\u0003\u0014\u0003LQ\u0012RQ\u0003WKH\u0003GUDZHU\u0003\u0014\u0011\u000b\u0014D\f\u00036WDQGDUG$QVZHU\u001d\u0003L3RG\u000b\u0014E\f\u0003&R7\u0003\u000b5HDVRQ\u00032QO\\\f7KRXJKW\u001d\u0003/HW", "start_char_idx": 0, "end_char_idx": 868, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "58d4fa7c-d448-49da-a6b8-a5372bc336c6": {"__data__": {"id_": "58d4fa7c-d448-49da-a6b8-a5372bc336c6", "embedding": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9eecf876-8edd-4976-942d-f267b8e272cd", "node_type": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "hash": "63bc7d6a752b12c8c1e4628b012d897dc8118f6aeadb32e16cf1d3829606d041"}, "2": {"node_id": "e79a93c4-cba1-43a2-b714-8a7881352d11", "node_type": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "hash": "4e0b74f38f480c5031afe550d7cfb0a23a23f97f08a7c9edec94d6ab6020bea2"}, "3": {"node_id": "a4f9ec63-d393-45d7-8f25-26856a884f9a", "node_type": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "hash": "720a8afa1db3e44bf2be6f7c3a2f95369d5fdd77534703cc59324e8627a035f5"}}, "hash": "e05f86a6228f65148ee91226279ab1db5813a4c1443c9166c9f671f5933b7b1c", "text": "V\u0003WKLQN\u0003VWHS\u0003E\\\u0003VWHS\u0011\u0003$SSOH\u00035HPRWH\u0003ZDV\u0003RULJLQDOO\\\u0003GHVLJQHG\u0003WR\u0003LQWHUDFW\u0003ZLWK\u0003$SSOH\u000379\u0011\u0003$SSOH\u000379\u0003FDQ\u0003EH\u0003FRQWUROOHG\u0003E\\\u0003L3KRQH\u000f\u0003L3DG\u000f\u0003DQG\u0003L3RG\u00037RXFK\u0011\u00036R\u0003WKH\u0003DQVZHU\u0003LV\u0003L3KRQH\u000f\u0003L3DG\u000f\u0003DQG\u0003L3RG\u00037RXFK\u0011$QVZHU\u001d\u0003L3KRQH\u000f\u0003L3DG\u000f\u0003L3RG\u00037RXFK\u000b\u0014F\f\u0003$FW\u00102QO\\\u0003$FW\u0003\u0014\u001d\u00036HDUFK>$SSOH\u00035HPRWH@\u00032EV\u0003\u0014\u001d\u00037KH\u0003$SSOH\u00035HPRWH\u0003LV\u0003D\u0003UHPRWH\u0003FRQWURO\u0003\u00aa$FW\u0003\u0015\u001d\u00036HDUFK>)URQW\u00035RZ@\u00032EV\u0003\u0015\u001d\u0003&RXOG\u0003QRW\u0003ILQG\u0003>)URQW\u00035RZ@\u0011\u00036LPLODU\u001d\u0003\u00aa$FW\u0003\u0016\u001d\u00036HDUFK>)URQW\u00035RZ\u0003\u000bVRIWZDUH\f@\u00032EV\u0003\u0016\u001d\u0003)URQW\u00035RZ\u0003LV\u0003D\u0003GLVFRQWLQXHG\u0003PHGLD\u0003FHQWHU\u0003VRIWZDUH\u0003\u00aa$FW\u0003\u0017\u001d\u0003)LQLVK>\\HV@\u000b\u0014G\f\u00035H$FW\u0003\u000b5HDVRQ\u0003\u000e\u0003$FW\f7KRXJKW\u0003\u0014\u001d\u0003,\u0003QHHG\u0003WR\u0003VHDUFK\u0003$SSOH\u00035HPRWH\u0003DQG\u0003ILQG\u0003WKH\u0003SURJUDP\u0003LW\u0003ZDV\u0003RULJLQDOO\\\u0003GHVLJQHG\u0003WR\u0003LQWHUDFW\u0003ZLWK\u0011$FW\u0003\u0014\u001d\u00036HDUFK>$SSOH\u00035HPRWH@2EV\u0003\u0014\u001d\u00037KH\u0003$SSOH\u00035HPRWH\u0003LV\u0003D\u0003UHPRWH\u0003FRQWURO\u0003LQWURGXFHG\u0003LQ\u00032FWREHU\u0003\u0015\u0013\u0013\u0018\u0003E\\\u0003$SSOH\u0003\u00aa\u0003RULJLQDOO\\\u0003GHVLJQHG\u0003WR\u0003FRQWURO\u0003WKH\u0003)URQW\u00035RZ\u0003PHGLD\u0003FHQWHU\u0003SURJUDP\u0003\u00aa7KRXJKW\u0003\u0015\u001d\u0003$SSOH\u00035HPRWH\u0003ZDV\u0003RULJLQDOO\\\u0003GHVLJQHG\u0003WR\u0003FRQWURO\u0003WKH\u0003)URQW\u00035RZ\u0003PHGLD\u0003FHQWHU\u0003SURJUDP\u0011\u0003,\u0003QHHG\u0003WR\u0003VHDUFK\u0003)URQW\u00035RZ\u0003QH[W\u0003DQG\u0003ILQG\u0003ZKDW\u0003RWKHU\u0003GHYLFH\u0003FDQ\u0003FRQWURO\u0003LW\u0011$FW\u0003\u0015\u001d\u00036HDUFK>)URQW\u00035RZ@2EV\u0003\u0015\u001d\u0003&RXOG\u0003QRW\u0003ILQG\u0003>)URQW\u00035RZ@\u0011\u00036LPLODU\u001d\u0003> )URQW\u00035RZ\u00036HDW\u0003WR\u0003(DUWK \u000f\u0003 )URQW\u00035RZ\u00030RWRUVSRUWV \u000f )URQW\u00035RZ\u0003\u000bVRIWZDUH\f", "start_char_idx": 869, "end_char_idx": 1979, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a4f9ec63-d393-45d7-8f25-26856a884f9a": {"__data__": {"id_": "a4f9ec63-d393-45d7-8f25-26856a884f9a", "embedding": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9eecf876-8edd-4976-942d-f267b8e272cd", "node_type": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "hash": "63bc7d6a752b12c8c1e4628b012d897dc8118f6aeadb32e16cf1d3829606d041"}, "2": {"node_id": "58d4fa7c-d448-49da-a6b8-a5372bc336c6", "node_type": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "hash": "e05f86a6228f65148ee91226279ab1db5813a4c1443c9166c9f671f5933b7b1c"}, "3": {"node_id": "53791395-7c37-4fb1-81f4-35d52e297ca3", "node_type": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "hash": "644c1a744d87a59fb1691a0bc5dcf4e5d1e0eb8e413f547cec137f357f25321b"}}, "hash": "720a8afa1db3e44bf2be6f7c3a2f95369d5fdd77534703cc59324e8627a035f5", "text": "\u000f )URQW\u00035RZ\u0003\u000bVRIWZDUH\f \u000f\u0003\u00aa@7KRXJKW\u0003\u0016\u001d\u0003)URQW\u00035RZ\u0003LV\u0003QRW\u0003IRXQG\u0011\u0003,\u0003QHHG\u0003WR\u0003VHDUFK\u0003)URQW\u00035RZ\u0003\u000bVRIWZDUH\f\u0003\u0011$FW\u0003\u0016\u001d\u00036HDUFK>)URQW\u00035RZ\u0003\u000bVRIWZDUH\f@2EV\u0003\u0016\u001d\u0003)URQW\u00035RZ\u0003LV\u0003D\u0003GLVFRQWLQXHG\u0003PHGLD\u0003FHQWHU\u0003VRIWZDUH\u0003\u00aa7KRXJKW\u0003\u0017\u001d\u0003)URQW\u00035RZ\u0003\u000bVRIWZDUH\f\u0003LV\u0003FRQWUROOHG\u0003E\\\u0003DQ\u0003$SSOH\u00035HPRWH\u0003RU\u0003WKH\u0003NH\\ERDUG\u0003IXQFWLRQ\u0003NH\\V\u0011\u00036R\u0003WKH\u0003DQVZHU\u0003LV\u0003NH\\ERDUG\u0003IXQFWLRQ\u0003NH\\V\u0011$FW\u0003\u0017\u001d\u0003)LQLVK>NH\\ERDUG\u0003IXQFWLRQ\u0003NH\\V@\u04bc4XHVWLRQ\u001d\u0003$VLGH\u0003IURP\u0003WKH\u0003$SSOH\u00035HPRWH\u000f\u0003ZKDW\u0003RWKHU\u0003GHYLFH\u0003FDQ\u0003FRQWURO\u0003WKH\u0003SURJUDP\u0003$SSOH\u00035HPRWH\u0003ZDV\u0003RULJLQDOO\\\u0003GHVLJQHG\u0003WR\u0003LQWHUDFW\u0003ZLWK\" \u000b\u0015D\f\u0003$FW\u00102QO\\\u0003$FW\u0003\u0014\u001d\u0003*R\u0003WR\u0003GUDZHU\u0003\u0014\u00032EV\u0003\u0014\u001d\u00037KH\u0003GUDZHU\u0003\u0014\u0003LV\u0003FORVHG\u0011\u0003$FW\u0003\u0015\u001d\u00032SHQ\u0003GUDZHU\u0003\u0014\u00032EV\u0003\u0015\u001d\u0003<RX\u0003RSHQ\u0003WKH\u0003GUDZHU\u0003\u0014\u0011\u00037KH\u0003GUDZHU\u0003\u0014\u0003LV\u0003RSHQ\u0011\u0003,Q\u0003LW\u000f\u0003\\RX\u0003VHH\u0003D\u0003GLVKVSRQJH\u0003\u0015\u000f\u0003DQG\u0003D\u0003VSRRQ\u0003\u0014\u0011\u0003$FW\u0003\u0016\u001d\u0003*R\u0003WR\u0003VLQNEDVLQ\u0003\u0014\u00032EV\u0003\u0016\u001d\u00032Q\u0003WKH\u0003VLQNEDVLQ\u0003\u0014\u000f\u0003\\RX\u0003VHH\u0003D\u0003GLVKVSRQJH\u0003\u0016\u000f\u0003D\u0003VSDWXOD\u0003\u0014\u000f\u0003DQG\u0003D\u0003VSRRQ\u0003\u0015\u0011\u0003$FW\u0003\u0017\u001d\u00037DNH\u0003SHSSHUVKDNHU\u0003\u0014\u0003IURP\u0003VLQNEDVLQ\u0003\u0014\u00032EV\u0003\u0017\u001d\u00031RWKLQJ\u0003KDSSHQV\u0011\u0003$FW\u0003\u0018\u001d\u00037DNH\u0003SHSSHUVKDNHU\u0003\u0014\u0003IURP\u0003VLQNEDVLQ\u0003\u0014\u00032EV\u0003\u0018\u001d\u00031RWKLQJ\u0003KDSSHQV\u0011\u0003\u000b\u0015E\f\u00035H$FW\u0003\u000b5HDVRQ\u0003\u000e\u0003$FW\f \u04bc<RX\u0003DUH\u0003LQ\u0003WKH\u0003PLGGOH\u0003RI\u0003D\u0003URRP\u0011\u0003/RRNLQJ\u0003TXLFNO\\\u0003DURXQG\u0003\\RX\u000f\u0003\\RX\u0003VHH\u0003D\u0003FDELQHW\u0003\u0019\u000f\u0003D\u0003FDELQHW\u0003\u0014\u000f\u0003D\u0003FRIIHH\u0003PDFKLQH\u0003\u0014\u000f\u0003D\u0003FRXQWHUWRS\u0003\u0016\u000f\u0003\u0003D\u0003VWRYH\u0003EXUQHU\u0003\u0014\u000f\u0003DQG\u0003D\u0003WRDVWHU\u0003\u0014\u0011\u0003<RXU\u0003WDVN\u0003LV\u0003WR\u001d\u00033XW\u0003VRPH\u0003SHSSHU\u0003VKDNHU\u0003RQ\u0003D\u0003GUDZHU\u0011\u000b\u0015\f\u0003$OI:RUOG\u000b\u0014\f\u0003+RWVSRW\u00034$ Figure 1: (1) Comparison of 4 prompting", "start_char_idx": 1959, "end_char_idx": 3201, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "53791395-7c37-4fb1-81f4-35d52e297ca3": {"__data__": {"id_": "53791395-7c37-4fb1-81f4-35d52e297ca3", "embedding": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9eecf876-8edd-4976-942d-f267b8e272cd", "node_type": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "hash": "63bc7d6a752b12c8c1e4628b012d897dc8118f6aeadb32e16cf1d3829606d041"}, "2": {"node_id": "a4f9ec63-d393-45d7-8f25-26856a884f9a", "node_type": null, "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}, "hash": "720a8afa1db3e44bf2be6f7c3a2f95369d5fdd77534703cc59324e8627a035f5"}}, "hash": "644c1a744d87a59fb1691a0bc5dcf4e5d1e0eb8e413f547cec137f357f25321b", "text": "Figure 1: (1) Comparison of 4 prompting methods, (a) Standard , (b) Chain-of-thought ( CoT,\nReason Only), (c) Act-only, and (d) ReAct (Reason+Act), solving a HotpotQA (Yang et al., 2018)\nquestion. (2) Comparison of (a) Act-only and (b) ReAct prompting to solve an AlfWorld (Shridhar\net al., 2020b) game. In both domains, we omit in-context examples in the prompt, and only show task\nsolving trajectories generated by the model (Act, Thought) and the environment (Obs).\nanswers from questions in arithmetic, commonsense, and symbolic reasoning tasks (Wei et al.,\n2022). However, this \u201cchain-of-thought\u201d reasoning is a static black box, in that the model uses\nits own internal representations to generate thoughts and is not grounded in the external world,\nwhich limits its ability to reason reactively or update its knowledge. This can lead to issues like fact\nhallucination and error propagation over the reasoning process (Figure 1 (1b)). On the other hand,\nrecent work has explored the use of pre-trained language models for planning and acting in interactive\nenvironments (Ahn et al., 2022; Nakano et al., 2021; Yao et al., 2020; Huang et al., 2022a), with\na focus on predicting actions via language priors. These approaches usually convert multi-modal\nobservations into text, use a language model to generate domain-speci\ufb01c actions or plans, and then\nuse a controller to choose or execute them. However, they do not employ language models to reason\nabstractly about high-level goals or maintain a working memory to support acting, barring Huang\net al. (2022b) who perform a limited form of verbal reasoning to reiterate spatial facts about the\ncurrent state. Beyond such simple embodied tasks to interact with a few blocks, there have not been\nstudies on how reasoning and acting can be combined in a synergistic manner for general task solving,\nand if such a combination can bring systematic bene\ufb01ts compared to reasoning or acting alone.\nIn this work, we present ReAct , a general paradigm to combine reasoning and acting with language\nmodels for solving diverse language reasoning and decision making tasks (Figure 1). ReAct\nprompts LLMs to generate both verbal reasoning traces and actions pertaining to a task in an\ninterleaved manner, which allows the model to perform dynamic reasoning to create, maintain, and\nadjust high-level plans for acting (reason to act), while also interact with the external environments\n(e.g. Wikipedia) to incorporate additional information into reasoning (act to reason).\n2", "start_char_idx": 3183, "end_char_idx": 5696, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "85923b04-5b0f-4d9d-aa26-04168ac9b8f3": {"__data__": {"id_": "85923b04-5b0f-4d9d-aa26-04168ac9b8f3", "embedding": null, "metadata": {"page_label": "3", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "39c7e2a6-7dad-4643-ad5b-631d01345809", "node_type": null, "metadata": {"page_label": "3", "file_name": "2210.03629.pdf"}, "hash": "b003cf6ca69eaaf907e4008ff6da8d637bebb8af12c0fc85788a261422fbf3c9"}, "3": {"node_id": "16cde075-4c30-4361-b0c0-1c2405bd7236", "node_type": null, "metadata": {"page_label": "3", "file_name": "2210.03629.pdf"}, "hash": "05a38f8ed482b80add886e0e5a43f06ae676daf24d31042ce91e394001d40b1f"}}, "hash": "1622f7987645b2a63d96e6c29729d316c95d6f6fac78cc778f28163c16484584", "text": "Published as a conference paper at ICLR 2023\nWe conduct empirical evaluations of ReAct and state-of-the-art baselines on four diverse benchmarks:\nquestion answering (HotPotQA, Yang et al., 2018), fact veri\ufb01cation (Fever, Thorne et al., 2018),\ntext-based game (ALFWorld, Shridhar et al., 2020b), and webpage navigation (WebShop, Yao\net al., 2022). For HotPotQA and Fever, with access to a Wikipedia API that the model can interact\nwith, ReAct outperforms vanilla action generation models while being competitive with chain-of-\nthought reasoning ( CoT) (Wei et al., 2022). The best approach overall is a combination of ReAct\nandCoT that allows for the use of both internal knowledge and externally obtained information\nduring reasoning. On ALFWorld and WebShop, two or even one-shot ReAct prompting is able\nto outperform imitation or reinforcement learning methods trained with 103\u0018105task instances,\nwith an absolute improvement of 34% and 10% in success rates respectively. We also demonstrate\nthe importance of sparse, versatile reasoning in decision making by showing consistent advantages\nover controlled baselines with actions only. Besides general applicability and performance boost,\nthe combination of reasoning and acting also contributes to model interpretability, trustworthiness,\nand diagnosability across all domains, as humans can readily distinguish information from model\u2019s\ninternal knowledge versus external environments, as well as inspect reasoning traces to understand\nthe decision basis of model actions.\nTo summarize, our key contributions are the following: (1) we introduce ReAct , a novel prompt-\nbased paradigm to synergize reasoning and acting in language models for general task solving; (2) we\nperform extensive experiments across diverse benchmarks to showcase the advantage of ReAct in a\nfew-shot learning setup over prior approaches that perform either reasoning or action generation in\nisolation; (3) we present systematic ablations and analysis to understand the importance of acting in\nreasoning tasks, and reasoning in interactive tasks; (4) we analyze the limitations of ReAct under the\nprompting setup (i.e. limited support of reasoning and acting behaviors), and perform initial \ufb01netuning\nexperiments showing the potential of ReAct to improve with additional training data. Scaling up\nReAct to train and operate on more tasks and combining it with complementary paradigms like\nreinforcement learning could further unlock the potential of large language models.\n2REAC T: SYNERGIZING REASONING +AC TING\nConsider a general setup of an agent interacting with an environment for task solving. At time\nstept, an agent receives an observation ot2O from the environment and takes an action at2A\nfollowing some policy \u0019(atjct), wherect= (o1;a1;\u0001\u0001\u0001;ot\u00001;at\u00001;ot)is the context to the agent.\nLearning a policy is challenging when the mapping ct7!atis highly implicit and requires extensive\ncomputation. For example, the agent shown in Figure 1(1c) is unable to generate the correct \ufb01nal\naction (Act 4) to \ufb01nish the QA task as it requires complex reasoning over the trajectory context\n(Question, Act 1-3, Obs 1-3). Similarly, the agent shown in Figure 1(2a) fails to comprehend from the\ncontext that sinkbasin 1 does not contain peppershaker 1, thus keep producing hallucinating actions.\nThe idea of ReAct is simple: we augment the agent\u2019s action space to ^A=A[L , whereLis the\nspace of language. An action ^at2L in the language space, which we will refer to as a thought or a\nreasoning trace , does not affect the external environment, thus leading to no observation feedback.\nInstead, a thought ^ataims to compose useful information by reasoning over the current context ct,\nand update the context ct+1=", "start_char_idx": 0, "end_char_idx": 3731, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "16cde075-4c30-4361-b0c0-1c2405bd7236": {"__data__": {"id_": "16cde075-4c30-4361-b0c0-1c2405bd7236", "embedding": null, "metadata": {"page_label": "3", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "39c7e2a6-7dad-4643-ad5b-631d01345809", "node_type": null, "metadata": {"page_label": "3", "file_name": "2210.03629.pdf"}, "hash": "b003cf6ca69eaaf907e4008ff6da8d637bebb8af12c0fc85788a261422fbf3c9"}, "2": {"node_id": "85923b04-5b0f-4d9d-aa26-04168ac9b8f3", "node_type": null, "metadata": {"page_label": "3", "file_name": "2210.03629.pdf"}, "hash": "1622f7987645b2a63d96e6c29729d316c95d6f6fac78cc778f28163c16484584"}}, "hash": "05a38f8ed482b80add886e0e5a43f06ae676daf24d31042ce91e394001d40b1f", "text": "information by reasoning over the current context ct,\nand update the context ct+1= (ct;^at)to support future reasoning or acting. As shown in Figure 1,\nthere could be various types of useful thoughts, e.g. decomposing task goals and create action plans\n(2b, Act 1; 1d, Thought 1), injecting commonsense knowledge relevant to task solving (2b, Act 1),\nextracting important parts from observations (1d, Thought2, 4), track progress and transit action plans\n(2b, Act 8), handle exceptions and adjust action plans (1d, Thought 3), and so on.\nHowever, as the language space Lis unlimited, learning in this augmented action space is dif\ufb01cult\nand requires strong language priors. In this paper, we mainly focus on the setup where a frozen\nlarge language model, PaLM-540B (Chowdhery et al., 2022)1, is prompted with few-shot in-context\nexamples to generate both domain-speci\ufb01c actions and free-form language thoughts for task solving\n(Figure 1 (1d), (2b)). Each in-context example is a human trajectory of actions, thoughts, and\nenvironment observations to solve a task instance (see Appendix C). For the tasks where reasoning is\nof primary importance (Figure 1(1)), we alternate the generation of thoughts and actions so that the\ntask-solving trajectory consists of multiple thought-action-observation steps. In contrast, for decision\nmaking tasks that potentially involve a large number of actions (Figure 1(2)), thoughts only need to\n1We show some GPT-3 (Brown et al., 2020) results in Appendix A.1, which outperforms PaLM-540B.\n3", "start_char_idx": 3649, "end_char_idx": 5174, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "422b49d4-44c0-432c-8868-0a3ae51bf76c": {"__data__": {"id_": "422b49d4-44c0-432c-8868-0a3ae51bf76c", "embedding": null, "metadata": {"page_label": "4", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ffec7c77-c935-4014-8123-9f14cae9e412", "node_type": null, "metadata": {"page_label": "4", "file_name": "2210.03629.pdf"}, "hash": "7c800bbb8839d60ead68330aabb50f1bf2fc0e262635a43eaeeff90aae3814d2"}, "3": {"node_id": "9eb9889a-cd93-45e4-b8c0-5d370e6161eb", "node_type": null, "metadata": {"page_label": "4", "file_name": "2210.03629.pdf"}, "hash": "9f9c677640a8f6d1f0ef697912b10093af661290abc11e28c06a2fec9fd347b9"}}, "hash": "4918ef107e95bcad94db7ec037515d3984a2eb420a8da641e6d8a20deac93794", "text": "Published as a conference paper at ICLR 2023\nappear sparsely in the most relevant positions of a trajectory, so we let the language model decide the\nasynchronous occurrence of thoughts and actions for itself.\nSince decision making and reasoning capabilities are integrated into a large language model, ReAct\nenjoys several unique features: A) Intuitive and easy to design : Designing ReAct prompts is\nstraightforward as human annotators just type down their thoughts in language on top of their actions\ntaken. No ad-hoc format choice, thought design, or example selection is used in this paper. We detail\nprompt design for each task in Sections 3 and 4. B) General and \ufb02exible : Due to the \ufb02exible thought\nspace and thought-action occurrence format, ReAct works for diverse tasks with distinct action\nspaces and reasoning needs, including but not limited to QA, fact veri\ufb01cation, text game, and web\nnavigation. C) Performant and robust :ReAct shows strong generalization to new task instances\nwhile learning solely from one to six in-context examples, consistently outperforming baselines with\nonly reasoning or acting across different domains. We also show in Section 3 additional bene\ufb01ts\nwhen \ufb01netuning is enabled, and in Section 4 how ReAct performance is robust to prompt selections.\nD) Human aligned and controllable :ReAct promises an interpretable sequential decision making\nand reasoning process where humans can easily inspect reasoning and factual correctness. Moreover,\nhumans can also control or correct the agent behavior on the go by thought editing, as shown in\nFigure 5 in Section 4.\n3 K NOWLEDGE -INTENSIVE REASONING TASKS\nWe begin with knowledge-intensive reasoning tasks like multi-hop question answering and fact\nveri\ufb01cation. As shown in Figure 1(1d), by interacting with a Wikipedia API, ReAct is able to\nretrieve information to support reasoning, while also use reasoning to target what to retrieve next,\ndemonstrating a synergy of reasoning and acting.\n3.1 S ETUP\nDomains We consider two datasets challenging knowledge retrieval and reasoning: (1) Hot-\nPotQA (Yang et al., 2018), a multi-hop question answering benchmark that requires reasoning\nover two or more Wikipedia passages, and (2) FEVER (Thorne et al., 2018), a fact veri\ufb01cation\nbenchmark where each claim is annotated SUPPORTS, REFUTES, or NOT ENOUGH INFO, based\non if there exists a Wikipedia passage to verify the claim. In this work, we operate in a question-only\nsetup for both tasks, where models only receive the question/claim as input without access to support\nparagraphs, and have to rely on their internal knowledge or retrieve knowledge via interacting with\nan external environment to support reasoning.\nAction Space We design a simple Wikipedia web API with three types of actions to support\ninteractive information retrieval: (1) search [entity ], which returns the \ufb01rst 5 sentences from\nthe corresponding entity wiki page if it exists, or else suggests top-5 similar entities from the\nWikipedia search engine, (2) lookup [string ], which would return the next sentence in the page\ncontaining string , simulating Ctrl+F functionality on the browser. (3) finish [answer ], which\nwould \ufb01nish the current task with answer . We note that this action space mostly can only retrieve a\nsmall part of a passage based on exact passage name, which is signi\ufb01cantly weaker than state-of-the-\nart lexical or neural retrievers. The purpose is to simulate how humans would interact with Wikipedia,\nand force models to retrieve via explicit reasoning in language.\n3.2 M ETHODS\nReAct Prompting For HotpotQA and Fever, we randomly select 6 and 3 cases2from the training\nset and manually compose ReAct -format trajectories to use as few-shot exemplars in the prompts.\nSimilar to Figure 1(d), each trajectory consists of multiple thought-action-observation steps (i.e.", "start_char_idx": 0, "end_char_idx": 3844, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9eb9889a-cd93-45e4-b8c0-5d370e6161eb": {"__data__": {"id_": "9eb9889a-cd93-45e4-b8c0-5d370e6161eb", "embedding": null, "metadata": {"page_label": "4", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ffec7c77-c935-4014-8123-9f14cae9e412", "node_type": null, "metadata": {"page_label": "4", "file_name": "2210.03629.pdf"}, "hash": "7c800bbb8839d60ead68330aabb50f1bf2fc0e262635a43eaeeff90aae3814d2"}, "2": {"node_id": "422b49d4-44c0-432c-8868-0a3ae51bf76c", "node_type": null, "metadata": {"page_label": "4", "file_name": "2210.03629.pdf"}, "hash": "4918ef107e95bcad94db7ec037515d3984a2eb420a8da641e6d8a20deac93794"}}, "hash": "9f9c677640a8f6d1f0ef697912b10093af661290abc11e28c06a2fec9fd347b9", "text": "trajectory consists of multiple thought-action-observation steps (i.e. dense\nthought), where free-form thoughts are used for various purposes. Speci\ufb01cally, we use a combination\nof thoughts that decompose questions (\u201cI need to search x, \ufb01nd y, then \ufb01nd z\u201d), extract information\nfrom Wikipedia observations (\u201cx was started in 1844\u201d, \u201cThe paragraph does not tell x\u201d), perform\ncommonsense (\u201cx is not y, so z must instead be...\u201d) or arithmetic reasoning (\u201c1844 < 1989\u201d), guide\n2We \ufb01nd more examples do not improve performance.\n4", "start_char_idx": 3774, "end_char_idx": 4297, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "0c696ece-b278-4082-9bac-7a2cba011e16": {"__data__": {"id_": "0c696ece-b278-4082-9bac-7a2cba011e16", "embedding": null, "metadata": {"page_label": "5", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9b31f9b1-8d0d-482e-948b-2873365655ee", "node_type": null, "metadata": {"page_label": "5", "file_name": "2210.03629.pdf"}, "hash": "553472b7e37f352fb872c015c99e4d42aab3a3fee0f6fad880943cc92f78378a"}, "3": {"node_id": "330f38e4-4d83-4f60-b74e-3e4e9a345ae8", "node_type": null, "metadata": {"page_label": "5", "file_name": "2210.03629.pdf"}, "hash": "73920310140b4c736f3bdeefe7721bec4ec7bdf9d40ad25f5916e28edf444152"}}, "hash": "665418a7f72001af20f86018bbb280eada38fa5c8391e0d20f03e8e0aea6087c", "text": "Published as a conference paper at ICLR 2023\nPrompt Methoda HotpotQA Fever\n(EM) (Acc)\nStandard 28.7 57.1\nCoT (Wei et al., 2022) 29.4 56.3\nCoT-SC (Wang et al., 2022a) 33.4 60.4\nAct 25.7 58.9\nReAct 27.4 60.9\nCoT-SC!ReAct 34.2 64.6\nReAct!CoT-SC 35.1 62.0\nSupervised SoTAb67.5 89.5\nTable 1: PaLM-540B prompting results on\nHotpotQA and Fever.\naHotpotQA EM is 27.1, 28.9, 33.8 for Standard ,CoT,\nCoT-SC in Wang et al. (2022b).\nb(Zhu et al., 2021; Lewis et al., 2020)\n0 5 10 15 20\n#CoT-SC trials2628303234HotpotQA EM\n0 5 10 15 20\n#CoT-SC trials47.550.052.555.057.560.062.565.0Fever AccMethod\nCoT-SC -> ReAct\nReAct -> CoT-SC\nCoT-SC\nReAct\nCoTFigure 2: PaLM-540B prompting results with respect to\nnumber of CoT-SC samples used.\nsearch reformulation (\u201cmaybe I can search/look up x instead\u201d), and synthesize the \ufb01nal answer (\u201c...so\nthe answer is x\u201d). See Appendix C for more details.\nBaselines We systematically ablate ReAct trajectories to build prompts for multiple baselines (with\nformats as Figure 1(1a-1c)): (a) Standard prompting (Standard ), which removes all thoughts,\nactions, observations in ReAct trajectories. (b) Chain-of-thought prompting (CoT) (Wei et al.,\n2022), which removes actions and observations and serve as a reasoning-only baseline. We also\nbuild a self-consistency baseline ( CoT-SC ) (Wang et al., 2022a;b) by sampling 21 CoT trajectories\nwith decoding temperature 0.7 during inference and adopting the majority answer, which is found to\nconsistently boost performance over CoT. (c)Acting-only prompt (Act), which removes thoughts\ninReAct trajectories, loosely resembling how WebGPT (Nakano et al., 2021) interacts with the\nInternet to answer questions, though it operates on a different task and action space, and uses imitation\nand reinforcement learning instead of prompting.\nCombining Internal and External Knowledge As will be detail in Section 3.3, we observe that\nthe problem solving process demonstrated by ReAct is more factual and grounded, whereas CoT\nis more accurate in formulating reasoning structure but can easily suffer from hallucinated facts\nor thoughts. We therefore propose to incorporate ReAct andCoT-SC , and let the model decide\nwhen to switch to the other method based on the following heuristics: A) ReAct!CoT-SC : when\nReAct fails to return an answer within given steps, back off to CoT-SC . We set 7 and 5 steps for\nHotpotQA and FEVER respectively as we \ufb01nd more steps will not improve ReAct performance3.\nB)CoT-SC!ReAct : when the majority answer among nCoT-SC samples occurs less than n=2\ntimes (i.e. internal knowledge might not support the task con\ufb01dently), back off to ReAct .\nFinetuning Due to the challenge of manually annotating reasoning traces and actions at scale,\nwe consider a bootstraping approach similar to Zelikman et al. (2022), using 3,000 trajectories\nwith correct answers generated by ReAct (also for other baselines) to \ufb01netune smaller language\nmodels (PaLM-8/62B) to decode trajectories (all thoughts, actions, observations) conditioned on\ninput questions/claims. More details are", "start_char_idx": 0, "end_char_idx": 3046, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "330f38e4-4d83-4f60-b74e-3e4e9a345ae8": {"__data__": {"id_": "330f38e4-4d83-4f60-b74e-3e4e9a345ae8", "embedding": null, "metadata": {"page_label": "5", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9b31f9b1-8d0d-482e-948b-2873365655ee", "node_type": null, "metadata": {"page_label": "5", "file_name": "2210.03629.pdf"}, "hash": "553472b7e37f352fb872c015c99e4d42aab3a3fee0f6fad880943cc92f78378a"}, "2": {"node_id": "0c696ece-b278-4082-9bac-7a2cba011e16", "node_type": null, "metadata": {"page_label": "5", "file_name": "2210.03629.pdf"}, "hash": "665418a7f72001af20f86018bbb280eada38fa5c8391e0d20f03e8e0aea6087c"}}, "hash": "73920310140b4c736f3bdeefe7721bec4ec7bdf9d40ad25f5916e28edf444152", "text": "actions, observations) conditioned on\ninput questions/claims. More details are in Appendix B.1.\n3.3 R ESULTS AND OBSERVATIONS\nReAct outperforms Act consistently Table 1 shows HotpotQA and Fever results using PaLM-\n540B as the base model with different prompting methods. We note that ReAct is better than Act\non both tasks, demonstrating the value of reasoning to guide acting, especially for synthesizing the\n\ufb01nal answer, as shown in Figure 1 (1c-d). Fine-tuning results 3 also con\ufb01rm the bene\ufb01t of reasoning\ntraces for more informed acting.\n3Of all trajectories with correct \ufb01nal answers, those with 7 steps on HotpotQA and 5 steps on FEVER only\ntake up 0.84% and 1.33% respectively.\n5", "start_char_idx": 2968, "end_char_idx": 3655, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8fb17a11-6d73-4ab3-ad3a-28b9f1f948b7": {"__data__": {"id_": "8fb17a11-6d73-4ab3-ad3a-28b9f1f948b7", "embedding": null, "metadata": {"page_label": "6", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce1e3f57-da81-43f6-b33b-19366426affd", "node_type": null, "metadata": {"page_label": "6", "file_name": "2210.03629.pdf"}, "hash": "a87bc9e5ad500e01e4a5d6889c29504a70aaf2de0442dfa12d3a6655586d4ee6"}, "3": {"node_id": "33d0cea3-8e84-48f1-b071-80f2fe06638b", "node_type": null, "metadata": {"page_label": "6", "file_name": "2210.03629.pdf"}, "hash": "6e4428f0994dc858dddb45716e8927e4cdedc1d044538ce900c3a91f3ee002ec"}}, "hash": "0535c1f431f481424254e834d9d40cebc98cb8d1009616ae565c6acd00a4e9c5", "text": "Published as a conference paper at ICLR 2023\nType De\ufb01nition ReAct CoT\nSuccessTrue positive Correct reasoning trace and facts 94% 86%\nFalse positive Hallucinated reasoning trace or facts 6% 14%\nFailureReasoning error Wrong reasoning trace (including failing to recover from repetitive steps) 47% 16%\nSearch result error Search return empty or does not contain useful information 23% -\nHallucination Hallucinated reasoning trace or facts 0% 56%\nLabel ambiguity Right prediction but did not match the label precisely 29% 28%\nTable 2: Types of success and failure modes of ReAct andCoT on HotpotQA, as well as their\npercentages in randomly selected examples studied by human.\nReAct vs.CoT On the other hand, ReAct outperforms CoT on Fever (60.9 vs. 56.3) and slightly\nlags behind CoT on HotpotQA (27.4 vs. 29.4). Fever claims for SUPPORTS/REFUTES might only\ndiffer by a slight amount (see Appendix D.1), so acting to retrieve accurate and up-to-date knowledge\nis vital. To better understand the behavioral difference between ReAct andCoT on HotpotQA, we\nrandomly sampled 50 trajectories with correct and incorrect answers (judged by EM) from ReAct\nandCoT respectively (thus 200 examples in total), and manually labeled their success and failure\nmodes in Table 2. Some key observations are as follows:\nA)Hallucination is a serious problem for CoT, resulting in much higher false positive rate than\nReAct (14% vs. 6%) in success mode, and make up its major failure mode (56%). In contrast, the\nproblem solving trajectory of ReAct is more grounded, fact-driven, and trustworthy, thanks to the\naccess of an external knowledge base.\nB)While interleaving reasoning, action and observation steps improves ReAct \u2019s grounded-\nness and trustworthiness, such a structural constraint also reduces its \ufb02exibility in formulating\nreasoning steps , leading to more reasoning error rate than CoT. we note that there is one frequent\nerror pattern speci\ufb01c to ReAct , in which the model repetitively generates the previous thoughts and\nactions, and we categorize it as part of \u201creasoning error\u201d as the model fails to reason about what the\nproper next action to take and jump out of the loop4.\nC)ForReAct , successfully retrieving informative knowledge via search is critical. Non-\ninformative search, which counts for 23% of the error cases, derails the model reasoning and gives\nit a hard time to recover and reformulate thoughts. This is perhaps an expected trade-off between\nfactuality and \ufb02exibility, which motivates our proposed strategies of combining two methods.\nWe provide examples for each success and failure modes in Appendix E.1. We also \ufb01nd some\nHotpotQA questions may contain outdated answer labels, see Figure 4 for example.\nReAct +CoT-SC perform best for prompting LLMs Also shown in Table 1, the best prompting\nmethod on HotpotQA and Fever are ReAct!CoT-SC andCoT-SC!ReAct respectively.\nFurthermore, Figure 2 shows how different methods perform with respect to the number of CoT-SC\nsamples used. While two ReAct +CoT-SC methods are advantageous at one task each, they both\nsigni\ufb01cantly and consistently outperform CoT-SC across different number of samples, reaching\nCoT-SC performance with 21 samples using merely 3-5 samples. These results indicate the value of\nproperly combining model internal knowledge and external knowledge for reasoning tasks.\nReAct performs best for \ufb01ne-tuning Figure 3 shows the scaling effect of prompting/\ufb01netuning\nfour methods ( Standard ,CoT,Act,ReAct ) on HotpotQA. With PaLM-8/62B, prompting ReAct\nperforms worst among four methods due", "start_char_idx": 0, "end_char_idx": 3561, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "33d0cea3-8e84-48f1-b071-80f2fe06638b": {"__data__": {"id_": "33d0cea3-8e84-48f1-b071-80f2fe06638b", "embedding": null, "metadata": {"page_label": "6", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce1e3f57-da81-43f6-b33b-19366426affd", "node_type": null, "metadata": {"page_label": "6", "file_name": "2210.03629.pdf"}, "hash": "a87bc9e5ad500e01e4a5d6889c29504a70aaf2de0442dfa12d3a6655586d4ee6"}, "2": {"node_id": "8fb17a11-6d73-4ab3-ad3a-28b9f1f948b7", "node_type": null, "metadata": {"page_label": "6", "file_name": "2210.03629.pdf"}, "hash": "0535c1f431f481424254e834d9d40cebc98cb8d1009616ae565c6acd00a4e9c5"}}, "hash": "6e4428f0994dc858dddb45716e8927e4cdedc1d044538ce900c3a91f3ee002ec", "text": "prompting ReAct\nperforms worst among four methods due to the dif\ufb01culty to learn both reasoning and acting from\nin-context examples. However, when \ufb01netuned with just 3,000 examples, ReAct becomes the best\nmethod among the four, with PaLM-8B \ufb01netuned ReAct outperforming all PaLM-62B prompting\nmethods, and PaLM-62B \ufb01netuned ReAct outperforming all 540B prompting methods. In contrast,\n\ufb01netuning Standard orCoT is signi\ufb01cantly worse than \ufb01netuning ReAct orAct for both PaLM-\n8/62B, as the former essentially teaches models to memorize (potentially halluincated) knowledge\nfacts, and the latter teaches models how to (reason and) act to access information from Wikipedia, a\nmore generalizable skill for knowledge reasoning. As all prompting methods are still signi\ufb01cantly\nfar from domain-speci\ufb01c state-of-the-art approaches (Table 1), we believe \ufb01netuning with more\nhuman-written data might be a better way to unleash the power of ReAct .\n4We suspect that this could be due to the sub-optimal greedy decoding procedure, and future work using\nbetter decoding (e.g. beam search) might help address this issue.\n6", "start_char_idx": 3508, "end_char_idx": 4614, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "24170805-97f6-460a-9dae-d806d9a8867f": {"__data__": {"id_": "24170805-97f6-460a-9dae-d806d9a8867f", "embedding": null, "metadata": {"page_label": "7", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "52b69969-d9a4-4493-9a79-a0fd69886a11", "node_type": null, "metadata": {"page_label": "7", "file_name": "2210.03629.pdf"}, "hash": "a7f8253c248b93a666e038278f6319f9a2a5d1d7fcd65a8d6154f85eefbd73e1"}, "3": {"node_id": "bfa94f5c-b2d3-4d2a-83da-1a501ebc6c14", "node_type": null, "metadata": {"page_label": "7", "file_name": "2210.03629.pdf"}, "hash": "d9a437606891c7f6b4c4cb5396f4e6846f81c1e89ceed254ae52189bb7064680"}}, "hash": "607035725104ffb96eaf0cac64375398e0d7cc3c38399cef1b422c87d4cbb377", "text": "Published as a conference paper at ICLR 2023\n8b 62b 540b\nsize051015202530HotpotQA EMlearning = prompt\n8b 62b 540b\nsizelearning = finetune\nMethod\nStandard\nCoT\nAct\nReAct\nFigure 3: Scaling results for prompting and \ufb01netuning on HotPotQA with ReAct (ours) and baselines.\n4 D ECISION MAKING TASKS\nWe also test ReAct on two language-based interactive decision-making tasks, ALFWorld and\nWebShop, both of which feature complex environments that require agents to act over long horizons\nwith sparse rewards, warranting the need for reasoning to act and explore effectively.\nALFWorld ALFWorld (Shridhar et al., 2020b) (Figure 1(2)) is a synthetic text-based game designed\nto align with the embodied ALFRED benchmark (Shridhar et al., 2020a). It includes 6 types of\ntasks in which an agent needs to achieve a high-level goal (e.g. examine paper under desklamp) by\nnavigating and interacting with a simulated household via text actions (e.g. go to coffeetable 1, take\npaper 2, use desklamp 1). A task instance can have more than 50 locations and take an expert policy\nmore than 50 steps to solve, thus challenging an agent to plan and track subgoals, as well as explore\nsystematically (e.g. check all desks one by one for desklamp). In particular, one challenge built into\nALFWorld is the need to determine likely locations for common household items (e.g. desklamps will\nlikely be on desks, shelfs, or dressers), making this environment a good \ufb01t for LLMs to exploit their\npretrained commonsense knowledge. To prompt ReAct , we randomly annotate three trajectories\nfrom the training set for each task type, where each trajectory includes sparse thoughts that (1)\ndecompose the goal, (2) track subgoal completion, (3) determine the next subgoal, and (4) reason via\ncommonsense where to \ufb01nd an object and what to do with it. We show prompts used for ALFWorld\nin Appendix C.4. Following Shridhar et al. (2020b), we evaluate on 134 unseen evaluation games\nin a task-speci\ufb01c setup. For robustness, we construct 6 prompts for each task type through each\npermutation of 2 annotated trajectories from the 3 we annotate. Act prompts are constructed using\nthe same trajectories, but without thoughts \u2014 since task instances are randomly chosen from the\ntraining set, it favors neither ReAct norAct and provides a fair and controlled comparison to test the\nimportance of sparse thoughts. For baselines, we use BUTLER (Shridhar et al., 2020b), an imitation\nlearning agent trained on 105expert trajectories for each task type5.\nWebShop CanReAct also interact with noisy real-world language environments for practical\napplications? We investigate WebShop (Yao et al., 2022), a recently proposed online shopping\nwebsite environment with 1.18M real-world products and 12k human instructions. Unlike ALFWorld,\nWebshop contains a high variety of structured and unstructured texts (e.g. product titles, descriptions,\nand options crawled from Amazon), and requires an agent to purchase a product based on a user\ninstruction (e.g. \u201cI am looking for a nightstand with drawers. It should have a nickel \ufb01nish, and\npriced lower than $140\u201d) through web interactions (e.g. search \u201cnightstand drawers\u201d, choose buttons\nsuch as \u201ccolor: modern-nickel-white\u201d or \u201cback to search\u201d). This task is evaluated by average score\n(percentage of desired attributes covered by the chosen product averaged across all episodes) and\nsuccess rate (percentage of episodes where the chosen product satis\ufb01es all requirements) on 500 test\ninstructions. We formulate Act prompts with", "start_char_idx": 0, "end_char_idx": 3520, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "bfa94f5c-b2d3-4d2a-83da-1a501ebc6c14": {"__data__": {"id_": "bfa94f5c-b2d3-4d2a-83da-1a501ebc6c14", "embedding": null, "metadata": {"page_label": "7", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "52b69969-d9a4-4493-9a79-a0fd69886a11", "node_type": null, "metadata": {"page_label": "7", "file_name": "2210.03629.pdf"}, "hash": "a7f8253c248b93a666e038278f6319f9a2a5d1d7fcd65a8d6154f85eefbd73e1"}, "2": {"node_id": "24170805-97f6-460a-9dae-d806d9a8867f", "node_type": null, "metadata": {"page_label": "7", "file_name": "2210.03629.pdf"}, "hash": "607035725104ffb96eaf0cac64375398e0d7cc3c38399cef1b422c87d4cbb377"}}, "hash": "d9a437606891c7f6b4c4cb5396f4e6846f81c1e89ceed254ae52189bb7064680", "text": "all requirements) on 500 test\ninstructions. We formulate Act prompts with actions to search, choose product, choose options,\nand buy, with ReAct prompts additionally reasoning to determine what to explore, when to buy,\nand what products options are relevant to the instruction. See Table 6 for an example prompt, and\nTable 10 for model predictions in the Appendix. We compare to an imitation learning (IL) method\n5Micheli & Fleuret (2021) \ufb01netuned a GPT-2 model on 3553 task instances and achieved a much improved\nperformance than BUTLER, but it is trained on all task types, thus not included as a baseline.\n7", "start_char_idx": 3447, "end_char_idx": 4057, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4c0b1d9e-a335-4225-b57b-70396c168bbc": {"__data__": {"id_": "4c0b1d9e-a335-4225-b57b-70396c168bbc", "embedding": null, "metadata": {"page_label": "8", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ec4f7de8-a525-4137-8097-a46db8ccf40b", "node_type": null, "metadata": {"page_label": "8", "file_name": "2210.03629.pdf"}, "hash": "e6cb0c3715ab899f3cc2e86c1019a5ae4340ace801d5ed46e5cb0095fb734408"}, "3": {"node_id": "a4a161ae-a5a3-4db9-997a-8d5a242f4c7b", "node_type": null, "metadata": {"page_label": "8", "file_name": "2210.03629.pdf"}, "hash": "ced4c5115a7856a590f56ce1841e765e81aec2b0829ef8a8eb6b43bbbf949aa4"}}, "hash": "528e2c1846603c092af336ec0dbaec1e8a1c11a86653affe40f7aa8e4859aaa7", "text": "Published as a conference paper at ICLR 2023\nMethod Pick Clean Heat Cool Look Pick 2 All\nAct (best of 6) 88 42 74 67 72 41 45\nReAct (avg) 65 39 83 76 55 24 57\nReAct (best of 6) 92 58 96 86 78 41 71\nReAct-IM (avg) 55 59 60 55 23 24 48\nReAct-IM (best of 6) 62 68 87 57 39 33 53\nBUTLER g(best of 8) 33 26 70 76 17 12 22\nBUTLER (best of 8) 46 39 74 100 22 24 37\nTable 3: AlfWorld task-speci\ufb01c success rates (%). BUTLER and\nBUTLER gresults are from Table 4 of Shridhar et al. (2020b). All\nmethods use greedy decoding, except that BUTLER uses beam search.Method Score SR\nAct 62.3 30.1\nReAct 66.6 40.0\nIL 59.9 29.1\nIL+RL 62.4 28.7\nHuman82.1 59.6Expert\nTable 4: Score and suc-\ncess rate (SR) on Web-\nshop. IL/IL+RL taken\nfrom Yao et al. (2022).\ntrained with 1,012 human annotated trajectories, and a imitation + reinforcement learning (IL + RL)\nmethod additionally trained with 10,587 training instructions.\nResults ReAct outperforms Act on both ALFWorld (Table 3) and Webshop (Table 4). On\nALFWorld, the best ReAct trial achieves an average success rate of 71%, signi\ufb01cantly outperforming\nthe best Act (45%) and BUTLER (37%) trials. In fact, even the worse ReAct trial (48%) beats\nthe best trial of both methods. Moreover, the advantage of ReAct overAct is consistent across\nsix controlled trials, with relative performance gain ranging from 33% to 90% and averaging 62%.\nQualitatively, we saw that, without any thoughts at all, Act fails to correctly decompose goals\ninto smaller subgoals, or loses track of the current state of the environment. Example trajectories\ncomparing ReAct andAct can be found in Appendix D.2.1 and Appendix D.2.2.\nOn Webshop, one-shot Act prompting already performs on par with IL and IL+RL methods. With\nadditional sparse reasoning, ReAct achieves signi\ufb01cantly better performance, with an absolute 10%\nimprovement over the previous best success rate. By checking examples, we \ufb01nd that ReAct is more\nlikely to identify instruction-relevant products and options by reasoning to bridge the gap between\nnoisy observations and actions (e.g. \u201cFor \u2018space-saving ottoman bench for living room\u2019, the item\nhas options \u201839x18x18inch\u2019 and \u2018blue\u2019 and seems good to buy.\u201d). However, existing methods are\nstill far from the performance of expert humans (Table 4), who perform signi\ufb01cantly more product\nexplorations and query re-formulations that are still challenging for prompting-based methods.\nOn the value of internal reasoning vs. external feedback To our knowledge, ReAct is the \ufb01rst\ndemonstration of combined reasoning and action using an LLM applied to an interactive environment\nwithin a closed-loop system. Perhaps the closest prior work is Inner Monologue (IM), from Huang\net al. (2022b), in which actions from an embodied agent are motivated by an eponymous \u201cinner\nmonologue\u201d. However, IM\u2019s \u201cinner monologue\u201d is limited to observations of the environment\nstate and what needs to be completed by the agent for the goal to be satis\ufb01ed. In contrast, the\nreasoning traces in ReAct for decision making is \ufb02exible and sparse, allowing diverse reasoning\ntypes (see Section 2) to be induced for different tasks.\nTo demonstrate the differences between ReAct and IM, and to highlight the importance of internal\nreasoning vs. simple reactions to external feedback, we ran an ablation experiment using a thought\npattern composed of IM-like dense external feedback. As can", "start_char_idx": 0, "end_char_idx": 3378, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a4a161ae-a5a3-4db9-997a-8d5a242f4c7b": {"__data__": {"id_": "a4a161ae-a5a3-4db9-997a-8d5a242f4c7b", "embedding": null, "metadata": {"page_label": "8", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ec4f7de8-a525-4137-8097-a46db8ccf40b", "node_type": null, "metadata": {"page_label": "8", "file_name": "2210.03629.pdf"}, "hash": "e6cb0c3715ab899f3cc2e86c1019a5ae4340ace801d5ed46e5cb0095fb734408"}, "2": {"node_id": "4c0b1d9e-a335-4225-b57b-70396c168bbc", "node_type": null, "metadata": {"page_label": "8", "file_name": "2210.03629.pdf"}, "hash": "528e2c1846603c092af336ec0dbaec1e8a1c11a86653affe40f7aa8e4859aaa7"}}, "hash": "ced4c5115a7856a590f56ce1841e765e81aec2b0829ef8a8eb6b43bbbf949aa4", "text": "using a thought\npattern composed of IM-like dense external feedback. As can be seen in Table 3, ReAct substantially\noutperforms IM-style prompting ( ReAct-IM ) (71 vs. 53 overall success rate), with consistent\nadvantages on \ufb01ve out of six tasks. Qualitatively, we observed that ReAct-IM often made mistakes\nin identifying when subgoals were \ufb01nished, or what the next subgoal should be, due to a lack of high-\nlevel goal decomposition. Additionally, many ReAct-IM trajectories struggled to determine where\nan item would likely be within the ALFWorld environment, due to a lack of commonsense reasoning.\nBoth shortcomings can be addressed in the ReAct paradigm. More details about ReAct-IM is in\nAppendix B.2. An example prompt for ReAct-IM can be found in Appendix C.4, and an example\ntrajectory in Appendix D.2.3.\n8", "start_char_idx": 3303, "end_char_idx": 4118, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1bde052c-9e9c-433d-a451-eabb12cb61a3": {"__data__": {"id_": "1bde052c-9e9c-433d-a451-eabb12cb61a3", "embedding": null, "metadata": {"page_label": "9", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1b86be2e-ba5a-4cf7-b8d7-656f737199a9", "node_type": null, "metadata": {"page_label": "9", "file_name": "2210.03629.pdf"}, "hash": "958e2813b9271d03b10d8b527a2517227181c3fdf3b709e14f82e1573bc8ab14"}, "3": {"node_id": "9b9e6492-51c4-4f50-ae34-beb5a03e22cf", "node_type": null, "metadata": {"page_label": "9", "file_name": "2210.03629.pdf"}, "hash": "4c8846ac33f746b21985563a0b4ac0ccefad688791bb33f1bfa48690ac4664cf"}}, "hash": "89342b15f8ee472a6a007b795a91ce5bba221e5abc633fae8df3d9bfaa8e72d8", "text": "Published as a conference paper at ICLR 2023\n5 R ELATED WORK\nLanguage model for reasoning Perhaps the most well-known work of using LLMs for reasoning\nis Chain-of-Thought (CoT) (Wei et al., 2022), which reveals the ability of LLMs to formulate their\nown \u201cthinking procedure\u201d for problem solving. Several follow-up works have since been performed,\nincluding least-to-most prompting for solving complicated tasks (Zhou et al., 2022), zero-shot-\nCoT (Kojima et al., 2022), and reasoning with self-consistency (Wang et al., 2022a). Recently,\n(Madaan & Yazdanbakhsh, 2022) systematically studied the formulation and structure of CoT, and\nobserved that the presence of symbols, patterns and texts is crucial to the effectiveness of CoT. Other\nwork has also been extended to more sophisticated reasoning architecture beyond simple prompting.\nFor example Selection-Inference (Creswell et al., 2022) divides the reasoning process into two steps\nof \u201cselection\u201d and \u201cinference\u201d. STaR (Zelikman et al., 2022) bootstraps the reasoning process by\n\ufb01netuning the model on correct rationales generated by the model itself. Faithful reasoning (Creswell\n& Shanahan, 2022) decomposes multi-step reasoning into three steps, each performed by a dedicated\nLM respectively. Similar approaches like Scratchpad (Nye et al., 2021), which \ufb01netunes a LM on\nintermediate computation steps, also demonstrate improvement on multi-step computation problems.\nIn contrast to these methods, ReAct performs more than just isolated, \ufb01xed reasoning, and integrates\nmodel actions and their corresponding observations into a coherent stream of inputs for the model to\nreason more accurately and tackle tasks beyond reasoning (e.g. interactive decision making).\nLanguage model for decision making The strong capability of LLMs has enabled them to perform\ntasks beyond language generation, and it is becoming more popular to take advantage of LLMs as a\npolicy model for decision making, especially in interactive environments. WebGPT (Nakano et al.,\n2021) uses an LM to interact with web browsers, navigate through web pages, and infer answers to\ncomplicated questions from ELI5 (Fan et al., 2019). In comparison to ReAct , WebGPT does not\nexplicitly model the thinking and reasoning procedure, instead rely on expensive human feedback for\nreinforcement learning. In conversation modeling, chatbots like BlenderBot (Shuster et al., 2022b)\nand Sparrow (Glaese et al., 2022) and task-oriented dialogue systems like SimpleTOD (Hosseini-Asl\net al., 2020) also train LMs to make decision about API calls. Unlike ReAct , they do not explicitly\nconsider the reasoning procedure either, and also relies on expensive datasets and human feedback\ncollections for policy learning. In contrast, ReAct learns a policy in a much cheaper way, since the\ndecision making process only requires language description of the reasoning procedure.6\nLLMS have also been increasingly employed in interactive and embodied environments for planning\nand decision making. Perhaps most relevant to ReAct in this respect are SayCan (Ahn et al., 2022)\nand Inner Monologue (Huang et al., 2022b), which use LLMs for robotic action planning and decision\nmaking. In SayCan, LLMs were prompted to directly predict possible actions a robot can take, which\nis then reranked by an affordance model grounded on the visual environments for \ufb01nal prediction.\nInner Monologue made further improvements by adding the eponymous \u201cinner monologue\", which is\nimplemented as injected feedback from the environment. To our knowledge, Inner Monologue is the\n\ufb01rst work that demonstrates such a closed-loop system, which ReAct builds", "start_char_idx": 0, "end_char_idx": 3634, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9b9e6492-51c4-4f50-ae34-beb5a03e22cf": {"__data__": {"id_": "9b9e6492-51c4-4f50-ae34-beb5a03e22cf", "embedding": null, "metadata": {"page_label": "9", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1b86be2e-ba5a-4cf7-b8d7-656f737199a9", "node_type": null, "metadata": {"page_label": "9", "file_name": "2210.03629.pdf"}, "hash": "958e2813b9271d03b10d8b527a2517227181c3fdf3b709e14f82e1573bc8ab14"}, "2": {"node_id": "1bde052c-9e9c-433d-a451-eabb12cb61a3", "node_type": null, "metadata": {"page_label": "9", "file_name": "2210.03629.pdf"}, "hash": "89342b15f8ee472a6a007b795a91ce5bba221e5abc633fae8df3d9bfaa8e72d8"}}, "hash": "4c8846ac33f746b21985563a0b4ac0ccefad688791bb33f1bfa48690ac4664cf", "text": "work that demonstrates such a closed-loop system, which ReAct builds on. However, we argue\nthat Inner Monologue does not truly comprise of inner thoughts \u2014 this is elaborated in Section 4. We\nalso note that leveraging language as semantically-rich inputs in the process of interactive decision\nmaking has been shown to be successful under other settings (Abramson et al., 2020; Karamcheti\net al., 2021; Huang et al., 2022a; Li et al., 2022). It is becoming more evident that with the help of\nLLMs, language as a fundamental cognitive mechanism will play a critical role in interaction and\ndecision making. What is more, progress in LLMs has also inspired the development of versatile and\ngeneralist agents like Reed et al. (2022).\n6 C ONCLUSION\nWe have proposed ReAct \u2013 a simple yet effective method for synergizing reasoning and acting in\nlarge language models. Through a diverse set of experiments on multi-hop question-answering, fact\nchecking, and interactive decision-making tasks, we show that ReAct leads to superior performance\nwith interpretable decision traces. Despite the simplicity of our method, complex tasks with large\naction spaces require more demonstrations to learn well, which unfortunately can easily go beyond\nthe input length limit of in-context learning. We explore the \ufb01ne-tuning approach on HotpotQA\n6Human feedback can also be incorporated in a complementary manner but we leave it for future work.\n9", "start_char_idx": 3566, "end_char_idx": 4994, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5e5695ef-427a-4bbd-aa3f-5433f52f1d35": {"__data__": {"id_": "5e5695ef-427a-4bbd-aa3f-5433f52f1d35", "embedding": null, "metadata": {"page_label": "10", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "02df2dd5-8010-47da-9e0a-8832d599e6c6", "node_type": null, "metadata": {"page_label": "10", "file_name": "2210.03629.pdf"}, "hash": "3e4ee7bfae158c01d1a25bdefd303066c146f4f807ba1df42c887db3faabf0ce"}, "3": {"node_id": "df255d4d-3e3f-4ee7-8b8b-2dc3bf375e8e", "node_type": null, "metadata": {"page_label": "10", "file_name": "2210.03629.pdf"}, "hash": "0dcc713f223676aa9e2f66b228cefdbe79b5d4beb748883501ec4883bab2dc1a"}}, "hash": "634998572f42c80772ae881b2ed1ecb8f323516849f1efa44a39bda7b422cf23", "text": "Published as a conference paper at ICLR 2023\nwith initial promising results, but learning from more high-quality human annotations will be the\ndesiderata to further improve the performance. Scaling up ReAct with multi-task training and\ncombining it with complementary paradigms like reinforcement learning could result in stronger\nagents that further unlock the potential of LLMs for more applications.\nACKNOWLEDGMENTS\nWe thank the support and feedback of many people from Google Brain team and Princeton NLP\nGroup. This work was supported in part by the National Science Foundation under Grant No.\n2107048. Any opinions, \ufb01ndings, and conclusions or recommendations expressed in this material are\nthose of the author(s) and do not necessarily re\ufb02ect the views of the National Science Foundation.\nREPRODUCIBILITY STATEMENT\nOur main experiments are done on PaLM (Chowdhery et al., 2022), which is not an openly accessible\nmodel yet. To increase reproducibility, we have included all used prompts in Appendix C, additional\nexperiments using GPT-3 (Brown et al., 2020) in Appendix A.1, and associated GPT-3 ReAct\nprompting code at https://anonymous.4open.science/r/ReAct-2268/ .\nETHICS STATEMENT\nReAct prompts large language models to generate more human interpretable, diagnosable, and\ncontrollable task-solving trajectories than previous methods. However, hooking up a large language\nmodel with an action space to interact with external environments (e.g. the web, physical environ-\nments) has potential dangers, e.g. looking up inappropriate or private information, or taking harmful\nactions in an environment. Our experiments minimize such risks by limiting the interactions to\nspeci\ufb01c websites (Wikipedia or WebShop) that are free of private information, without any dangerous\nactions in the action space design (i.e. models cannot really buy products on WebShop the research\nbenchmark, or edit Wikipedia). We believe researchers should be aware of such risks before designing\nmore extensive experiments in the future.\nREFERENCES\nJosh Abramson, Arun Ahuja, Iain Barr, Arthur Brussee, Federico Carnevale, Mary Cassin, Rachita\nChhaparia, Stephen Clark, Bogdan Damoc, Andrew Dudzik, Petko Georgiev, Aurelia Guy, Tim\nHarley, Felix Hill, Alden Hung, Zachary Kenton, Jessica Landon, Timothy Lillicrap, Kory Mathew-\nson, So \u02c7na Mokr\u00e1, Alistair Muldal, Adam Santoro, Nikolay Savinov, Vikrant Varma, Greg Wayne,\nDuncan Williams, Nathaniel Wong, Chen Yan, and Rui Zhu. Imitating interactive intelligence,\n2020. URL https://arxiv.org/abs/2012.05672 .\nMichael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea\nFinn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Daniel Ho, Jasmine\nHsu, Julian Ibarz, Brian Ichter, Alex Irpan, Eric Jang, Rosario Jauregui Ruano, Kyle Jeffrey, Sally\nJesmonth, Nikhil J Joshi, Ryan Julian, Dmitry Kalashnikov, Yuheng Kuang, Kuang-Huei Lee,\nSergey Levine, Yao Lu, Linda Luu, Carolina Parada, Peter Pastor, Jornell Quiambao, Kanishka\nRao, Jarek Rettinghouse, Diego Reyes, Pierre Sermanet, Nicolas Sievers, Clayton Tan, Alexander\nToshev, Vincent Vanhoucke, Fei Xia, Ted Xiao, Peng Xu, Sichun Xu, Mengyuan Yan, and\nAndy Zeng. Do as i can, not as i say: Grounding language in robotic affordances, 2022.", "start_char_idx": 0, "end_char_idx": 3270, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "df255d4d-3e3f-4ee7-8b8b-2dc3bf375e8e": {"__data__": {"id_": "df255d4d-3e3f-4ee7-8b8b-2dc3bf375e8e", "embedding": null, "metadata": {"page_label": "10", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "02df2dd5-8010-47da-9e0a-8832d599e6c6", "node_type": null, "metadata": {"page_label": "10", "file_name": "2210.03629.pdf"}, "hash": "3e4ee7bfae158c01d1a25bdefd303066c146f4f807ba1df42c887db3faabf0ce"}, "2": {"node_id": "5e5695ef-427a-4bbd-aa3f-5433f52f1d35", "node_type": null, "metadata": {"page_label": "10", "file_name": "2210.03629.pdf"}, "hash": "634998572f42c80772ae881b2ed1ecb8f323516849f1efa44a39bda7b422cf23"}}, "hash": "0dcc713f223676aa9e2f66b228cefdbe79b5d4beb748883501ec4883bab2dc1a", "text": "can, not as i say: Grounding language in robotic affordances, 2022. URL\nhttps://arxiv.org/abs/2204.01691 .\nBen Alderson-Day and Charles Fernyhough. Inner speech: development, cognitive functions,\nphenomenology, and neurobiology. Psychological bulletin , 141(5):931, 2015.\nAlan Baddeley. Working memory. Science , 255(5044):556\u2013559, 1992.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\nfew-shot learners. Advances in neural information processing systems , 33:1877\u20131901, 2020.\n10", "start_char_idx": 3203, "end_char_idx": 3815, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "82171b36-dd0f-47fe-ade1-a51a512af9dd": {"__data__": {"id_": "82171b36-dd0f-47fe-ade1-a51a512af9dd", "embedding": null, "metadata": {"page_label": "11", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9244f2d2-7882-46d5-95a1-c87ddfdf246a", "node_type": null, "metadata": {"page_label": "11", "file_name": "2210.03629.pdf"}, "hash": "d587f6f6319dcd13c5ab666cca36d4e0200a469d4455731717bf4c58d34953f2"}, "3": {"node_id": "9b4dad63-8b6f-4aa6-a130-53d444270946", "node_type": null, "metadata": {"page_label": "11", "file_name": "2210.03629.pdf"}, "hash": "931bf32822d58d3ca0b4fe34372fc80c8a9564fcf64c46929c57d0b77f59f91b"}}, "hash": "5779dbd66edc7c9d9b99766a8bf5381edb7fedaceb0d95a55aaf8697d23ca42a", "text": "Published as a conference paper at ICLR 2023\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm:\nScaling language modeling with pathways. arXiv preprint arXiv:2204.02311 , 2022.\nAntonia Creswell and Murray Shanahan. Faithful reasoning using large language models, 2022. URL\nhttps://arxiv.org/abs/2208.14271 .\nAntonia Creswell, Murray Shanahan, and Irina Higgins. Selection-inference: Exploiting large\nlanguage models for interpretable logical reasoning, 2022. URL https://arxiv.org/abs/\n2205.09712 .\nAngela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli. ELI5:\nLong form question answering. In Proceedings of the 57th Annual Meeting of the Association\nfor Computational Linguistics , pp. 3558\u20133567, Florence, Italy, July 2019. Association for Com-\nputational Linguistics. doi: 10.18653/v1/P19-1346. URL https://aclanthology.org/\nP19-1346 .\nCharles Fernyhough. Vygotsky, luria, and the social brain. Self and social regulation: Social\ninteraction and the development of social understanding and executive functions , pp. 56\u201379, 2010.\nAmelia Glaese, Nat McAleese, Maja Trebacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Mari-\nbeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, Lucy Campbell-Gillingham,\nJonathan Uesato, Po-Sen Huang, Ramona Comanescu, Fan Yang, Abigail See, Sumanth\nDathathri, Rory Greig, Charlie Chen, Doug Fritz, Jaume Sanchez Elias, Richard Green,\nSo\u02c7na Mokr\u00e1, Nicholas Fernando, Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel,\nWilliam Isaac, John Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, and\nGeoffrey Irving. Improving alignment of dialogue agents via targeted human judgements,\n2022. URL https://storage.googleapis.com/deepmind-media/DeepMind.\ncom/Authors-Notes/sparrow/sparrow-final.pdf .\nEhsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih Yavuz, and Richard Socher. A simple\nlanguage model for task-oriented dialogue. Advances in Neural Information Processing Systems ,\n33:20179\u201320191, 2020.\nWenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-shot\nplanners: Extracting actionable knowledge for embodied agents. arXiv preprint arXiv:2201.07207 ,\n2022a.\nWenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan\nTompson, Igor Mordatch, Yevgen Chebotar, et al. Inner monologue: Embodied reasoning through\nplanning with language models. arXiv preprint arXiv:2207.05608 , 2022b.\nSiddharth Karamcheti, Megha Srivastava, Percy Liang, and Dorsa Sadigh. Lila: Language-informed\nlatent actions. In CoRL , pp. 1379\u20131390, 2021. URL https://proceedings.mlr.press/\nv164/karamcheti22a.html .\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\nlanguage models are zero-shot reasoners.", "start_char_idx": 0, "end_char_idx": 2901, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9b4dad63-8b6f-4aa6-a130-53d444270946": {"__data__": {"id_": "9b4dad63-8b6f-4aa6-a130-53d444270946", "embedding": null, "metadata": {"page_label": "11", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9244f2d2-7882-46d5-95a1-c87ddfdf246a", "node_type": null, "metadata": {"page_label": "11", "file_name": "2210.03629.pdf"}, "hash": "d587f6f6319dcd13c5ab666cca36d4e0200a469d4455731717bf4c58d34953f2"}, "2": {"node_id": "82171b36-dd0f-47fe-ade1-a51a512af9dd", "node_type": null, "metadata": {"page_label": "11", "file_name": "2210.03629.pdf"}, "hash": "5779dbd66edc7c9d9b99766a8bf5381edb7fedaceb0d95a55aaf8697d23ca42a"}}, "hash": "931bf32822d58d3ca0b4fe34372fc80c8a9564fcf64c46929c57d0b77f59f91b", "text": "and Yusuke Iwasawa. Large\nlanguage models are zero-shot reasoners. arXiv preprint arXiv:2205.11916 , 2022.\nAngeliki Lazaridou, Elena Gribovskaya, Wojciech Stokowiec, and Nikolai Grigorev. Internet-\naugmented language models through few-shot prompting for open-domain question answering.\narXiv preprint arXiv:2203.05115 , 2022.\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,\nHeinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, et al. Retrieval-augmented genera-\ntion for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems , 33:\n9459\u20139474, 2020.\nShuang Li, Xavier Puig, Chris Paxton, Yilun Du, Clinton Wang, Linxi Fan, Tao Chen, De-An\nHuang, Ekin Aky\u00fcrek, Anima Anandkumar, Jacob Andreas, Igor Mordatch, Antonio Torralba,\nand Yuke Zhu. Pre-trained language models for interactive decision-making, 2022. URL https:\n//arxiv.org/abs/2202.01771 .\n11", "start_char_idx": 2835, "end_char_idx": 3764, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "75ed95ba-39fd-4939-9797-0f6910e64349": {"__data__": {"id_": "75ed95ba-39fd-4939-9797-0f6910e64349", "embedding": null, "metadata": {"page_label": "12", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f5e77c29-a785-486d-9081-1a8cf68d1b0a", "node_type": null, "metadata": {"page_label": "12", "file_name": "2210.03629.pdf"}, "hash": "88bb258c5b23699920e91d8f0c6670388e4c310ffbb6020cb2a35e8aa91df1d3"}, "3": {"node_id": "63173a7c-e3e0-4293-a638-cfa868fcc985", "node_type": null, "metadata": {"page_label": "12", "file_name": "2210.03629.pdf"}, "hash": "41adbf5fba435fcb9b4404e3850eb9aede0ccd1d72ef1107fdeac8e0f7affa16"}}, "hash": "fe3a63185f8cb43d1d49aa1e62e832e65d19d5fc8181c3600e2dcee239544c23", "text": "Published as a conference paper at ICLR 2023\nAleksandr Romanovich Luria. Ls vygotsky and the problem of localization of functions. Neuropsy-\nchologia , 3(4):387\u2013392, 1965.\nAman Madaan and Amir Yazdanbakhsh. Text and patterns: For effective chain of thought, it takes\ntwo to tango, 2022. URL https://arxiv.org/abs/2209.07686 .\nVincent Micheli and Fran\u00e7ois Fleuret. Language models are few-shot butlers. arXiv preprint\narXiv:2104.07972 , 2021.\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher\nHesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou,\nGretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. Webgpt:\nBrowser-assisted question-answering with human feedback, 2021. URL https://arxiv.\norg/abs/2112.09332 .\nMaxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David\nBieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton, and\nAugustus Odena. Show your work: Scratchpads for intermediate computation with language\nmodels, 2021. URL https://arxiv.org/abs/2112.00114 .\nScott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo, Alexander Novikov,\nGabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost Tobias Springenberg, Tom\nEccles, Jake Bruce, Ali Razavi, Ashley Edwards, Nicolas Heess, Yutian Chen, Raia Hadsell,\nOriol Vinyals, Mahyar Bordbar, and Nando de Freitas. A generalist agent, 2022. URL https:\n//arxiv.org/abs/2205.06175 .\nMohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi,\nLuke Zettlemoyer, and Dieter Fox. Alfred: A benchmark for interpreting grounded instructions\nfor everyday tasks. In Proceedings of the IEEE/CVF conference on computer vision and pattern\nrecognition , pp. 10740\u201310749, 2020a.\nMohit Shridhar, Xingdi Yuan, Marc-Alexandre C\u00f4t\u00e9, Yonatan Bisk, Adam Trischler, and Matthew\nHausknecht. Alfworld: Aligning text and embodied environments for interactive learning. arXiv\npreprint arXiv:2010.03768 , 2020b.\nKurt Shuster, Mojtaba Komeili, Leonard Adolphs, Stephen Roller, Arthur Szlam, and Jason Weston.\nLanguage models that seek for knowledge: Modular search & generation for dialogue and prompt\ncompletion. arXiv preprint arXiv:2203.13224 , 2022a.\nKurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung,\nMoya Chen, Kushal Arora, Joshua Lane, Morteza Behrooz, William Ngan, Spencer Poff, Naman\nGoyal, Arthur Szlam, Y-Lan Boureau, Melanie Kambadur, and Jason Weston. Blenderbot 3:\na deployed conversational agent that continually learns to responsibly engage, 2022b. URL\nhttps://arxiv.org/abs/2208.03188 .\nJames Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. Fever: a large-scale\ndataset for fact extraction and veri\ufb01cation. arXiv preprint", "start_char_idx": 0, "end_char_idx": 2859, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "63173a7c-e3e0-4293-a638-cfa868fcc985": {"__data__": {"id_": "63173a7c-e3e0-4293-a638-cfa868fcc985", "embedding": null, "metadata": {"page_label": "12", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f5e77c29-a785-486d-9081-1a8cf68d1b0a", "node_type": null, "metadata": {"page_label": "12", "file_name": "2210.03629.pdf"}, "hash": "88bb258c5b23699920e91d8f0c6670388e4c310ffbb6020cb2a35e8aa91df1d3"}, "2": {"node_id": "75ed95ba-39fd-4939-9797-0f6910e64349", "node_type": null, "metadata": {"page_label": "12", "file_name": "2210.03629.pdf"}, "hash": "fe3a63185f8cb43d1d49aa1e62e832e65d19d5fc8181c3600e2dcee239544c23"}}, "hash": "41adbf5fba435fcb9b4404e3850eb9aede0ccd1d72ef1107fdeac8e0f7affa16", "text": "for fact extraction and veri\ufb01cation. arXiv preprint arXiv:1803.05355 , 2018.\nLev S Vygotsky. Thinking and speech. The collected works of LS Vygotsky , 1:39\u2013285, 1987.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdh-\nery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models,\n2022a. URL https://arxiv.org/abs/2203.11171 .\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. Rationale-augmented\nensembles in language models. arXiv preprint arXiv:2207.00747 , 2022b.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny\nZhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint\narXiv:2201.11903 , 2022.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov,\nand Christopher D Manning. Hotpotqa: A dataset for diverse, explainable multi-hop question\nanswering. arXiv preprint arXiv:1809.09600 , 2018.\n12", "start_char_idx": 2808, "end_char_idx": 3807, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "99eaaee5-5cca-4b6c-b84d-cbc6bffa4424": {"__data__": {"id_": "99eaaee5-5cca-4b6c-b84d-cbc6bffa4424", "embedding": null, "metadata": {"page_label": "13", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2d62d1b5-f409-4e2e-86a6-3faed4e22fdb", "node_type": null, "metadata": {"page_label": "13", "file_name": "2210.03629.pdf"}, "hash": "9e1210cb5f3bc09781aecb839c4c81ec7ab6ad643545c67c1bb8582ed8ed6780"}}, "hash": "9e1210cb5f3bc09781aecb839c4c81ec7ab6ad643545c67c1bb8582ed8ed6780", "text": "Published as a conference paper at ICLR 2023\nShunyu Yao, Rohan Rao, Matthew Hausknecht, and Karthik Narasimhan. Keep CALM and explore:\nLanguage models for action generation in text-based games. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Processing (EMNLP) , pp. 8736\u20138754, Online, Novem-\nber 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.704.\nURLhttps://aclanthology.org/2020.emnlp-main.704 .\nShunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan. Webshop: Towards scalable\nreal-world web interaction with grounded language agents. arXiv preprint arXiv:2207.01206 ,\n2022.\nEric Zelikman, Yuhuai Wu, Jesse Mu, and Noah D. Goodman. Star: Bootstrapping reasoning with\nreasoning, 2022. URL https://arxiv.org/abs/2203.14465 .\nDenny Zhou, Nathanael Sch\u00e4rli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans,\nOlivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in\nlarge language models, 2022. URL https://arxiv.org/abs/2205.10625 .\nYunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen, and Xueqi Cheng. Adaptive information\nseeking for open-domain question answering. arXiv preprint arXiv:2109.06747 , 2021.\n13", "start_char_idx": 0, "end_char_idx": 1227, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "89a6e40b-542c-41f4-a4d1-192b4ed73239": {"__data__": {"id_": "89a6e40b-542c-41f4-a4d1-192b4ed73239", "embedding": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b802cc3f-ede2-4b5b-9bc7-51720a3b84b1", "node_type": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "hash": "b6ae0bcec522b97a26e388d4cbad7b516a69835a2b319229a5702054da2cdf27"}, "3": {"node_id": "7b106e53-4279-4fc1-b0f6-28189d4c0b7b", "node_type": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "hash": "c103a0d9619c5e57cf58d37108c6810b46849289af10896ef34623d8759f1a9c"}}, "hash": "1d32377d8679742fa5ef84391f91aa52ca75690bf93bd70da60e0b0e9e55d296", "text": "Published as a conference paper at ICLR 2023\nA A DDITIONAL RESULTS\nA.1 GPT-3 E XPERIMENTS\nPaLM-540B GPT-3\nHotpotQA (exact match) 29.4 30.8\nALFWorld (success rate %) 70.9 78.4\nTable 5: ReAct prompting results using PaLM-540B vs. GPT-3 (text-davinci-002, greedy decoding).\nOn HotpotQA, we randomly sample a subset of 500 validation questions. On ALFWorld, we use all\n134 unseen validation task instances, and use the best prompt set according to PaLM-540B.\nWe run additional GPT-3 (Brown et al., 2020) experiments to con\ufb01rm ReAct prompting performance\nis general across different large language models. As shown in Table 5, GPT-3 (text-davinci-002,\ngreedy decoding) consistently outperforms PaLM-540B on HotpotQA and ALFWorld, possibly\nbecause it is \ufb01netuned with human instruction following. This indicates ReAct prompting is effective\nacross different large language models on different tasks. The code for these experiments are at\nhttps://react-lm.github.io/ .\nA.2 REAC TOBTAINS UP -TO-DATE KNOWLEDGE ON HOTPOT QA \u000b\u0014D\f\u00036WDQGDUG$QVZHU\u001d\u0003\u0016\u000f\u0013\u0013\u0013\u000b\u0014E\f\u0003&R7\u0003\u000b5HDVRQ\u00032QO\\\f7KRXJKW\u001d\u0003/HW", "start_char_idx": 0, "end_char_idx": 1075, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7b106e53-4279-4fc1-b0f6-28189d4c0b7b": {"__data__": {"id_": "7b106e53-4279-4fc1-b0f6-28189d4c0b7b", "embedding": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b802cc3f-ede2-4b5b-9bc7-51720a3b84b1", "node_type": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "hash": "b6ae0bcec522b97a26e388d4cbad7b516a69835a2b319229a5702054da2cdf27"}, "2": {"node_id": "89a6e40b-542c-41f4-a4d1-192b4ed73239", "node_type": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "hash": "1d32377d8679742fa5ef84391f91aa52ca75690bf93bd70da60e0b0e9e55d296"}, "3": {"node_id": "1e7b4340-7f30-43db-88f1-5b638b793622", "node_type": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "hash": "8c06a406cbc6940affa4dad7d7ed152f2237ccd438f0c8f499a037e83d6ccb70"}}, "hash": "c103a0d9619c5e57cf58d37108c6810b46849289af10896ef34623d8759f1a9c", "text": "V\u0003WKLQN\u0003VWHS\u0003E\\\u0003VWHS\u0011\u00037KH\u0003KRWHO\u0003WKDW\u0003LV\u0003KRPH\u0003WR\u0003WKH\u0003&LUTXH\u0003GX\u00036ROHLO\u0003VKRZ\u00030\\VWHUH\u0003LV\u00037UHDVXUH\u0003,VODQG\u0011\u00037UHDVXUH\u0003,VODQG\u0003KDV\u0003\u0015\u000f\u001b\u001b\u0018\u0003URRPV\u000f\u0003VR\u0003WKH\u0003DQVZHU\u0003LV\u0003\u0015\u000f\u001b\u001b\u0018\u0011$QVZHU\u001d\u0003\u0015\u000f\u001b\u001b\u0018\u000b\u0014F\f\u0003$FW\u00102QO\\\u0003$FW\u0003\u0014\u001d\u00036HDUFK>&LUTXH\u0003GX\u00036ROHLO@\u00032EV\u0003\u0014\u001d\u0003&LUTXH\u0003GX\u00036ROHLO\u0003LV\u0003D\u0003&DQDGLDQ\u0003HQWHUWDLQPHQW\u0003FRPSDQ\\\u00aa$FW\u0003\u0015\u001d\u0003/RRNXS>0\\VWHUH@\u00032EV\u0003\u0015\u001d\u00031R\u0003PRUH\u0003UHVXOWV$FW\u0003\u0016\u001d\u00036HDUFK>0\\VWHUH\u0003\u000b&LUTXH\u0003GX\u00036ROHLO\u0003VKRZ\f@\u00032EV\u0003\u0016\u001d\u0003&RXOG\u0003QRW\u0003ILQG\u00aa$FW\u0003\u0017\u001d\u00036HDUFK>0\\VWHUH\u0003\u000b&LUTXH\u0003GX\u00036ROHLO\f@\u00032EV\u0003\u0017\u001d\u00030\\VWqUH\u0003\u000bP\\\u0010VWHHU\f\u0003\u0003LV\u0003RQH\u0003RI\u0003VL[\u00aa$FW\u0003\u0018\u001d\u0003/RRNXS>7UHDVXUH\u0003,VODQG\u0003+RWHO\u0003DQG\u0003&DVLQR@\u0003\u00aa\u00aa\u000bHQG\u0003ZLWKRXW\u0003DQVZHU\f\u000b\u0014G\f\u00035H$FW\u0003\u000b5HDVRQ\u0003\u000e\u0003$FW\f7KRXJKW\u0003\u0014\u001d\u0003,\u0003QHHG\u0003WR\u0003VHDUFK\u0003&LUTXH\u0003GX\u00036ROHLO\u0003VKRZ\u00030\\VWHUH\u000f\u0003ILQG\u0003WKH\u0003KRWHO\u0003LW\u0003LV\u0003LQ\u000f\u0003WKHQ\u0003ILQG\u0003WKH\u0003QXPEHU\u0003RI\u0003URRPV\u0003LQ\u0003WKH\u0003KRWHO\u0011$FW\u0003\u0014\u001d\u00036HDUFK>&LUTXH\u0003GX\u00036ROHLO\u0003VKRZ\u00030\\VWHUH@2EV\u0003\u0014\u001d\u0003&RXOG\u0003QRW\u0003ILQG\u0003&LUTXH\u0003GX\u00036ROHLO\u0003VKRZ\u00030\\VWHUH\u0011\u00036LPLODU\u001d\u0003> &LUTXH\u0003GX\u00036ROHLO", "start_char_idx": 1076, "end_char_idx": 1896, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1e7b4340-7f30-43db-88f1-5b638b793622": {"__data__": {"id_": "1e7b4340-7f30-43db-88f1-5b638b793622", "embedding": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b802cc3f-ede2-4b5b-9bc7-51720a3b84b1", "node_type": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "hash": "b6ae0bcec522b97a26e388d4cbad7b516a69835a2b319229a5702054da2cdf27"}, "2": {"node_id": "7b106e53-4279-4fc1-b0f6-28189d4c0b7b", "node_type": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "hash": "c103a0d9619c5e57cf58d37108c6810b46849289af10896ef34623d8759f1a9c"}, "3": {"node_id": "eabc83f4-e161-4fc5-9588-9a73cfce6a7b", "node_type": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "hash": "95e599565e25a36bdb35a09007afeb3450e29bfc91af6e9c0316abce18012411"}}, "hash": "8c06a406cbc6940affa4dad7d7ed152f2237ccd438f0c8f499a037e83d6ccb70", "text": "&LUTXH\u0003GX\u00036ROHLO \u0003\u00aa7KRXJKW\u0003\u0015\u001d\u00037R\u0003ILQG\u0003WKH\u0003KRWHO\u000f\u0003,\u0003FDQ\u0003VHDUFK\u00030\\VWHUH\u0003\u000b&LUTXH\u0003GX\u00036ROHLO\f\u0011$FW\u0003\u0015\u001d\u00036HDUFK>0\\VWHUH\u0003\u000b&LUTXH\u0003GX\u00036ROHLO\f@2EV\u0003\u0015\u001d\u00030\\VWqUH\u0003\u000bP\\\u0010VWHHU\f\u0003\u0003LV\u0003\u00aa\u0003+HOG\u0003LQ\u0003D\u0003FXVWRP\u0003WKHDWUH\u0003DW\u0003WKH\u00037UHDVXUH\u0003,VODQG\u0003+RWHO\u0003DQG\u0003&DVLQR\u0003\u00aa7KRXJKW\u0003\u0016\u001d\u00030\\VWHUH\u0003LV\u0003KHOG\u0003LQ\u0003D\u0003FXVWRP\u0003WKHDWUH\u0003DW\u0003WKH\u00037UHDVXUH\u0003,VODQG\u0003+RWHO\u0003DQG\u0003&DVLQR\u0011\u00036R\u0003,\u0003QHHG\u0003WR\u0003VHDUFK\u00037UHDVXUH\u0003,VODQG\u0003+RWHO\u0003DQG\u0003&DVLQR\u0003QH[W\u0003DQG\u0003ILQG\u0003WKH\u0003QXPEHU\u0003RI\u0003URRPV\u0003LQ\u0003WKH\u0003KRWHO\u0011$FW\u0003\u0016\u001d\u00036HDUFK>7UHDVXUH\u0003,VODQG\u0003+RWHO\u0003DQG\u0003&DVLQR@2EV\u0003\u0016\u001d\u00037UHDVXUH\u0003,VODQG\u0003+RWHO\u0003DQG\u0003&DVLQR\u0003\u00aa\u0003ZLWK\u0003\u0015\u000f\u001b\u001b\u0017\u0003URRPV\u0003DQG\u0003\u0015\u0015\u0013\u0003VXLWHV\u0003\u00aa7KRXJKW\u0003\u0017\u001d\u00037UHDVXUH\u0003,VODQG\u0003+RWHO\u0003DQG\u0003&DVLQR\u0003KDV\u0003\u0015\u000f\u001b\u001b\u0017\u0003URRPV\u0003DQG\u0003\u0015\u0015\u0013\u0003VXLWHV\u0011\u00036R\u0003WKH\u0003DQVZHU\u0003LV\u0003\u0016\u000f\u0014\u0013\u0017\u0011$FW\u0003\u0017\u001d\u0003)LQLVK>\u0016\u000f\u0014\u0013\u0017@\u04bc4XHVWLRQ\u001d\u0003+RZ\u0003PDQ\\\u0003URRPV\u0003DUH\u0003LQ\u0003WKH\u0003KRWHO\u0003WKDW\u0003LV\u0003KRPH\u0003WR\u0003WKH\u0003&LUTXH\u0003GX\u00036ROHLO\u0003VKRZ\u00030\\VWHUH\"+RWSRW4$\u0003ODEHO\u001d\u0003\u0015\u000f\u0019\u0019\u0017\u000b\u0014\f\u0003+RWVSRW\u00034$2XWGDWHG\u0003 8S\u0010WR\u0010GDWH\u0003 Figure 4: Another example HotpotQA question, where the original label is outdated. Only ReAct is\nable to obtain the up-to-date answer thanks to real-world web interaction plus reasoning.\nDuring trajectory inspection, we also \ufb01nd that sometimes ReAct does not agree with dataset labels as\nthe labels themselves could be outdated. For example, as shown in Figure 4, the question asks about\nthe size of a hotel, which increased from the HotpotQA construction time. While Standard andCoT\ngive wrong answers due to hallucination, Act fails despite the access of real-world web interaction,\ndue to a lack of reasoning to guide how to interact with the Internet for QA. Only ReAct is able to\nretrieve up-to-date information from the Internet and provide a reasonable answer. Therefore, better\nincorporation of reasoning abilities might bene\ufb01t recent Internet-augmented language models (Nakano\net al., 2021; Lazaridou et al., 2022; Shuster et al., 2022a) for up-to-date task solving.\nA.3 H UMAN -IN-THE-LOOP BEHAVIOR CORRECTION ON ALFWORLD\nWe also explore human-in-the-loop interaction with ReAct , to allow a human to inspect and edit\nReAct \u2019s", "start_char_idx": 1881, "end_char_idx": 3824, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "eabc83f4-e161-4fc5-9588-9a73cfce6a7b": {"__data__": {"id_": "eabc83f4-e161-4fc5-9588-9a73cfce6a7b", "embedding": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b802cc3f-ede2-4b5b-9bc7-51720a3b84b1", "node_type": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "hash": "b6ae0bcec522b97a26e388d4cbad7b516a69835a2b319229a5702054da2cdf27"}, "2": {"node_id": "1e7b4340-7f30-43db-88f1-5b638b793622", "node_type": null, "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}, "hash": "8c06a406cbc6940affa4dad7d7ed152f2237ccd438f0c8f499a037e83d6ccb70"}}, "hash": "95e599565e25a36bdb35a09007afeb3450e29bfc91af6e9c0316abce18012411", "text": "with ReAct , to allow a human to inspect and edit\nReAct \u2019s reasoning traces. Figure 5 shows that by simply removing a hallucinating sentence in Act\n17 and adding some hints in Act 23, ReAct can be made to change its behavior drastically to align\nwith these human thought edits and succeed in the task. From a human perspective, solving such a\ntask becomes signi\ufb01cantly easier, from typing tens of actions to only editing a couple of thoughts,\nwhich enables new forms of human-machine collaboration. We note that such a policy edit on-the-go\n14", "start_char_idx": 3782, "end_char_idx": 4325, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a6940ea4-f77e-43d4-88ba-d6f88b2f8e90": {"__data__": {"id_": "a6940ea4-f77e-43d4-88ba-d6f88b2f8e90", "embedding": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e1eead87-5cc0-4e45-8604-ff161f28436b", "node_type": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "hash": "72f9ff6da3cde3e1eb4d4a91497e186e570635b03785723afe0afbbe798fce30"}, "3": {"node_id": "46033e39-3299-49c0-92c3-155dd1f40bc4", "node_type": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "hash": "5a172f0668947301fec52eb0c4f78cb90ae43301b8f207d9374a0610ea368bbd"}}, "hash": "a5f48445c159dd33d1614674d690f67b47f1f3183d4168644e47e2681a50760f", "text": "Published as a conference paper at ICLR 2023", "start_char_idx": 0, "end_char_idx": 44, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "46033e39-3299-49c0-92c3-155dd1f40bc4": {"__data__": {"id_": "46033e39-3299-49c0-92c3-155dd1f40bc4", "embedding": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e1eead87-5cc0-4e45-8604-ff161f28436b", "node_type": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "hash": "72f9ff6da3cde3e1eb4d4a91497e186e570635b03785723afe0afbbe798fce30"}, "2": {"node_id": "a6940ea4-f77e-43d4-88ba-d6f88b2f8e90", "node_type": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "hash": "a5f48445c159dd33d1614674d690f67b47f1f3183d4168644e47e2681a50760f"}, "3": {"node_id": "94db492c-82c1-475f-b794-d39935776411", "node_type": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "hash": "dbed0dca93d5964de914c0de7cc0f584ad11f15eb5a6b305a874ef1a4629498d"}}, "hash": "5a172f0668947301fec52eb0c4f78cb90ae43301b8f207d9374a0610ea368bbd", "text": "Published as a conference paper at ICLR 2023 \u000bD\f\u00035H$FW\u0003\u0011\u0011\u0011\u0011\u0011\u00112EV\u0003\u0014\u0019\u001d\u0003<RX\u0003RSHQ\u0003WKH\u0003GUDZHU\u0003\u0017\u0011\u00037KH\u0003GUDZHU\u0003\u0017\u0003LV\u0003RSHQ\u0011\u0003,Q\u0003LW\u000f\u0003\\RX\u0003VHH\u0003D\u0003NH\\FKDLQ\u0003\u0016\u000f\u0003DQG\u0003D\u0003ZDWFK\u0003\u0015\u0011\u0003$FW\u0003\u0014\u001a\u001d\u00037KLQN\u0003>1RZ\u0003,\u0003ILQG\u0003WKH\u0003ILUVW\u0003NH\\FKDLQ\u0003\u000b\u0016\f\u0011\u00031H[W\u000f\u0003,\u0003QHHG\u0003WR\u0003WDNH\u0003LW\u0011\u0003,\u0003FDQ\u0003ILQG\u0003WKH\u0003VHFRQG\u0003NH\\FKDLQ\u0003\u000b\u0015\f\u0003ODWHU\u0003LQ\u0003GUDZHU\u0003\u0017\u0011\u0003@$FW\u0003\u0014\u001b\u001d\u0003WDNH\u0003NH\\FKDLQ\u0003\u0016\u0003IURP\u0003GUDZHU\u0003\u0017\u00032EV\u0003\u0014\u001b\u001d\u0003<RX\u0003SLFN\u0003XS\u0003WKH\u0003NH\\FKDLQ\u0003\u0016\u0003IURP\u0003WKH\u0003GUDZHU\u0003\u0017\u0011\u0003\u0011\u0011\u0011\u0011\u0011\u0011$FW\u0003\u0015\u0015\u001d\u0003SXW\u0003NH\\FKDLQ\u0003\u0016\u0003LQ\u0012RQ\u0003VDIH\u0003\u0014\u00032EV\u0003\u0015\u0015\u001d\u0003<RX\u0003SXW\u0003WKH\u0003NH\\FKDLQ\u0003\u0016\u0003LQ\u0012RQ\u0003WKH\u0003VDIH\u0003\u0014\u0011\u0003$FW\u0003\u0015\u0016\u001d\u00037KLQN\u0003>1RZ\u0003,\u0003SXW\u0003WKH\u0003ILUVW\u0003NH\\FKDLQ\u0003LQ\u0003VDIH\u0011\u00031H[W\u000f\u0003,\u0003QHHG\u0003WR\u0003ILQG\u0003WKH\u0003VHFRQG\u0003NH\\FKDLQ\u0011\u0003,\u0003FDQ\u0003GLUHFWO\\\u0003JR\u0003WR\u0003GUDZHU\u0003\u0017\u0011\u0003@$FW\u0003\u0015\u0017\u001d\u0003JR\u0003WR\u0003GUDZHU\u0003\u0017\u00032EV\u0003\u0015\u0017\u001d\u00037KH\u0003GUDZHU\u0003\u0017\u0003LV\u0003RSHQ\u0011\u0003,Q\u0003LW\u000f\u0003\\RX\u0003VHH\u0003D\u0003ZDWFK\u0003\u0015\u0011\u0003$FW\u0003\u0015\u0018\u001d\u00037KLQN\u0003>1RZ\u0003,\u0003ILQG\u0003WKH\u0003VHFRQG\u0003NH\\FKDLQ\u0003\u000b\u0015\f\u0011\u00031H[W\u000f\u0003,\u0003QHHG\u0003WR\u0003WDNH\u0003LW\u0011@$FW\u0003\u0015\u0019\u001d\u0003WDNH\u0003NH\\FKDLQ\u0003\u0015\u0003IURP\u0003GUDZHU\u0003\u0017\u00032EV\u0003\u0015\u0019\u001d\u00031RWKLQJ\u0003KDSSHQV\u0011\u000bE\f\u00035H$FW\u0003\u000b+XPDQ\u00037KRXJKW\u0003HGLW\f\u0011\u0011\u0011\u0011\u0011\u00112EV\u0003\u0014\u0019\u001d\u0003<RX\u0003RSHQ\u0003WKH\u0003GUDZHU\u0003\u0017\u0011\u00037KH\u0003GUDZHU\u0003\u0017\u0003LV\u0003RSHQ\u0011\u0003,Q\u0003LW\u000f\u0003\\RX\u0003VHH\u0003D\u0003NH\\FKDLQ\u0003\u0016\u000f\u0003DQG\u0003D\u0003ZDWFK\u0003\u0015\u0011\u0003$FW\u0003\u0014\u001a\u001d\u04557KLQN\u0455>1RZ\u0003,\u0003ILQG\u0003WKH\u0003ILUVW\u0003NH\\FKDLQ\u0003\u000b\u0016\f\u0011\u00031H[W\u000f\u0003,\u0003QHHG\u0003WR\u0003WDNH\u0003LW\u0011\u0003,\u0003FDQ\u0003ILQG\u0003WKH\u0003VHFRQG\u0003NH\\FKDLQ\u0003\u000b\u0015\f\u0003ODWHU\u0003LQ\u0003GUDZHU\u0003\u0017\u0011@$FW\u0003\u0014\u001b\u001d\u0003WDNH\u0003NH\\FKDLQ\u0003\u0016\u0003IURP\u0003GUDZHU\u0003\u0017\u00032EV\u0003\u0014\u001b\u001d\u0003<RX\u0003SLFN\u0003XS\u0003WKH\u0003NH\\FKDLQ\u0003\u0016\u0003IURP\u0003WKH\u0003GUDZHU\u0003\u0017\u0011\u0003\u0011\u0011\u0011\u0011\u0011\u0011$FW\u0003\u0015\u0015\u001d\u0003SXW\u0003NH\\FKDLQ\u0003\u0016\u0003LQ\u0012RQ\u0003VDIH\u0003\u0014\u00032EV\u0003\u0015\u0015\u001d\u0003<RX\u0003", "start_char_idx": 8, "end_char_idx": 1231, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "94db492c-82c1-475f-b794-d39935776411": {"__data__": {"id_": "94db492c-82c1-475f-b794-d39935776411", "embedding": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e1eead87-5cc0-4e45-8604-ff161f28436b", "node_type": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "hash": "72f9ff6da3cde3e1eb4d4a91497e186e570635b03785723afe0afbbe798fce30"}, "2": {"node_id": "46033e39-3299-49c0-92c3-155dd1f40bc4", "node_type": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "hash": "5a172f0668947301fec52eb0c4f78cb90ae43301b8f207d9374a0610ea368bbd"}, "3": {"node_id": "e32a3b9e-4ff8-408d-a65b-0294eae9a8a2", "node_type": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "hash": "6eea9e965f48a6f11d23043a8da298b6483363e8a99e3c8a67358843539b50ac"}}, "hash": "dbed0dca93d5964de914c0de7cc0f584ad11f15eb5a6b305a874ef1a4629498d", "text": "SXW\u0003WKH\u0003NH\\FKDLQ\u0003\u0016\u0003LQ\u0012RQ\u0003WKH\u0003VDIH\u0003\u0014\u0011\u0003$FW\u0003\u0015\u0016\u001d\u00037KLQN\u0455>1RZ\u0003,\u0003SXW\u0003WKH\u0003ILUVW\u0003NH\\FKDLQ\u0003LQ\u0003VDIH\u0011\u00031H[W\u000f\u0003,\u0003QHHG\u0003WR\u0003ILQG\u0003WKH\u0003VHFRQG\u0003NH\\FKDLQ\u000f\u0003ZKLFK\u0003LV\u0003PRUH\u0003OLNHO\\\u0003WR\u0003DSSHDU\u0003LQ\u0003GUHVVHU\u0003\u000b\u0014\f\u000f\u0003JDUEDJHFDQ\u0003\u000b\u0014\f\u000f\u0003VDIH\u0003\u000b\u0014\f\u000f\u0003VLGHWDEOH\u0003\u000b\u0014\f\u000f\u0003VRID\u0003\u000b\u0014\f\u000f\u0003VKHOI\u0003\u000b\u0014\u0010\u0014\u0015\f\u0011@$FW\u0003\u0015\u0017\u001d\u0003JR\u0003WR\u0003GUHVVHU\u0003\u0014\u00032EV\u0003\u0015\u0017\u001d\u00032Q\u0003WKH\u0003GUHVVHU\u0003\u0014\u000f\u0003\\RX\u0003VHH\u0003D\u0003ER[\u0003\u0014\u000f\u0003D\u0003FUHGLWFDUG\u0003\u0014\u000f\u0003D\u0003NH\\FKDLQ\u0003\u0015\u000f\u0003D\u0003NH\\FKDLQ\u0003\u0014\u000f\u0003D\u0003ODSWRS\u0003\u0014\u0011\u0011\u0011$FW\u0003\u0015\u0018\u001d\u00037KLQN\u0455>1RZ\u0003,\u0003ILQG\u0003WKH\u0003VHFRQG\u0003NH\\FKDLQ\u0003\u000b\u0015\f\u0011\u00031H[W\u000f\u0003,\u0003QHHG\u0003WR\u0003WDNH\u0003LW\u0011@$FW\u0003\u0015\u0019\u001d\u0003WDNH\u0003NH\\FKDLQ\u0003\u0015\u0003IURP\u0003GUHVVHU\u0003\u0014\u00032EV\u0003\u0015\u0019\u001d\u0003<RX\u0003SLFN\u0003XS\u0003WKH\u0003NH\\FKDLQ\u0003\u0015\u0003IURP\u0003WKH\u0003GUHVVHU\u0003\u0014\u0011\u0003$FW\u0003\u0015\u001a\u001d\u00037KLQN\u0455>1RZ\u0003,\u0003WDNH\u0003WKH\u0003VHFRQG\u0003NH\\FKDLQ\u0003\u000b\u0015\f\u0011\u00031H[W\u000f\u0003,\u0003QHHG\u0003WR\u0003SXW\u0003LW\u0003LQ\u0012RQ\u0003VDIH\u0003\u0014\u0011@$FW\u0003\u0015\u001b\u001d\u0003JR\u0003WR\u0003VDIH\u0003\u00142EV\u0003\u0015\u001b\u001d\u00037KH\u0003VDIH\u0003\u0014\u0003LV\u0003RSHQ\u0011\u0003,Q\u0003LW\u000f\u0003\\RX\u0003VHH\u0003D\u0003NH\\FKDLQ\u0003\u0016\u000f\u0003D\u0003VWDWXH\u0003\u0015\u000f\u0003DQG\u0003D\u0003ZDWFK\u0003\u0016\u0011$FW\u0003\u0015\u001c\u001d\u0003SXW\u0003NH\\FKDLQ\u0003\u0015\u0003LQ\u0012RQ\u0003VDIH\u0003\u00142EV\u0003\u0015\u001c\u001d\u0003<RX\u0003SXW\u0003WKH\u0003NH\\FKDLQ\u0003\u0015\u0003LQ\u0012RQ\u0003WKH\u0003VDIH\u0003\u0014\u0011\u04bc<RX\u0003DUH\u0003LQ\u0003WKH\u0003PLGGOH\u0003RI\u0003D\u0003URRP\u0011\u0003/RRNLQJ\u0003TXLFNO\\\u0003DURXQG\u0003\\RX\u000f\u0003\\RX\u0003VHH\u0003D\u0003DUPFKDLU\u0003\u0014\u000f\u0003D\u0003FDELQHW\u0003\u0017\u000f\u0003\u00aa\u0003D\u0003FDELQHW\u0003\u0014\u000f\u0003D\u0003GUDZHU\u0003\u0018\u000f\u0003\u00aa\u000f\u0003D\u0003GUDZHU\u0003\u0014\u000f\u0003D\u0003GUHVVHU\u0003\u0014\u000f\u0003D\u0003JDUEDJHFDQ\u0003\u0014\u000f\u0003D\u0003VDIH\u0003\u0014\u000f\u0003D\u0003VKHOI\u0003\u0014\u0015\u000f\u0003\u00aa\u000f\u0003D\u0003VKHOI\u0003\u0014\u000f\u0003D\u0003VLGHWDEOH\u0003\u0014\u000f\u0003DQG\u0003D\u0003VRID\u0003\u0014\u0011\u0003<RXU\u0003WDVN\u0003LV\u0003WR\u001d\u0003SXW\u0003WZR\u0003NH\\FKDLQ\u0003LQ\u0003VDIH\u0011$OI:RUOG Figure 5: A human-in-the-loop behavior correction example with ReAct in AlfWorld. (a) ReAct\ntrajectory fails due to a hallucinating thought (Act 17). (b) By a human simply editing two thoughts\n(Act 17, 23), the ReAct", "start_char_idx": 1269, "end_char_idx": 2581, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e32a3b9e-4ff8-408d-a65b-0294eae9a8a2": {"__data__": {"id_": "e32a3b9e-4ff8-408d-a65b-0294eae9a8a2", "embedding": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e1eead87-5cc0-4e45-8604-ff161f28436b", "node_type": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "hash": "72f9ff6da3cde3e1eb4d4a91497e186e570635b03785723afe0afbbe798fce30"}, "2": {"node_id": "94db492c-82c1-475f-b794-d39935776411", "node_type": null, "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}, "hash": "dbed0dca93d5964de914c0de7cc0f584ad11f15eb5a6b305a874ef1a4629498d"}}, "hash": "6eea9e965f48a6f11d23043a8da298b6483363e8a99e3c8a67358843539b50ac", "text": "By a human simply editing two thoughts\n(Act 17, 23), the ReAct trajectory produces desirable reasoning traces and actions and succeeds.\nis dif\ufb01cult for Act and previous RL methods, as a human cannot change the model parameters, and\nchanging a few actions might not edit the rest of the model behavior. This paradigm is also more than\nhuman dialogue to update the goal or subgoal as in Huang et al. (2022b) \u2014 while editing ReAct\nthoughts can do these, it can also modify the model\u2019s internal belief, reasoning styles, or anything the\n\ufb02exible thought space supports, for better task solving. We believe this is an exciting direction for\nhuman alignment and leave more systematic study as future work.\nB E XPERIMENT DETAILS\nB.1 H OTPOT QA F INETUNING DETAILS\nFor all \ufb01netuning we use a batch size of 64. On PaLM-8B, we \ufb01netune ReAct andAct methods\nfor4;000steps and Standard andCoT methods for 2;000steps. On PaLM-62B, we \ufb01netune\nReAct andAct methods for 4;000steps and Standard andCoT methods for 1;000steps. We\n\ufb01ndReAct andAct methods generally bene\ufb01t from more training steps (and more training data),\nwhile Standard andCoT methods degrade soon after \ufb01netuning.\nB.2 A LFWORLD IM-S TYLE DETAILS\nFor the IM-style ablation, the same expert trajectories used in ReAct are reannotated with dense\nexternal feedback thoughts within these trajectories, that limit ReAct-IM to only think about (1)\ndecomposing the current goal and (2) the current subgoal that needs to be completed. In particular,\nReAct-IM lacks thoughts that (1) determine when a subgoal is completed (2) determine what the\nnext subgoal should be (3) inducing the LLM to refer to its internal pretraining knowledge to identify\nwhere items can be within the environment.\n15", "start_char_idx": 2519, "end_char_idx": 4250, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5556c5fe-7bf4-451d-afb1-08ab0a2e5bf0": {"__data__": {"id_": "5556c5fe-7bf4-451d-afb1-08ab0a2e5bf0", "embedding": null, "metadata": {"page_label": "16", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1be368dc-8171-48d0-9f32-5df4b4621216", "node_type": null, "metadata": {"page_label": "16", "file_name": "2210.03629.pdf"}, "hash": "2a9bd0cf28cb085b7598c8d3b151b20de7830fcbb9443f6fbb64d42712b3cdd8"}}, "hash": "2a9bd0cf28cb085b7598c8d3b151b20de7830fcbb9443f6fbb64d42712b3cdd8", "text": "Published as a conference paper at ICLR 2023\nC P ROMPTS\nC.1 H OTPOT QA\nHotpot QA Prompts\nOrig inal\nQuestion What is the elevation range for the area that the eastern sector of the\nColorado orogeny extends into?\nAnswer 1,800 to 7,000 ft\nQuestion Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\ncharacter Milhouse, who Matt Groening named after who?\nAnswer Richard Nixon\nQuestion Which documentary is about Finnish rock groups, Adam Clayton Powell or The\nSaimaa Gesture?\nAnswer The Saimaa Gesture\nQuestion What profession does Nicholas Ray and Elia Kazan have in common?\nAnswer director, screenwriter, actor\nQuestion Which magazine was started first Arthur\u2019s Magazine or First for Women?\nAnswer Arthur\u2019s Magazine\nQuestion Were Pavel Urysohn and Leonid Levin known for the same type of work?\nAnswer Yes\nAct\nQuestion What is the elevation range for the area that the eastern sector of the\nColorado orogeny extends into?\nAction 1 Search[Colorado orogeny]\nObservation 1 The Colorado orogeny was an episode of mountain building (an orogeny) in\nColorado and surrounding areas.\nAction 2 Lookup[eastern sector]\nObservation 2 (Result 1 / 1) The eastern sector extends into the High Plains and is called\nthe Central Plains orogeny.\nAction 3 Search[High Plains]\nObservation 3 High Plains refers to one of two distinct land regions:\nAction 4 Search[High Plains (United States)]\nObservation 4 The High Plains are a subregion of the Great Plains. From east to west, the\nHigh Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130\nm).[3]\nAction 5 Finish[1,800 to 7,000 ft]\nQuestion Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\ncharacter Milhouse, who Matt Groening named after who?\nAction 1 Search[Milhouse]\nObservation 1 Milhouse Mussolini Van Houten is a recurring character in the Fox animated\ntelevision series The Simpsons voiced by Pamela Hayden and created by Matt\nGroening.\nAction 2 Lookup[named after]\nObservation 2 (Result 1 / 1) Milhouse was named after U.S. president Richard Nixon, whose\nmiddle name was Milhous.\nAction 3 Finish[Richard Nixon]\nQuestion Which documentary is about Finnish rock groups, Adam Clayton Powell or The\nSaimaa Gesture?\nAction 1 Search[Adam Clayton Powell]\nObservation 1 Could not find [Adam Clayton Powell]. Similar: [\u2019Adam Clayton Powell\nIII\u2019, \u2019Seventh Avenue (Manhattan)\u2019, \u2019Adam Clayton Powell Jr. State Office\nBuilding\u2019, \u2019Isabel Washington Powell\u2019, \u2019Adam Powell\u2019, \u2019Adam Clayton Powell\n(film)\u2019, \u2019Giancarlo Esposito\u2019].\nAction 2 Search[Adam Clayton Powell (film)]\nObservation 2 Adam Clayton Powell is a 1989 American documentary film directed by\nRichard Kilberg. The film is about the rise and fall of influential\nAfrican-American politician Adam Clayton Powell Jr.[3][4] It was later aired\nas part of the PBS series The American Experience.\nAction 3 Finish[The Saimaa Gesture]\nQuestion What profession does Nicholas Ray and Elia Kazan have in common?\nAction 1 Search[Nicholas Ray]\nObservation 1 Nicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16,\n1979) was an American film director, screenwriter, and actor best known for\nthe 1955 film Rebel Without a Cause.\nAction 2 Search[Elia Kazan]\nObservation 2 Elia Kazan was an American film and theatre director, producer, screenwriter\nand actor.\nContinued on next page\n16", "start_char_idx": 0, "end_char_idx": 3327, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7ffc471a-ff29-4dc5-bc87-5414f017c679": {"__data__": {"id_": "7ffc471a-ff29-4dc5-bc87-5414f017c679", "embedding": null, "metadata": {"page_label": "17", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9fafd1cc-5dec-484e-80de-d76f4f032286", "node_type": null, "metadata": {"page_label": "17", "file_name": "2210.03629.pdf"}, "hash": "855608d882c70d799ade64e301c33ea89540d3b6ffc870ff48d9072d1fcf2db0"}, "3": {"node_id": "bb254241-ad3c-4e10-9538-f1079529729c", "node_type": null, "metadata": {"page_label": "17", "file_name": "2210.03629.pdf"}, "hash": "f42c7ae2606dda677ffaa50d67598411560c0571b406bad4d62674f516cd7114"}}, "hash": "d87de81ae30e3916985cd60b7fdebfac3c2e0563751ee031c3079770ac7dfb02", "text": "Published as a conference paper at ICLR 2023\nHotpot QA Prompts \u2013 Continued from previous page\nAction 3 Finish[director, screenwriter, actor]\nQuestion Which magazine was started first Arthur\u2019s Magazine or First for Women?\nAction 1 Search[Arthur\u2019s Magazine]\nObservation 1 Arthur\u2019s Magazine (1844-1846) was an American literary periodical published\nin Philadelphia in the 19th century.\nAction 2 Search[First for Women]\nObservation 2 First for Women is a woman\u2019s magazine published by Bauer Media Group in the\nUSA.[1] The magazine was started in 1989.\nAction 3 Finish[Arthur\u2019s Magazine]\nQuestion Were Pavel Urysohn and Leonid Levin known for the same type of work?\nAction 1 Search[Pavel Urysohn]\nObservation 1 Pavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet\nmathematician who is best known for his contributions in dimension theory.\nAction 2 Search[Leonid Levin]\nObservation 2 Leonid Anatolievich Levin is a Soviet-American mathematician and computer\nscientist.\nAction 3 Finish[yes]\nCoT\nQuestion What is the elevation range for the area that the eastern sector of the\nColorado orogeny extends into?\nThought Let\u2019s think step by step. The eastern sector of Colorado orogeny extends\ninto the High Plains. High Plains rise in elevation from around 1,800 to\n7,000 ft, so the answer is 1,800 to 7,000 ft.\nAnswer 1,800 to 7,000 ft\nQuestion Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\ncharacter Milhouse, who Matt Groening named after who?\nThought Let\u2019s think step by step. Milhouse was named after U.S. president Richard\nNixon, so the answer is Richard Nixon.\nAnswer Richard Nixon\nQuestion Which documentary is about Finnish rock groups, Adam Clayton Powell or The\nSaimaa Gesture?\nThought Let\u2019s think step by step. Adam Clayton Powell (film) is a documentary about\nan African-American politician, not Finnish rock groups. So the documentary\nabout Finnish rock groups must instead be The Saimaa Gesture.\nAnswer The Saimaa Gesture\nQuestion What profession does Nicholas Ray and Elia Kazan have in common?\nThought Let\u2019s think step by step. Professions of Nicholas Ray are director,\nscreenwriter, and actor. Professions of Elia Kazan are director, producer,\nscreenwriter, and actor. So profession Nicholas Ray and Elia Kazan have in\ncommon is director, screenwriter, and actor.\nAnswer director, screenwriter, actor\nQuestion Which magazine was started first Arthur\u2019s Magazine or First for Women?\nThought Let\u2019s think step by step. Arthur\u2019s Magazine was started in 1844. First\nfor Women was started in 1989. 1844 (Arthur\u2019s Magazine) < 1989 (First for\nWomen), so Arthur\u2019s Magazine was started first.\nAnswer Arthur\u2019s Magazine\nQuestion Were Pavel Urysohn and Leonid Levin known for the same type of work?\nThought Let\u2019s think step by step. Pavel Urysohn is a mathematician. Leonid Levin\nis a mathematician and computer scientist. So Pavel Urysohn and Leonid\nLevin have the same type of work.\nAnswer Yes\nReAct\nQuestion What is the elevation range for the area that the eastern sector of the\nColorado orogeny extends into?\nThought 1 I need to search Colorado orogeny, find the area that the eastern sector\nof the Colorado orogeny extends into, then find the elevation range of the\narea.\nAction 1 Search[Colorado orogeny]\nObservation 1 The Colorado orogeny was an episode of mountain building (an orogeny) in\nColorado and surrounding areas.\nThought 2 It does not mention the eastern sector. So I need to look up eastern\nsector.\nAction 2 Lookup[eastern sector]\nObservation 2 (Result 1 / 1) The eastern sector extends into the High Plains and", "start_char_idx": 0, "end_char_idx": 3572, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "bb254241-ad3c-4e10-9538-f1079529729c": {"__data__": {"id_": "bb254241-ad3c-4e10-9538-f1079529729c", "embedding": null, "metadata": {"page_label": "17", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9fafd1cc-5dec-484e-80de-d76f4f032286", "node_type": null, "metadata": {"page_label": "17", "file_name": "2210.03629.pdf"}, "hash": "855608d882c70d799ade64e301c33ea89540d3b6ffc870ff48d9072d1fcf2db0"}, "2": {"node_id": "7ffc471a-ff29-4dc5-bc87-5414f017c679", "node_type": null, "metadata": {"page_label": "17", "file_name": "2210.03629.pdf"}, "hash": "d87de81ae30e3916985cd60b7fdebfac3c2e0563751ee031c3079770ac7dfb02"}}, "hash": "f42c7ae2606dda677ffaa50d67598411560c0571b406bad4d62674f516cd7114", "text": "2 (Result 1 / 1) The eastern sector extends into the High Plains and is called\nthe Central Plains orogeny.\nThought 3 The eastern sector of Colorado orogeny extends into the High Plains. So I\nneed to search High Plains and find its elevation range.\nAction 3 Search[High Plains]\nObservation 3 High Plains refers to one of two distinct land regions\nThought 4 I need to instead search High Plains (United States).\nAction 4 Search[High Plains (United States)]\nContinued on next page\n17", "start_char_idx": 3504, "end_char_idx": 3984, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "84ce8a0b-a1d9-48af-b48b-9ffde148b56d": {"__data__": {"id_": "84ce8a0b-a1d9-48af-b48b-9ffde148b56d", "embedding": null, "metadata": {"page_label": "18", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ed35cb3c-7cc2-4ebe-b442-cc76a3597c09", "node_type": null, "metadata": {"page_label": "18", "file_name": "2210.03629.pdf"}, "hash": "f60939c21d82eb5f9626db8c76c03ae577cb160a370e26d6ce2b810d4caae7bd"}, "3": {"node_id": "230db994-13d4-4703-8389-15e8977abd76", "node_type": null, "metadata": {"page_label": "18", "file_name": "2210.03629.pdf"}, "hash": "3e3d6dc00762ad3073651a60c6616e8a3eeadb0d83330667c46c540024648f76"}}, "hash": "c96f490ff0490b1c295a0627bc6894f679ad084e4ddf97c5d22bf329d4110e6e", "text": "Published as a conference paper at ICLR 2023\nHotpot QA Prompts \u2013 Continued from previous page\nObservation 4 The High Plains are a subregion of the Great Plains. From east to west, the\nHigh Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130\nm).[3]\nThought 5 High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer\nis 1,800 to 7,000 ft.\nAction 5 Finish[1,800 to 7,000 ft]\nQuestion Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\"\ncharacter Milhouse, who Matt Groening named after who?\nThought 1 The question simplifies to \"The Simpsons\" character Milhouse is named after\nwho. I only need to search Milhouse and find who it is named after.\nAction 1 Search[Milhouse]\nObservation 1 Milhouse Mussolini Van Houten is a recurring character in the Fox animated\ntelevision series The Simpsons voiced by Pamela Hayden and created by Matt\nGroening.\nThought 2 The paragraph does not tell who Milhouse is named after, maybe I can look up\n\"named after\".\nAction 2 Lookup[named after]\nObservation 2 (Result 1 / 1) Milhouse was named after U.S. president Richard Nixon, whose\nmiddle name was Milhous.\nThought 3 Milhouse was named after U.S. president Richard Nixon, so the answer is\nRichard Nixon.\nAction 3 Finish[Richard Nixon]\nQuestion Which documentary is about Finnish rock groups, Adam Clayton Powell or The\nSaimaa Gesture?\nThought 1 I need to search Adam Clayton Powell and The Saimaa Gesture, and find which\ndocumentary is about Finnish rock groups.\nAction 1 Search[Adam Clayton Powell]\nObservation 1 Could not find [Adam Clayton Powell]. Similar: [\u2019Adam Clayton Powell\nIII\u2019, \u2019Seventh Avenue (Manhattan)\u2019, \u2019Adam Clayton Powell Jr. State Office\nBuilding\u2019, \u2019Isabel Washington Powell\u2019, \u2019Adam Powell\u2019, \u2019Adam Clayton Powell\n(film)\u2019, \u2019Giancarlo Esposito\u2019].\nThought 2 To find the documentary, I can search Adam Clayton Powell (film).\nAction 2 Search[Adam Clayton Powell (film)]\nObservation 2 Adam Clayton Powell is a 1989 American documentary film directed by\nRichard Kilberg. The film is about the rise and fall of influential\nAfrican-American politician Adam Clayton Powell Jr.[3][4] It was later aired\nas part of the PBS series The American Experience.\nThought 3 Adam Clayton Powell (film) is a documentary about an African-American\npolitician, not Finnish rock groups. So the documentary about Finnish rock\ngroups must instead be The Saimaa Gesture.\nAction 3 Finish[The Saimaa Gesture]\nQuestion What profession does Nicholas Ray and Elia Kazan have in common?\nThought 1 I need to search Nicholas Ray and Elia Kazan, find their professions, then\nfind the profession they have in common.\nAction 1 Search[Nicholas Ray]\nObservation 1 Nicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16,\n1979) was an American film director, screenwriter, and actor best known for\nthe 1955 film Rebel Without a Cause.\nThought 2 Professions of Nicholas Ray are director, screenwriter, and actor. I need\nto search Elia Kazan next and find his professions.\nAction 2 Search[Elia Kazan]\nObservation 2 Elia Kazan was an American film and theatre director, producer, screenwriter\nand actor.\nThought 3 Professions of Elia Kazan are director, producer, screenwriter, and actor.\nSo profession Nicholas Ray and Elia Kazan have in common is director,\nscreenwriter, and actor.\nAction 3 Finish[director, screenwriter, actor]\nQuestion Which magazine was started first Arthur\u2019s Magazine or First for Women?\nThought 1 I need to search", "start_char_idx": 0, "end_char_idx": 3464, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "230db994-13d4-4703-8389-15e8977abd76": {"__data__": {"id_": "230db994-13d4-4703-8389-15e8977abd76", "embedding": null, "metadata": {"page_label": "18", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ed35cb3c-7cc2-4ebe-b442-cc76a3597c09", "node_type": null, "metadata": {"page_label": "18", "file_name": "2210.03629.pdf"}, "hash": "f60939c21d82eb5f9626db8c76c03ae577cb160a370e26d6ce2b810d4caae7bd"}, "2": {"node_id": "84ce8a0b-a1d9-48af-b48b-9ffde148b56d", "node_type": null, "metadata": {"page_label": "18", "file_name": "2210.03629.pdf"}, "hash": "c96f490ff0490b1c295a0627bc6894f679ad084e4ddf97c5d22bf329d4110e6e"}}, "hash": "3e3d6dc00762ad3073651a60c6616e8a3eeadb0d83330667c46c540024648f76", "text": "started first Arthur\u2019s Magazine or First for Women?\nThought 1 I need to search Arthur\u2019s Magazine and First for Women, and find which was\nstarted first.\nAction 1 Search[Arthur\u2019s Magazine]\nObservation 1 Arthur\u2019s Magazine (1844-1846) was an American literary periodical published\nin Philadelphia in the 19th century.\nThought 2 Arthur\u2019s Magazine was started in 1844. I need to search First for Women\nnext.\nAction 2 Search[First for Women]\nObservation 2 First for Women is a woman\u2019s magazine published by Bauer Media Group in the\nUSA.[1] The magazine was started in 1989.\nThought 3 First for Women was started in 1989. 1844 (Arthur\u2019s Magazine) < 1989 (First\nfor Women), so Arthur\u2019s Magazine was started first.\nAction 3 Finish[Arthur\u2019s Magazine]\nQuestion Were Pavel Urysohn and Leonid Levin known for the same type of work?\nThought 1 I need to search Pavel Urysohn and Leonid Levin, find their types of work,\nthen find if they are the same.\nAction 1 Search[Pavel Urysohn]\nContinued on next page\n18", "start_char_idx": 3386, "end_char_idx": 4377, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1a7875d2-4f14-4337-b1d8-5b9f22c234a4": {"__data__": {"id_": "1a7875d2-4f14-4337-b1d8-5b9f22c234a4", "embedding": null, "metadata": {"page_label": "19", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "96e89d07-6776-4a2b-8f25-1495a5d3d9bd", "node_type": null, "metadata": {"page_label": "19", "file_name": "2210.03629.pdf"}, "hash": "af8c0b9c1f8dbb19b1790db01aa80133671d153bbeda5a55e68ad7c73b886dda"}}, "hash": "af8c0b9c1f8dbb19b1790db01aa80133671d153bbeda5a55e68ad7c73b886dda", "text": "Published as a conference paper at ICLR 2023\nHotpot QA Prompts \u2013 Continued from previous page\nObservation 1 Pavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet\nmathematician who is best known for his contributions in dimension theory.\nThought 2 Pavel Urysohn is a mathematician. I need to search Leonid Levin next and\nfind its type of work.\nAction 2 Search[Leonid Levin]\nObservation 2 Leonid Anatolievich Levin is a Soviet-American mathematician and computer\nscientist.\nThought 3 Leonid Levin is a mathematician and computer scientist. So Pavel Urysohn\nand Leonid Levin have the same type of work.\nAction 3 Finish[yes]\n19", "start_char_idx": 0, "end_char_idx": 645, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d5eaa846-da0c-4ca1-b0bc-a43ec8be473b": {"__data__": {"id_": "d5eaa846-da0c-4ca1-b0bc-a43ec8be473b", "embedding": null, "metadata": {"page_label": "20", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "37742a01-b463-4f05-a75f-69ffff56c3c8", "node_type": null, "metadata": {"page_label": "20", "file_name": "2210.03629.pdf"}, "hash": "cdf14a262d87a9607fc4c17fad43634a8e5928c58e4ee864724b51e6dee53db2"}}, "hash": "cdf14a262d87a9607fc4c17fad43634a8e5928c58e4ee864724b51e6dee53db2", "text": "Published as a conference paper at ICLR 2023\nC.2 F EVER\nFEVER Prompts\nOrig inal Determine if there is Observation that SUPPORTS or REFUTES a Claim, or if\nthere is NOT ENOUGH INFORMATION.\nClaim Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\nAnswer SUPPORTS\nClaim Stranger Things is set in Bloomington, Indiana.\nAnswer REFUTES\nClaim Beautiful reached number two on the Billboard Hot 100 in 2003.\nAnswer NOT ENOUGH INFO\nAct Determine if there is Observation that SUPPORTS or REFUTES a Claim, or if\nthere is NOT ENOUGH INFORMATION.\nClaim Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\nAction2 Search[Nikolaj Coster-Waldau]\nObservation 1 Nikolaj William Coster-Waldau (born 27 July 1970) is a Danish actor and\nproducer. He graduated from the Danish National School of Performing Arts\nin Copenhagen in 1993,[1] and had his breakthrough role in Denmark with\nthe film Nightwatch (1994). He played Jaime Lannister in the HBO fantasy\ndrama series Game of Thrones, for which he received two Primetime Emmy\nAward nominations for Outstanding Supporting Actor in a Drama Series..\nCoster-Waldau has appeared in numerous films in his native Denmark and\nScandinavia, including Headhunters (2011) and A Thousand Times Good Night\n(2013). In the U.S, his debut film role was in the war film Black Hawk Down\n(2001), playing Medal of Honor recipient Gary Gordon.[2] He then played a\ndetective in the short-lived Fox television series New Amsterdam (2008), and\nappeared in the 2009 Fox television film Virtuality, originally intended as\na pilot.\nAction 2 Finish[SUPPORTS]\nClaim Stranger Things is set in Bloomington, Indiana.\nAction 1 Search[Stranger Things]\nObservation 1 Stranger Things is an American science fiction horror drama television\nseries created by the Duffer Brothers. Set in the 1980s, primarily in\nthe fictional town of Hawkins, Indiana, the series centers on a number of\nmysteries and supernatural events occurring around the town and their impact\non an ensemble of child and adult characters.\nAction 2 Finish[REFUTES]\nClaim Beautiful reached number two on the Billboard Hot 100 in 2003.\nAction 1 Search[Beautiful]\nObservation 1 Could not find [Beautiful]. Similar: [\u2019Beautiful\u2019, \u2019Beautiful, Beautiful\u2019,\n\u2019A Beautiful Mind (film)\u2019, \u2019Beautiful (Christina Aguilera song)\u2019, \u2019Life Is\nBeautiful\u2019].\nAction 2 Search[Beautiful (Christina Aguilera song)\nObservation 2 \"Beautiful\" is a song recorded by American singer Christina Aguilera for her\nfourth studio album, Stripped (2002).\nAction 3 Lookup[Billboard Hot 100]\nObservation 3 (Result 1 / 3) The song peaked at number two on the Billboard Hot 100 in the\nUnited States, where it was certified Gold for 500,000 units shipped.\nAction 4 Finish[NOT ENOUGH INFO]\nCoT Determine if there is Observation that SUPPORTS or REFUTES a Claim, or if\nthere is NOT ENOUGH INFORMATION.\nClaim Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\nThought Nikolaj William Coster-Waldau appeared in the 2009 Fox television film\nVirtuality, so he has worked with the Fox Broadcasting Company.\nAnswer SUPPORTS\nClaim Stranger Things is set in Bloomington, Indiana.\nThought Stranger Things is in the fictional town of Hawkins, Indiana, not in\nBloomington, Indiana.\nAnswer REFUTES\nContinued on next page\n20", "start_char_idx": 0, "end_char_idx": 3263, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "97f94ff1-4d90-401e-950f-abd9f8964468": {"__data__": {"id_": "97f94ff1-4d90-401e-950f-abd9f8964468", "embedding": null, "metadata": {"page_label": "21", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "13c5b288-b69c-4a12-98d0-2184704a8ffa", "node_type": null, "metadata": {"page_label": "21", "file_name": "2210.03629.pdf"}, "hash": "c893e0a828d51d539489b307a61e5aef77015e636e010ce4b5d9b23a74ffb955"}}, "hash": "c893e0a828d51d539489b307a61e5aef77015e636e010ce4b5d9b23a74ffb955", "text": "Published as a conference paper at ICLR 2023\nFever Prompts \u2013 Continued from previous page\nClaim Beautiful reached number two on the Billboard Hot 100 in 2003.\nThought The song peaked at number two on the Billboard Hot 100 in the United States,\nbut not sure if it was in 2003.\nAnswer NOT ENOUGH INFO\nReAct Determine if there is Observation that SUPPORTS or REFUTES a Claim, or if\nthere is NOT ENOUGH INFORMATION.\nClaim Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\nThought 1 I need to search Nikolaj Coster-Waldau and find if he has worked with the\nFox Broadcasting Company.\nAction 1 Search[Nikolaj Coster-Waldau]\nObservation 1 Nikolaj William Coster-Waldau (born 27 July 1970) is a Danish actor and\nproducer. He graduated from the Danish National School of Performing Arts\nin Copenhagen in 1993,[1] and had his breakthrough role in Denmark with\nthe film Nightwatch (1994). He played Jaime Lannister in the HBO fantasy\ndrama series Game of Thrones, for which he received two Primetime Emmy\nAward nominations for Outstanding Supporting Actor in a Drama Series..\nCoster-Waldau has appeared in numerous films in his native Denmark and\nScandinavia, including Headhunters (2011) and A Thousand Times Good Night\n(2013). In the U.S, his debut film role was in the war film Black Hawk Down\n(2001), playing Medal of Honor recipient Gary Gordon.[2] He then played a\ndetective in the short-lived Fox television series New Amsterdam (2008), and\nappeared in the 2009 Fox television film Virtuality, originally intended as\na pilot.\nThought 2 Because he \"appeared in the 2009 Fox television film Virtuality\", he should\nhave worked with the Fox Broadcasting Company.\nAction 2 Finish[SUPPORTS]\nClaim Stranger Things is set in Bloomington, Indiana.\nThought 1 I should search for Stranger Things, and see if it is set in Bloomington,\nIndiana.\nAction 1 Search[Stranger Things]\nObservation 1 Stranger Things is an American science fiction horror drama television\nseries created by the Duffer Brothers. Set in the 1980s, primarily in\nthe fictional town of Hawkins, Indiana, the series centers on a number of\nmysteries and supernatural events occurring around the town and their impact\non an ensemble of child and adult characters.\nThought 2 The observation says that it is set in a \"fictional town of Hawkins,\nIndiana\", so it is not set in Bloomington.\nAction 2 Finish[REFUTES]\nClaim Beautiful reached number two on the Billboard Hot 100 in 2003.\nThought 1 I need to search the song Beautiful and find if it reached number two on the\nBillboard Hot 100 in 2003.\nAction 1 Search[Beautiful]\nObservation 1 Could not find [Beautiful]. Similar: [\u2019Beautiful\u2019, \u2019Beautiful, Beautiful\u2019,\n\u2019A Beautiful Mind (film)\u2019, \u2019Beautiful (Christina Aguilera song)\u2019, \u2019Life Is\nBeautiful\u2019].\nThought 2 From suggestions, I should search \"Beautiful (Christina Aguilera song)\" to\nfind the song.\nAction 2 Search[Beautiful (Christina Aguilera song)]\nObservation 2 \"Beautiful\" is a song recorded by American singer Christina Aguilera for her\nfourth studio album, Stripped (2002).\nThought 3 It does not mention Billboard, so I need to look up \"Billboard Hot 100\" to\nfind if it reached number two on it in 2003.\nAction 3 Lookup[Billboard Hot 100]\nObservation 3 (Result 1 / 3) The song peaked at number two on the Billboard Hot 100 in the\nUnited States, where it was certified Gold for 500,000 units shipped.\nThought 4 It only says the song peaked at number two on the Billboard Hot 100, but not\nif it was in 2003. I am not sure if this claim is true or not.\nAction 4 Finish[NOT ENOUGH INFO]\n21", "start_char_idx": 0, "end_char_idx": 3553, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "cd9da190-03cb-4f21-8692-b74130ddb1d8": {"__data__": {"id_": "cd9da190-03cb-4f21-8692-b74130ddb1d8", "embedding": null, "metadata": {"page_label": "22", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "771fd1a7-aba3-4cd8-a469-479d8e06d5b0", "node_type": null, "metadata": {"page_label": "22", "file_name": "2210.03629.pdf"}, "hash": "783c81ed06b496f597c7e44e198a7aeb780bc1dc0d38e53f734752f4031cfd50"}, "3": {"node_id": "baa7cd62-fa8d-44d4-becf-5e21b28227c8", "node_type": null, "metadata": {"page_label": "22", "file_name": "2210.03629.pdf"}, "hash": "658649d9c82358d42a7f0270b079416e4d7c05e9354e5db6380fc5ead0388947"}}, "hash": "8934caf9a1ed4125528cfd497f9e0574b2ea8193d79a00352c36346a4a743329", "text": "Published as a conference paper at ICLR 2023\nC.3 W EBSHOP\nTable 6: Prompts used for the Webshop experiments in Section 4. We use the prompt on the left for\nAct, and use the prompt on the right (add reasoning) for ReAct .\nInstruction : i would like a 3 ounce bottle of bright citrus deodorant for sensitive skin, and price lower than 50.00 dollars\nAct ReAct\nAction :search\u0002\n3 ounce bright citrus deodorant sensitive skin\u0003\nObservation:\u0002\nBack to Search\u0003\nPage 1 (Total results: 50)\u0002\nNext\u0003\n\u0002\nB078GWRC1J\u0003\nBright Citrus Deodorant by Earth Mama | Natural and Safe for\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\nCalendula 3-Ounce\n$10.99\u0002\nB078GTKVXY\u0003\nGinger Fresh Deodorant by Earth Mama | Natural and Safe for\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\nCalendula 3-Ounce\n$10.99\u0002\nB08KBVJ4XN\u0003\nBarrel and Oak - Aluminum-Free Deodorant, Deodorant for Men\n, Essential Oil-Based Scent, 24-Hour Odor Protection, Cedar\n& Patchouli Blend, Gentle on Sensitive Skin (Mountain Sage,\n2.7 oz, 2-Pack)\n$15.95\nAction :click\u0002\nB078GWRC1J\u0003\nObservation :\u0002\nBack to Search\u0003\n\u0002\nPrev\u0003\nscent [assorted scents][bright citrus][calming lavender][ginger\n[fresh] simply non-scents]\nsize [travel set (4-pack)][3 ounce (pack of 1)][3-ounce (2\n-pack)]\nBright Citrus Deodorant by Earth Mama | Natural and Safe for\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\nCalendula 3-Ounce\nPrice: $10.99\nRating: N.A.\n[Description]\n[Features]\n[Reviews]\n[Buy Now]\nAction :click [bright citrus]\nObservation : You have clicked bright citrus.\nAction :click [3 ounce (pack of 1)]\nObservation : You have clicked 3 ounce (pack of 1).\nAction :click [Buy Now]Action :search\u0002\n3 ounce bright citrus deodorant sensitive skin\nObservation:\u0002\nBack to Search\u0003\nPage 1 (Total results: 50)\u0002\nNext\u0003\n\u0002\nB078GWRC1J\u0003\nBright Citrus Deodorant by Earth Mama | Natural and Safe for\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\nCalendula 3-Ounce\n$10.99\u0002\nB078GTKVXY\u0003\nGinger Fresh Deodorant by Earth Mama | Natural and Safe for\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\nCalendula 3-Ounce\n$10.99\u0002\nB08KBVJ4XN\u0003\nBarrel and Oak - Aluminum-Free Deodorant, Deodorant for Men\n, Essential Oil-Based Scent, 24-Hour Odor Protection, Cedar\n& Patchouli Blend, Gentle on Sensitive Skin (Mountain Sage,\n2.7 oz, 2-Pack)\n$15.95\nAction :think [B078GWRC1J and B078GTKVXY are bright citrus\ndeodorant less then 50 dollars. I can check B078GWRC1J \ufb01rst.\nObservation : OK.\nAction :click\u0002\nB078GWRC1J\u0003\nObservation :\u0002\nBack to Search\u0003\n\u0002\nPrev\u0003\nscent [assorted scents][bright citrus][calming lavender][ginger\n[fresh] simply non-scents]\nsize [travel set (4-pack)][3 ounce (pack of 1)][3-ounce (2\n-pack)]\nBright Citrus Deodorant by Earth Mama | Natural and Safe for\nSensitive Skin, Pregnancy and Breastfeeding, Contains Organic\nCalendula 3-Ounce\nPrice: $10.99\nRating:", "start_char_idx": 0, "end_char_idx": 2836, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "baa7cd62-fa8d-44d4-becf-5e21b28227c8": {"__data__": {"id_": "baa7cd62-fa8d-44d4-becf-5e21b28227c8", "embedding": null, "metadata": {"page_label": "22", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "771fd1a7-aba3-4cd8-a469-479d8e06d5b0", "node_type": null, "metadata": {"page_label": "22", "file_name": "2210.03629.pdf"}, "hash": "783c81ed06b496f597c7e44e198a7aeb780bc1dc0d38e53f734752f4031cfd50"}, "2": {"node_id": "cd9da190-03cb-4f21-8692-b74130ddb1d8", "node_type": null, "metadata": {"page_label": "22", "file_name": "2210.03629.pdf"}, "hash": "8934caf9a1ed4125528cfd497f9e0574b2ea8193d79a00352c36346a4a743329"}}, "hash": "658649d9c82358d42a7f0270b079416e4d7c05e9354e5db6380fc5ead0388947", "text": "3-Ounce\nPrice: $10.99\nRating: N.A.\n[Description]\n[Features]\n[Reviews]\n[Buy Now]\nAction :think [For 3 ounce bottle of bright citrus deodorant\nfor sensitive skin, the item has options \u2019bright citrus\u2019\nand \u20193 ounce (pack of 1)\u2019 and seems good to buy.]\nObservation : OK.\nAction :click [bright citrus]\nObservation : You have clicked bright citrus.\nAction :click [3 ounce (pack of 1)]\nObservation : You have clicked 3 ounce (pack of 1).\nAction :click [Buy Now]\n22", "start_char_idx": 2807, "end_char_idx": 3263, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "790d2455-bfcb-4ef0-8fe5-749e944aca72": {"__data__": {"id_": "790d2455-bfcb-4ef0-8fe5-749e944aca72", "embedding": null, "metadata": {"page_label": "23", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "874bcad2-0af1-4d4d-bb73-de0a9f650877", "node_type": null, "metadata": {"page_label": "23", "file_name": "2210.03629.pdf"}, "hash": "861d4d17eb09391d4aa5f0afff04a40348f6e0c0c6245cef165816ff2e74bc51"}}, "hash": "861d4d17eb09391d4aa5f0afff04a40348f6e0c0c6245cef165816ff2e74bc51", "text": "Published as a conference paper at ICLR 2023\nC.4 ALFW ORLD\nTable 7: An Act prompt on the ALFWorld clean task. No thoughts are provided.\nYou are in the middle of a room. Looking quickly around you, you see a cabinet\n13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet\n7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet\n1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a\ngarbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a\nstoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\nYour task is to: put a clean lettuce in diningtable.\n>go to fridge 1\nThe fridge 1 is closed.\n>open fridge 1\nYou open the fridge 1. The fridge 1 is open. In it, you see a cup 3, a egg 2, a\npotato 3, and a potato 2.\n>go to diningtable 1\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a\nfork 2, a knife 2, a knife 1, a ladle 1, a lettuce 1, a mug 2, a mug 1, a pan 2, a\npeppershaker 1, a spatula 3, a tomato 2, and a tomato 1.\n>take lettuce 1 from diningtable 1\nYou pick up the lettuce 1 from the diningtable 1.\n>go to sinkbasin 1\nOn the sinkbasin 1, you see a apple 2, a ladle 2, a spoon 1, and a tomato 3.\n>clean lettuce 1 with sinkbasin 1\nYou clean the lettuce 1 using the sinkbasin 1.\n>think: Now I clean a lettuce (1). Next, I need to put it in/on diningtable 1.\nOK.\n>go to diningtable 1\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a fork\n2, a knife 2, a knife 1, a ladle 1, a mug 2, a mug 1, a pan 2, a peppershaker 1, a\nspatula 3, a tomato 2, and a tomato 1.\n>put lettuce 1 in/on diningtable 1\nYou put the lettuce 1 in/on the diningtable 1.\n23", "start_char_idx": 0, "end_char_idx": 1730, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ee452ccc-e4e6-459f-af91-2f027131de88": {"__data__": {"id_": "ee452ccc-e4e6-459f-af91-2f027131de88", "embedding": null, "metadata": {"page_label": "24", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8bc292b3-b332-4641-a20a-4165264e75cd", "node_type": null, "metadata": {"page_label": "24", "file_name": "2210.03629.pdf"}, "hash": "993d9c2aa9bb68cc39081426dc87dba98db27171b71d60840009c6181d03a5c5"}}, "hash": "993d9c2aa9bb68cc39081426dc87dba98db27171b71d60840009c6181d03a5c5", "text": "Published as a conference paper at ICLR 2023\nTable 8: An ReAct prompt on the ALFWorld clean task.\nYou are in the middle of a room. Looking quickly around you, you see a cabinet\n13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet\n7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet\n1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a\ngarbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a\nstoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\nYour task is to: put a clean lettuce in diningtable.\n> think: To solve the task, I need to find and take a lettuce, then clean it with\nsinkbasin, then put it in diningtable.\nOK.\n> think: First I need to find a lettuce. A lettuce is more likely to appear in\nfridge (1), diningtable (1), sinkbasin (1), stoveburner (1-3), cabinet (1-13). I\ncan check one by one, starting with fridge 1.\nOK.\n> go to fridge 1\nThe fridge 1 is closed.\n> open fridge 1\nYou open the fridge 1. The fridge 1 is open. In it, you see a cup 3, a egg 2, a\npotato 3, and a potato 2.\n> go to diningtable 1\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a\nfork 2, a knife 2, a knife 1, a ladle 1, a lettuce 1, a mug 2, a mug 1, a pan 2, a\npeppershaker 1, a spatula 3, a tomato 2, and a tomato 1.\n> think: Now I find a lettuce (1). Next, I need to take it.\nOK.\n> take lettuce 1 from diningtable 1\nYou pick up the lettuce 1 from the diningtable 1.\n> think: Now I take a lettuce (1). Next, I need to go to sinkbasin (1) and clean\nit.\nOK.\n> go to sinkbasin 1\nOn the sinkbasin 1, you see a apple 2, a ladle 2, a spoon 1, and a tomato 3.\n> clean lettuce 1 with sinkbasin 1\nYou clean the lettuce 1 using the sinkbasin 1.\n> think: Now I clean a lettuce (1). Next, I need to put it in/on diningtable 1.\nOK.\n> go to diningtable 1\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a fork\n2, a knife 2, a knife 1, a ladle 1, a mug 2, a mug 1, a pan 2, a peppershaker 1, a\nspatula 3, a tomato 2, and a tomato 1.\n> put lettuce 1 in/on diningtable 1\nYou put the lettuce 1 in/on the diningtable 1.\n24", "start_char_idx": 0, "end_char_idx": 2189, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d2cc267d-0857-4b85-8424-7f72dfcc921c": {"__data__": {"id_": "d2cc267d-0857-4b85-8424-7f72dfcc921c", "embedding": null, "metadata": {"page_label": "25", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9e776274-16bd-4c03-be9e-06951fdd6840", "node_type": null, "metadata": {"page_label": "25", "file_name": "2210.03629.pdf"}, "hash": "f28997ab8ddd35174b3fdc9375d7bdb35fc7ad49682a453486810f0c80eaf341"}}, "hash": "f28997ab8ddd35174b3fdc9375d7bdb35fc7ad49682a453486810f0c80eaf341", "text": "Published as a conference paper at ICLR 2023\nTable 9: An ReAct-IM prompt on the ALFWorld clean task.\nYou are in the middle of a room. Looking quickly around you, you see a cabinet\n13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet\n7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet\n1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a\ngarbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a\nstoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\nYour task is to: put a clean lettuce in diningtable.\n> think: To solve the task, I need to find and take a lettuce, then clean it with\nsinkbasin, then put it in diningtable.\nOK.\n> think: First I need to find a lettuce.\nOK.\n> go to fridge 1\nThe fridge 1 is closed.\n> think: First I need to find a lettuce.\nOK.\n> open fridge 1\nYou open the fridge 1. The fridge 1 is open. In it, you see a cup 3, a egg 2, a\npotato 3, and a potato 2.\n> think: First I need to find a lettuce.\nOK.\n> go to diningtable 1\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a\nfork 2, a knife 2, a knife 1, a ladle 1, a lettuce 1, a mug 2, a mug 1, a pan 2, a\npeppershaker 1, a spatula 3, a tomato 2, and a tomato 1.\n> think: First I need to find a lettuce.\nOK.\n> take lettuce 1 from diningtable 1\nYou pick up the lettuce 1 from the diningtable 1.\n> think: I need to clean this lettuce (1) using sinkbasin 1.\nOK.\n> go to sinkbasin 1\nOn the sinkbasin 1, you see a apple 2, a ladle 2, a spoon 1, and a tomato 3.\n> think: I need to clean this lettuce (1) using sinkbasin 1.\nOK.\n> clean lettuce 1 with sinkbasin 1\nYou clean the lettuce 1 using the sinkbasin 1.\n> think: I need to put this cleaned lettuce (1) in/on diningtable 1.\nOK.\n> go to diningtable 1\nOn the diningtable 1, you see a apple 1, a bread 1, a butterknife 2, a cup 2, a fork\n2, a knife 2, a knife 1, a ladle 1, a mug 2, a mug 1, a pan 2, a peppershaker 1, a\nspatula 3, a tomato 2, and a tomato 1.\n> think: I need to put this cleaned lettuce (1) in/on diningtable 1.\nOK.\n> put lettuce 1 in/on diningtable 1\nYou put the lettuce 1 in/on the diningtable 1.\nD T RAJECTORIES\nD.1 FEVER T RAJECTORIES\nWe provide some trajectories produced by ReAct ,CoTandActon several randomly selected exam-\nples from the FEVER dev set below. Search results are omitted to space.\n25", "start_char_idx": 0, "end_char_idx": 2405, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3255bb20-0b87-467b-931f-867432d1b6ed": {"__data__": {"id_": "3255bb20-0b87-467b-931f-867432d1b6ed", "embedding": null, "metadata": {"page_label": "26", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bf4015a4-688e-45d5-b06f-848040748b50", "node_type": null, "metadata": {"page_label": "26", "file_name": "2210.03629.pdf"}, "hash": "f301b68cbbaffb556e8ad4a414d5c817609fb42d53ab5d8f1e0d743d348520b8"}}, "hash": "f301b68cbbaffb556e8ad4a414d5c817609fb42d53ab5d8f1e0d743d348520b8", "text": "Published as a conference paper at ICLR 2023\nExample 2491 (gt: REFUTES)\nReAct\nClaim: Bermuda Triangle is a loosely-defined region in the Pacific Ocean.\nThought 1: I need to search Bermuda Triangle and find if it is in the Pacific Ocean.\nAction 1: Search[Bermuda Triangle]\nObservation 1: Reportedly haunted locations...\nThought 2: The observation says that it is in the western part of the North Atlantic\nOcean, so it is not in the Pacific Ocean.\nAction 2: Finish[REFUTES]\nObservation 2: Episode finished\nAct\nClaim: Bermuda Triangle is a loosely-defined region in the Pacific Ocean.\nAction 1 : Search[Bermuda Triangle]\nObservation 1 : Reportedly haunted locations:...\nAction 2: Finish[REFUTES]\nObservation 2: Episode finished\nCoT\nClaim: Bermuda Triangle is a loosely-defined region in the Pacific Ocean.\nThought: Let\u2019s think step by step. The Bermuda Triangle is a loosely-defined region\nin the Atlantic Ocean. The Pacific Ocean is not the Atlantic Ocean.\nAnswer: REFUTES\nExample 5908 (gt: SUPPORTS)\nReAct\nClaim: Princess Mononoke is a film.\nThought 1: I need to search Princess Mononoke and find if it is a film.\nAction 1: Search[Princess Mononoke]\nObservation 1: Princess Mononoke ...\nThought 2: From the observation, it says that Princess Mononoke is a film.\nAction 2: Finish[SUPPORTS]\nObservation 2: Episode finished\nAct\nClaim: Princess Mononoke is a film.\nAction 1: Search[Princess Mononoke]\nObservation 1: Princess Mononoke ...\nAction 2: Finish[SUPPORTS]\nObservation 2: Episode finished\nCoT\nClaim: Princess Mononoke is a film.\nThought: Let\u2019s think step by step. Princess Mononoke is a movie, and movies are\nfilms.\nAnswer: SUPPORTS\nExample 1951 (gt: REFUTES)\nReAct\nClaim: Soyuz was part of the American space program.\nThought 1: I need to search Soyuz and find if it was part of the American space\nprogram.\nAction 1: Search[Soyuz]\nObservation 1: Soyuz is a transliteration...\nThought 2: It does not mention the American space program, so I need to search\n\"American space program\" to find if it was part of it.\nAction 2: Search[American space program]\nObservation 2: The space policy...\nThought 3: It does not mention Soyuz, so I am not sure if this claim is true or not.\nAction 3: Finish[NOT ENOUGH INFO]\nObservation 3: Episode finished\nAct\nClaim: Soyuz was part of the American space program.\nAction 1: Search[Soyuz]\nObservation 1: Soyuz is a transliteration...\nAction 2: Finish[NOT ENOUGH INFO]\nObservation 2: Episode finished\nCoT\nClaim: Soyuz was part of the American space program.\nThought: Let\u2019s think step by step. Soyuz is a Russian spacecraft. The American\nspace program is NASA. NASA and Russia have worked together on the\nInternational Space Station.\nAnswer: SUPPORTS\n26", "start_char_idx": 0, "end_char_idx": 2684, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6f9c3c9c-aa65-41a6-8770-948af122fcc7": {"__data__": {"id_": "6f9c3c9c-aa65-41a6-8770-948af122fcc7", "embedding": null, "metadata": {"page_label": "27", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d61065d3-5978-4ea2-a71a-800593e6d194", "node_type": null, "metadata": {"page_label": "27", "file_name": "2210.03629.pdf"}, "hash": "c1dcfd5505402d3f1e03d53bda9952ab36426ba38c6b3e53cc2b821aabd47a3d"}}, "hash": "c1dcfd5505402d3f1e03d53bda9952ab36426ba38c6b3e53cc2b821aabd47a3d", "text": "Published as a conference paper at ICLR 2023\nExample 3208 (gt: REFUTES)\nReAct\nClaim: Reign Over Me is an American film made in 2010.\nThought 1: I need to search for Reign Over Me and find if it is an American film made\nin 2010.\nAction 1: Search[Reign Over Me]\nObservation 1: Reign Over Me ...\nThought 2: The observation says that it is an American film made in 2007, so it is not\nmade in 2010.\nAction 2: Finish[REFUTES]\nObservation 2: Episode finished\nAct\nClaim: Reign Over Me is an American film made in 2010.\nAction 1: Search[Reign Over Me]\nAction 2: Finish[SUPPORTS]\nObservation 2: Episode finished\nCoT\nClaim: Reign Over Me is an American film made in 2010.\nThought: Let\u2019s think step by step. First, is Reign Over Me an American film? Yes,\nit is. Second, was it made in 2010? Yes, it was.\nAnswer: SUPPORTS\nD.2 ALFW ORLD TRAJECTORIES\nWe provide an example trajectory of ReAct ,Act, andReAct-IM on the same ALFWorld game,\npick_clean_then_place_in_recep-Knife-None-CounterTop-10/\ntrial_T20190909_110445_675754 .\nD.2.1 REAC TTRAJECTORY\nReAct is able to correctly \ufb01nd the knife, clean it, and then place it on a countertop.\n27", "start_char_idx": 0, "end_char_idx": 1124, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6e02578c-a8d6-4106-8c49-680424d2b012": {"__data__": {"id_": "6e02578c-a8d6-4106-8c49-680424d2b012", "embedding": null, "metadata": {"page_label": "28", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "25fd9180-9e92-4751-bf45-67fa2a55fa5b", "node_type": null, "metadata": {"page_label": "28", "file_name": "2210.03629.pdf"}, "hash": "d03e21cf09b539f8943b859f1d0f4599901b4962fbd8e33c27a3acc9d2b2eb10"}}, "hash": "d03e21cf09b539f8943b859f1d0f4599901b4962fbd8e33c27a3acc9d2b2eb10", "text": "Published as a conference paper at ICLR 2023\nReAct ALFWorld trajectory\nYou are in the middle of a room. Looking quickly around you, you see a cabinet 6, a\ncabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a\ncountertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a\nfridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin\n1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster\n1.\nYour task is to: put a clean knife in countertop.\n> think: To solve the task, I need to find and take a knife, then clean it with\nsinkbasin, then put it in countertop.\nOK.\n> think: First I need to find a knife. A knife is more likely to appear in cabinet\n(1-6), drawer (1-3), countertop (1-3), fridge (1), garbagecan (1), shelf (1-3),\nsinkbasin (1), stoveburner (1-4), toaster (1). I can check one by one, starting with\ncabinet 1.\nOK.\n> go to cabinet 1\nOn the cabinet 1, you see a bowl 1.\n> go to cabinet 2\nThe cabinet 2 is closed.\n> go to cabinet 3\nOn the cabinet 3, you see a glassbottle 1.\n> go to cabinet 4\nOn the cabinet 4, you see a mug 1.\n> go to cabinet 5\nThe cabinet 5 is closed.\n> go to cabinet 6\nThe cabinet 6 is closed.\n> go to drawer 1\nThe drawer 1 is closed.\n> go to drawer 2\nThe drawer 2 is closed.\n> go to drawer 3\nThe drawer 3 is closed.\n> go to countertop 1\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\n> go to countertop 2\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a knife 1, a\nplate 2, a potato 3, and a statue 1.\n> think: Now I find a knife (1). Next, I need to take it.\nOK.\n> take knife 1 from countertop 2\nYou pick up the knife 1 from the countertop 2.\n> think: Now I take a knife (1). Next, I need to go to sinkbasin (1) and clean it.\nOK.\n> go to sinkbasin 1\nOn the sinkbasin 1, you see a fork 3, a lettuce 3, and a spatula 2.\n> clean knife 1 with sinkbasin 1\nYou clean the knife 1 using the sinkbasin 1.\n> think: Now I clean a knife (1). Next, I need to put it in/on countertop 1.\nOK.\n> go to countertop 1\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\n> put knife 1 in/on countertop 1\nYou put the knife 1 in/on the countertop 1.\nD.2.2 AC TTRAJECTORY\nAct is able to correctly \ufb01nd the knife, but tries to clean it using a sinkbasin before actually going\nto the sinkbasin. From there on, the model is unable to recover, and is stuck repeating the same\nsequence of commands. With ReAct , an existing thought would have concretely identi\ufb01ed that the\nknife had been taken, and that the next subgoal was to go to a sinkbasin to clean it.\n28", "start_char_idx": 0, "end_char_idx": 2661, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e7e672e9-15c1-45d1-b332-c08ca00bb845": {"__data__": {"id_": "e7e672e9-15c1-45d1-b332-c08ca00bb845", "embedding": null, "metadata": {"page_label": "29", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5b031e53-fc0a-42b0-90a8-7b6af3c7f6fc", "node_type": null, "metadata": {"page_label": "29", "file_name": "2210.03629.pdf"}, "hash": "2eb115ce1dd86e3db0ea1d7673359de8210f0a42e915761d9e481e3f46cbda96"}, "3": {"node_id": "a3e266ae-b709-4f6a-940a-6162370134b7", "node_type": null, "metadata": {"page_label": "29", "file_name": "2210.03629.pdf"}, "hash": "629dc1b3c22f88a3265df9ad9e6c62c7cb36830506a0ec795ce6c47fa5711e21"}}, "hash": "bcf0945e55212d33a9808b586dcf0ccf937bf9b7bd21aba83c2411a9acd3f55e", "text": "Published as a conference paper at ICLR 2023\nAct ALFWorld trajectory\nYou are in the middle of a room. Looking quickly around you, you see a cabinet 6, a\ncabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a\ncountertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a\nfridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin\n1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster\n1.\nYour task is to: put a clean knife in countertop.\n> go to countertop 1\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\n> go to countertop 2\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a knife 1, a\nplate 2, a potato 3, and a statue 1.\n> take knife 1 from countertop 2\nYou pick up the knife 1 from the countertop 2.\n> go to countertop 1\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\n> clean knife 1 with sinkbasin 1\nNothing happens.\n> go to countertop 3\nOn the countertop 3, you see a bread 3, a butterknife 2, a cellphone 1, a creditcard\n1, a fork 2, a houseplant 1, a knife 2, a spatula 1, a statue 3, a tomato 3, a tomato\n2, a tomato 1, and a vase 2.\n> take knife 2 from countertop 3\nNothing happens.\n> go to countertop 2\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a plate 2, a\npotato 3, and a statue 1.\n> take knife 1 from countertop 2\nNothing happens.\n> go to countertop 1\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\n> clean knife 1 with sinkbasin 1\nNothing happens.\n> go to countertop 3\nOn the countertop 3, you see a bread 3, a butterknife 2, a cellphone 1, a creditcard\n1, a fork 2, a houseplant 1, a knife 2, a spatula 1, a statue 3, a tomato 3, a tomato\n2, a tomato 1, and a vase 2.\n> take knife 2 from countertop 3\nNothing happens.\n> go to countertop 2\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a plate 2, a\npotato 3, and a statue 1.\n> take knife 1 from countertop 2\nNothing happens.\n> go to countertop 1\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\n> clean knife 1 with sinkbasin 1\nNothing happens.\n> go to countertop 3\nOn the countertop 3, you see a bread 3, a butterknife 2, a cellphone 1, a creditcard\n1, a fork 2, a houseplant 1, a knife 2, a spatula 1, a statue 3, a tomato 3, a tomato\n2, a tomato 1, and a vase 2.\n> take knife 2 from countertop 3\nNothing happens.\n> go to countertop 2\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a plate 2, a\npotato 3, and a statue 1.\n> take knife 1 from countertop 2\nNothing happens.\n> go to countertop 1\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a", "start_char_idx": 0, "end_char_idx": 2788, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a3e266ae-b709-4f6a-940a-6162370134b7": {"__data__": {"id_": "a3e266ae-b709-4f6a-940a-6162370134b7", "embedding": null, "metadata": {"page_label": "29", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5b031e53-fc0a-42b0-90a8-7b6af3c7f6fc", "node_type": null, "metadata": {"page_label": "29", "file_name": "2210.03629.pdf"}, "hash": "2eb115ce1dd86e3db0ea1d7673359de8210f0a42e915761d9e481e3f46cbda96"}, "2": {"node_id": "e7e672e9-15c1-45d1-b332-c08ca00bb845", "node_type": null, "metadata": {"page_label": "29", "file_name": "2210.03629.pdf"}, "hash": "bcf0945e55212d33a9808b586dcf0ccf937bf9b7bd21aba83c2411a9acd3f55e"}}, "hash": "629dc1b3c22f88a3265df9ad9e6c62c7cb36830506a0ec795ce6c47fa5711e21", "text": "see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\n> clean knife 1 with sinkbasin 1\nNothing happens.\nD.2.3 REAC T-IM TRAJECTORY\nReAct-IM is able to correctly \ufb01nd the knife, but is unable to clean it as well. The LLM then\ngets stuck trying to place this knife on a countertop. One possible issue is the incorrect thought\nthink: I need to find a clean knife. , which seems to trick the LLM in believing\nthat the knife is already cleaned. In ReAct , this sequence of subgoals would be concretely captured\nby each thought.\n29", "start_char_idx": 2739, "end_char_idx": 3268, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8f917f38-bf31-48e4-a709-f49fc3aa13df": {"__data__": {"id_": "8f917f38-bf31-48e4-a709-f49fc3aa13df", "embedding": null, "metadata": {"page_label": "30", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6f3b60b2-cf8b-4e9e-bea3-8b79cbbedc44", "node_type": null, "metadata": {"page_label": "30", "file_name": "2210.03629.pdf"}, "hash": "799bd0e52ef613a9f555cdb42c101f5afc6e7029a1c2822bf61037ee07f0eb90"}}, "hash": "799bd0e52ef613a9f555cdb42c101f5afc6e7029a1c2822bf61037ee07f0eb90", "text": "Published as a conference paper at ICLR 2023\nReAct-IM ALFWorld trajectory\nYou are in the middle of a room. Looking quickly around you, you see a cabinet 6, a\ncabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a\ncountertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a\nfridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin\n1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster\n1.\nYour task is to: put a clean knife in countertop.\n> think: To solve the task, I need to find and take a clean knife, then put it in\ncountertop.\nOK.\n> think: I need to find a clean knife.\nOK.\n> go to countertop 1\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\n> think: I need to find a clean knife.\nOK.\n> go to countertop 2\nOn the countertop 2, you see a cup 1, a dishsponge 1, a glassbottle 3, a knife 1, a\nplate 2, a potato 3, and a statue 1.\n> think: I need to find a clean knife.\nOK.\n> take knife 1 from countertop 2\nYou pick up the knife 1 from the countertop 2.\n> think: I need to put this knife (1) in/on countertop 1.\nOK.\n> go to countertop 1\nOn the countertop 1, you see a lettuce 2, a mug 2, a peppershaker 1, and a spoon 2.\n> think: I need to put this knife (1) in/on countertop 1.\nOK.\n> put knife 1 in/on countertop 1\nYou put the knife 1 in/on the countertop 1.\n> think: I need to put this knife (1) in/on countertop 1.\nOK.\n> put knife 1 in/on countertop 1\nNothing happens.\n> think: I need to put this knife (1) in/on countertop 1.\nOK.\n> put knife 1 in/on countertop 1\nNothing happens.\n> think: I need to put this knife (1) in/on countertop 1.\nOK.\n> put knife 1 in/on countertop 1\nNothing happens.\n> think: I need to put this knife (1) in/on countertop 1.\nOK.\n> put knife 1 in/on countertop 1\nNothing happens.\n> think: I need to put this knife (1) in/on countertop 1.\nOK.\n> put knife 1 in/on countertop 1\nNothing happens.\n> think: I need to put this knife (1) in/on countertop 1.\nOK.\n30", "start_char_idx": 0, "end_char_idx": 2034, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d71b5356-6861-4804-b8d5-d988f6458a72": {"__data__": {"id_": "d71b5356-6861-4804-b8d5-d988f6458a72", "embedding": null, "metadata": {"page_label": "31", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e51e61dc-4775-4092-89ba-ba106e9ea195", "node_type": null, "metadata": {"page_label": "31", "file_name": "2210.03629.pdf"}, "hash": "ed52f82228fcf6e4f52bddc17f0f7889b15b013a82ff1b3877ccaafe8f2c6768"}, "3": {"node_id": "01b85b0e-2535-4b86-a458-c9972eaa514b", "node_type": null, "metadata": {"page_label": "31", "file_name": "2210.03629.pdf"}, "hash": "6fd23d18cab2591617703b5e14ba90783af140f1bee7ec6fabff92e1d5d91f23"}}, "hash": "662eaafa7e07501f8541190bc1f985d8b2308f1eef82d9757a0c0c75d46f62cf", "text": "Published as a conference paper at ICLR 2023\nD.3 W EBSHOP TRAJECTORIES\nTable 10: Example trajectories for Webshop predicted by Act andReAct . Compared to Act,\nReAct uses reasoning to \ufb01nd products that satisfy all target attributes.\nInstruction : get me a sixteen pack of apple cinnamon freeze dried banana chips, and price lower than 50.00 dollars\nAct ReAct\nAction :search\u0002\nsixteen pack apple cinnamon freeze dried banana\nchips\u0003\nObservation:\u0002\nBack to Search\u0003\nPage 1 (Total results: 50)\u0002\nNext\u0003\n\u0002\nB0061IVFZE\u0003\nBrothers-ALL-Natural Fruit Crisps, Strawberry Banana, 0.42 -\nOunce (Pack of 100)\n$85.0\u0002\nB096H2P6G2\u0003\nMoon Fruit Freeze Dried Fruit Snacks. Fruit Snacks for Kids -\n(Variety Pack)\n$18.99\u0002\nB092JLLYK6\u0003\nNature\u2019s Turn Freeze-Dried Fruit Snacks - Banana Crisps - Perfect\nFor School Lunches or an On-The-Go Snack - No Sugar Added,\nNon GMO, Gluten Free, Nothing Arti\ufb01cial (0.53oz) 6-Pack\n$12.99\nAction :click\u0002\nB0061IVFZE\u0003\nObservation :\u0002\nBack to Search\u0003\n\u0002\nPrev\u0003\n\ufb02avor name [asian pear][banana][fuji apple & cinnamon][strawberry\nbanana] Brothers-ALL-Natural Fruit Crisps, Strawberry Banana,\n0.42 Ounce (Pack of 100)\nPrice: $85.0\nRating: N.A.\n[Description]\n[Features]\n[Reviews]\n[Buy Now]\nAction :click [Buy Now]Action :search\u0002\nsixteen pack apple cinnamon freeze dried banana\nchips\u0003\nObservation:\u0002\nBack to Search\u0003\nPage 1 (Total results: 50)\u0002\nNext\u0003\n\u0002\nB0061IVFZE\u0003\nBrothers-ALL-Natural Fruit Crisps, Strawberry Banana, 0.42 -\nOunce (Pack of 100)\n$85.0\u0002\nB096H2P6G2\u0003\nMoon Fruit Freeze Dried Fruit Snacks. Fruit Snacks for Kids -\n(Variety Pack)\n$18.99\u0002\nB092JLLYK6\u0003\nNature\u2019s Turn Freeze-Dried Fruit Snacks - Banana Crisps - Perfect\nFor School Lunches or an On-The-Go Snack - No Sugar Added,\nNon GMO, Gluten Free, Nothing Arti\ufb01cial (0.53oz) 6-Pack\n$12.99\nAction :think [B0061IVFZE is strawberry banana, not apple cinnamon.\nB096H2P6G2 is fruit snacks, not freeze dried banana chips.\nB092JLLYK6 is banana crisps, not apple cinnamon. I can check\nB092JLLYK6 \ufb01rst.\nObservation : OK.\nAction :click\u0002\nB092JLLYK6\u0003\nObservation :\u0002\nBack to Search\u0003\n\u0002\nPrev\u0003\n\ufb02avor name [apple][apple cinnamon][banana][cantaloupe][peach][pear]\n[strawberry][strawberry banana][sampler variety pack][mega variety\npack][orchard variety pack]\nsize [0.53 ounce (pack of 6)][0.53 ounce (pack of 8)][0.53 ounce (pack\nof 16)]\nNature\u2019s Turn Freeze-Dried Fruit Snacks - Banana Crisps - Perfect\nFor School Lunches or an On-The-Go Snack - No Sugar Added, Non\nGMO, Gluten Free, Nothing Arti\ufb01cial (0.53oz) 6-Pack\nPrice: $12.99\nRating: N.A.\n[Description]\n[Features]\n[Reviews]\n[Buy Now]\nAction :think [For sixteen pack of apple cinnamon freeze dried", "start_char_idx": 0, "end_char_idx": 2585, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "01b85b0e-2535-4b86-a458-c9972eaa514b": {"__data__": {"id_": "01b85b0e-2535-4b86-a458-c9972eaa514b", "embedding": null, "metadata": {"page_label": "31", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e51e61dc-4775-4092-89ba-ba106e9ea195", "node_type": null, "metadata": {"page_label": "31", "file_name": "2210.03629.pdf"}, "hash": "ed52f82228fcf6e4f52bddc17f0f7889b15b013a82ff1b3877ccaafe8f2c6768"}, "2": {"node_id": "d71b5356-6861-4804-b8d5-d988f6458a72", "node_type": null, "metadata": {"page_label": "31", "file_name": "2210.03629.pdf"}, "hash": "662eaafa7e07501f8541190bc1f985d8b2308f1eef82d9757a0c0c75d46f62cf"}}, "hash": "6fd23d18cab2591617703b5e14ba90783af140f1bee7ec6fabff92e1d5d91f23", "text": "Now]\nAction :think [For sixteen pack of apple cinnamon freeze dried banana\nchips, the item has options \u2019apple cinnamon\u2019 and \u20190.53 ounce (pack of\n16)\u2019 and seems good to buy.]\nObservation : OK.\nAction :click [apple cinnamon]\nObservation : You have clicked apple cinnamon.\nAction :click [0.53 ounce (pack of 16)]\nObservation : You have clicked 0.53 ounce (pack of 16).\nAction :click [Buy Now]\nScore : 0.125 Score : 1.0\n31", "start_char_idx": 2518, "end_char_idx": 2936, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4b14341c-f212-4b7e-a6bc-dc467e506941": {"__data__": {"id_": "4b14341c-f212-4b7e-a6bc-dc467e506941", "embedding": null, "metadata": {"page_label": "32", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "46abce09-9df9-40e1-8e60-79d47fb41249", "node_type": null, "metadata": {"page_label": "32", "file_name": "2210.03629.pdf"}, "hash": "6e47bf88cb3245b46ab702547a1fcda9e57bc831639be3b39d83fe83c2c2105d"}}, "hash": "6e47bf88cb3245b46ab702547a1fcda9e57bc831639be3b39d83fe83c2c2105d", "text": "Published as a conference paper at ICLR 2023\nE M ORE ANALYSIS\nE.1 S UCCESS AND FAILURE MODES ANALYSIS\nWe provide some examples corresponding to the success and error mode analysis given in Sec. 3.3.\nSearch results and non-representative steps are omitted to reduce space.\nSuccess: True positive\nReAct\nQuestion: Author David Chanoff has collaborated with a U.S. Navy admiral who served as\nthe ambassador to the United Kingdom under which President?\nThought 1: I need to search David Chanoff and find the U.S. Navy admiral he\ncollaborated with.\nAction 1: Search[David Chanoff]\nObservation 1: David Chanoff is a noted author...\nAction 2: Search[William J. Crowe]\nObservation 2: William J. Crowe is...\nThought 3: William J. Crowe served as the ambassador to the United Kingdom under\nPresident Bill Clinton. So the answer is Bill Clinton.\nAction 3: Finish[Bill Clinton]\nObservation 3: Episode finished\nCoT\nQuestion: What was the name of the team that represented an Arizona university in\nthe conference that covers a broad expanse of the western United States,\nincluding Arizona, California, and New Mexico?\nThought: Let\u2019s think step by step. The name of the team that represented an Arizona\nuniversity in the conference that covers a broad expanse of the western\nUnited States, including Arizona, California, and New Mexico is Arizona\nState Sun Devils.\nAnswer: Arizona State Sun Devils\nSuccess: False positive\nReAct\nQuestion: Did the board game San Marco or About Time come out first?\nThought 1: I need to search San Marco and About Time, and find which came out first.\nAction 1: Search[San Marco]\nObservation 1: San Marco is one of the ... The was built in venice.\nThought 2: San Marco is a sestiere of Venice. I need to search About Time next.\nAction 2: Search[About Time]\nObservation 2: Could not find [About Time]. Similar: [...].\nThought 3: About Time is a 2013 film. So San Marco came out first.\nAction 3: Finish[San Marco]\nObservation 3: Episode finished\nCoT\nQuestion: Was Vanderbilt University or Emory University founded first?\nThought: Let\u2019s think step by step. Vanderbilt University was founded in 1873. Emory\nUniversity was founded in 1836. 1873 (Vanderbilt University) > 1836 (Emory\nUniversity), so Vanderbilt University was founded first.\nAnswer: Emory University\nFailure: Reasoning error\nReAct\nQuestion: What was the middle name of the actress who was cast alongside Harvey\nFierstein, Linda Hart, Dick Latessa, Clarke Thorell, Mary Bond Davis, Laura\nBell Bundy, Matthew Morrison, Corey Reynolds, and Marissa Jaret Winokur in\nHairspray?\nThought 1: I need to search Harvey Fierstein, Linda Hart, Dick Latessa, Clarke Thorell,\nMary Bond Davis, Laura Bell Bundy, Matthew Morrison, Corey Reynolds, and\nMarissa Jaret Winokur, find the actress that was cast alongside them in\nHairspray, then find its middle name.\nAction 1: Search[Harvey Fierstein]\nObservation 1: Harvey Forbes Fierstein ...\nThought 2: Harvey Fierstein is an actor, playwright, and screenwriter. I need to\nsearch Linda Hart next...\nAction 2: Search[Linda Hart]...\nCoT\nQuestion: Who is older Danny Green or James Worthy?\nThought: Let\u2019s think step by step. Danny Green was born in 1987. James Worthy was\nborn in 1961. 1987 (Danny Green) > 1961 (James Worthy), so Danny Green is\nolder.\nAnswer: Danny Green\n32", "start_char_idx": 0, "end_char_idx": 3276, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e88d3de8-7a69-4d76-b8ff-c7c80ac87df3": {"__data__": {"id_": "e88d3de8-7a69-4d76-b8ff-c7c80ac87df3", "embedding": null, "metadata": {"page_label": "33", "file_name": "2210.03629.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e8b9a63a-5f7e-459f-b1e8-f2edf9bf5b13", "node_type": null, "metadata": {"page_label": "33", "file_name": "2210.03629.pdf"}, "hash": "58cee734f0a7a12a15efbada88de8ed138798292d3d33794af81ee5e552d21c5"}}, "hash": "58cee734f0a7a12a15efbada88de8ed138798292d3d33794af81ee5e552d21c5", "text": "Published as a conference paper at ICLR 2023\nFailure: Search error\nReAct\nQuestion: What does the goddess associated with the goddess frigg consists of what\ntales?\nThought 1: I need to search goddess frigg and find its associated goddess.\nAction 1: Search[goddess frigg]\nObservation 1: Could not find goddess frigg. Similar: [\u2019Frigg\u2019, \u2019Frigg and Freyja common\norigin hypothesis\u2019, \u2019Freyja (section Relation to Frigg and other goddesses\nand figures)\u2019, \u2019Eir (redirect from Eir (goddess))\u2019, \u2019Baldr\u2019].\nThought 2: I need to search Frigg instead...\nFailure: Hallucination\nCoT\nQuestion: What was the first year a scientific journal published by an organization\nlocated in the Bronx was published?\nThought: Let\u2019s think step by step. The first year a scientific journal published by\nan organization located in the Bronx was published was 1916.\nAnswer: 1916 (Label: 1909)\nFailure: Label ambiguity\nReAct\nQuestion: What nationality is the man who developed the dictator game?\nThought 1: I need to search dictator game, find the man who developed it, then find his\nnationality.\nAction 1: Search[dictator game]\nObservation 1: The dictator game is a popular experimental instrument in social psychology\nand economics...\nAction 3: Search[Amos Tversky]\nObservation 3: Amos Nathan Tversky...\nThought 4: Amos Tversky is an Israeli cognitive and mathematical psychologist. So the\nman who developed the dictator game is Israeli.\nAction 4: Finish[Israeli] (label: Israel-American)\nCoT\nQuestion: Kurt Fuller from Stockton, CA appeared in which American Detective Comedy\nDrama television series created by Steve Franks?\nThought: Let\u2019s think step by step. Kurt Fuller from Stockton, CA appeared in Psych.\nPsych is an American Detective Comedy Drama television series created by\nSteve Franks.\nAnswer: Psych (label: Psych is an American detective comedy-drama)\n33", "start_char_idx": 0, "end_char_idx": 1834, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "66ddb73e-075c-4912-845f-bdd630210707": {"__data__": {"id_": "66ddb73e-075c-4912-845f-bdd630210707", "embedding": null, "metadata": {"page_label": "1", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6809b276-7611-49e6-bc9e-fdc5e7be0947", "node_type": null, "metadata": {"page_label": "1", "file_name": "2305.06983.pdf"}, "hash": "987c5544c41282e64c5986021f968648043d9f2c2ff761a6c31c1f1eb40ef905"}, "3": {"node_id": "ffdd2dd1-6d94-40ff-95b1-ac2e021c119a", "node_type": null, "metadata": {"page_label": "1", "file_name": "2305.06983.pdf"}, "hash": "34a696eeef08ee6ffe87dfd6c75d17c6fe7ed3bb94b5b358e0968462cb8ccb5f"}}, "hash": "4a0ce2958aa702d970de9e755b8614e4f489dfc18a6f1475f550b2581ebe0c6e", "text": "Active Retrieval Augmented Generation\nZhengbao Jiang1\u0003Frank F. Xu1\u0003Luyu Gao1\u0003Zhiqing Sun1\u0003Qian Liu2\nJane Dwivedi-Yu3Yiming Yang1Jamie Callan1Graham Neubig1\n1Language Technologies Institute, Carnegie Mellon University\n2Sea AI Lab3Meta AI Research\n{zhengbaj,fangzhex,luyug,zhiqings,gneubig}@cs.cmu.edu\nAbstract\nDespite the remarkable ability of large lan-\nguage models (LMs) to comprehend and gen-\nerate language, they have a tendency to hal-\nlucinate and create factually inaccurate out-\nput. Augmenting LMs by retrieving infor-\nmation from external knowledge resources\nis one promising solution. Most existing\nretrieval-augmented LMs employ a retrieve-\nand-generate setup that only retrieves informa-\ntion once based on the input. This is lim-\niting, however, in more general scenarios in-\nvolving generation of long texts, where con-\ntinually gathering information throughout the\ngeneration process is essential. There have\nbeen some past efforts to retrieve informa-\ntion multiple times while generating outputs,\nwhich mostly retrieve documents at \ufb01xed inter-\nvals using the previous context as queries. In\nthis work, we provide a generalized view of\nactive retrieval augmented generation , meth-\nods that actively decide when and what to re-\ntrieve across the course of the generation. We\npropose Forward- Looking Active REtrieval\naugmented generation ( FLARE ), a generic\nretrieval-augmented generation method which\niteratively uses a prediction of the upcoming\nsentence to anticipate future content, which is\nthen utilized as a query to retrieve relevant doc-\numents to regenerate the sentence if it contains\nlow-con\ufb01dence tokens. We test FLARE along\nwith baselines comprehensively over 4 long-\nform knowledge-intensive generation tasks/-\ndatasets. FLARE achieves superior or compet-\nitive performance on all tasks, demonstrating\nthe effectiveness of our method.1\n1 Introduction\nGenerative language models (LMs) (Brown et al.,\n2020; Ouyang et al., 2022; OpenAI, 2023; Chowd-\nhery et al., 2022; Zhang et al., 2022; Touvron et al.,\n2023) have become a foundational component in\n\u0003Lead contributors.\n1Code and datasets are available at https://github.com/\njzbjyb/FLARE .many natural language processing (NLP) systems\nwith their remarkable ability to comprehend and\ngenerate language. Although LMs have memorized\nsome amount of world knowledge observed during\ntraining (Petroni et al., 2019; Roberts et al., 2020;\nJiang et al., 2020), they still tend to hallucinate\nand create imaginary content (Maynez et al., 2020;\nZhou et al., 2021; OpenAI, 2023). To address the\nissue of hallucination, one promising direction is to\naugment generation with retrieval, which involves\naugmenting parametric LMs with non-parametric\nretrieval components that can look up relevant in-\nformation from external knowledge resources such\nas document corpora (Lewis et al., 2020; Izacard\nand Grave, 2021; Khandelwal et al., 2020; Izacard\net al., 2022; Jiang et al., 2022; Shi et al., 2023).\nRetrieval-augmented LMs commonly use a\nretrieve-and-generate setup where they retrieve doc-\numents based on the user\u2019s input (e.g. questions\nin question answering), and then generate a com-\nplete answer conditioning on the retrieved docu-\nments (Lewis et al., 2020; Izacard and Grave, 2021;\nIzacard et al., 2022; Jiang et al., 2022; Shi et al.,\n2023). These single-time", "start_char_idx": 0, "end_char_idx": 3337, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ffdd2dd1-6d94-40ff-95b1-ac2e021c119a": {"__data__": {"id_": "ffdd2dd1-6d94-40ff-95b1-ac2e021c119a", "embedding": null, "metadata": {"page_label": "1", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6809b276-7611-49e6-bc9e-fdc5e7be0947", "node_type": null, "metadata": {"page_label": "1", "file_name": "2305.06983.pdf"}, "hash": "987c5544c41282e64c5986021f968648043d9f2c2ff761a6c31c1f1eb40ef905"}, "2": {"node_id": "66ddb73e-075c-4912-845f-bdd630210707", "node_type": null, "metadata": {"page_label": "1", "file_name": "2305.06983.pdf"}, "hash": "4a0ce2958aa702d970de9e755b8614e4f489dfc18a6f1475f550b2581ebe0c6e"}}, "hash": "34a696eeef08ee6ffe87dfd6c75d17c6fe7ed3bb94b5b358e0968462cb8ccb5f", "text": "et al., 2022; Shi et al.,\n2023). These single-time retrieval-augmented LMs\nhave been found to outperform purely paramet-\nric LMs, particularly for short-form knowledge-\nintensive generation tasks such as factoid QA\n(Kwiatkowski et al., 2019; Joshi et al., 2017) and\nfact checking (Thorne et al., 2018), where the in-\nformation needs are clear in the user\u2019s input, and\nit is suf\ufb01cient to retrieve relevant knowledge once\nsolely based on the input .\nIn recent years, increasingly powerful large LMs\nhave demonstrated abilities in more complex tasks\nthat involve generating long-form output, such as\nlong-form QA (Fan et al., 2019; Stelmakh et al.,\n2022), open-domain summarization (Cohen et al.,\n2021; Hayashi et al., 2021; Giorgi et al., 2022),\nand (chain-of-thought; CoT) reasoning (Wei et al.,\n2022; Ho et al., 2020; Geva et al., 2021; Hendrycks\net al., 2020). In contrast to short-form generation,arXiv:2305.06983v1  [cs.CL]  11 May 2023", "start_char_idx": 3287, "end_char_idx": 4226, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "05477283-841c-443c-8f86-ebfa3b5c7b98": {"__data__": {"id_": "05477283-841c-443c-8f86-ebfa3b5c7b98", "embedding": null, "metadata": {"page_label": "2", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "51559604-c485-4ab4-b411-fdd6b07403f0", "node_type": null, "metadata": {"page_label": "2", "file_name": "2305.06983.pdf"}, "hash": "d3439b9b9f5469059e1743b5866fbd1c1f9da99b1acdb93b0b162df726fdf8bc"}, "3": {"node_id": "b48194d5-d11d-4f9a-bf0f-599bbd487609", "node_type": null, "metadata": {"page_label": "2", "file_name": "2305.06983.pdf"}, "hash": "624fb3570204eeda9964c6c276a8dfc158a3df2a47c51cd3e65dbbdc2eebf5a2"}}, "hash": "4a65c273e93a5c88c4ba2a12edb57c70a05db8b236f6c10d0056535991864ef9", "text": "Generate a summary about Joe Biden.Search results:   !![1]: \u2026[2]: \u2026\nJoe Biden (born November 20, 1942) is the 46th president of the United States.Joe Biden (born November 20, 1942) is the 46th president of the United States.He graduated from the University of Delaware in 1965 with a Bachelor of Arts in history and political scienceJoe Biden attended the University of Pennsylvania, where he earned a law degree.RetrieverInputStep 1Search results:   !\"![1]: \u2026[2]: \u2026\"####\"#$#$$Step 2\nJoe Biden announced his candidacy for the 2020 presidential election on April 25, 2019.Joe Biden announced his candidacy for the 2020 presidential election on August 18, 2019.\"#%#%Step 3Search results:   !\"\"[1]: \u2026[2]: \u2026RetrieveddocumentsLMGeneration$%$%%\nFigure 1: An illustration of forward-looking active retrieval augmented generation (FLARE). Starting with the\nuser input xand initial retrieval results Dx, FLARE iteratively generates a temporary next sentence (shown in\ngray italic ) and check whether it contains low-probability tokens (indicated with underline ). If so (step 2 and 3),\nthe system retrieves relevant documents and regenerates the sentence.\nlong-form generation presents complex informa-\ntion needs that are not always evident from the in-\nput alone . Similar to how humans gradually gather\ninformation as we create content such as papers,\nessays, or books, long-form generation with LMs\nwould require gathering multiple pieces of knowl-\nedge throughout the generation process . For exam-\nple in open-domain summarization (Giorgi et al.,\n2022), the goal is to generate a summary about a\nparticular topic by retrieving references from the\nopen web. The initial retrieval based on the topic\nname (e.g., Joe Biden) may not cover all aspects\nand details. Therefore, it is crucial to retrieve ex-\ntra information as needed during the generation\nprocess, such as when generating a certain aspect\n(e.g., the education history of Joe Biden) or a spe-\nci\ufb01c detail (e.g., when did Joe Biden announce his\ncandidacy for the 2020 presidential campaign).\nSeveral attempts have been made to build sys-\ntems that retrieve multiple times throughout genera-\ntion. These attempts include methods that passively\nutilize the past context (e.g., previous sentences or\ntokens) to retrieve additional information at a \ufb01xed\ninterval (e.g., every sentence or every few tokens)\n(Khandelwal et al., 2020; Borgeaud et al., 2022;\nRam et al., 2023; Trivedi et al., 2022) which mightnot accurately re\ufb02ect what LMs intend to gener-\nate in the future or retrieve at inappropriate points.\nSome works in multihop QA address multiple infor-\nmation needs by decomposing the full question into\nsub-questions, each of which is used to retrieve ex-\ntra information (Press et al., 2022; Yao et al., 2022;\nKhot et al., 2022; Khattab et al., 2022).\nWe ask the following question in this paper: can\nwe create a simple and generic retrieval-augmented\nLM that actively decides when and what to retrieve\nthroughout the generation process, and are appli-\ncable to a variety of long-form generation tasks?\nWe consider a new paradigm, active retrieval aug-\nmented generation. Our hypothesis regarding when\nto retrieve is that LMs should retrieve information\nonly when they lack the required knowledge to\navoid unnecessary or inappropriate retrieval that\noccurs in passive retrieval-augmented LMs (Khan-\ndelwal et al., 2020; Borgeaud et al., 2022; Ram\net al., 2023; Trivedi et al., 2022). Given the obser-\nvation that large LMs tend to be well-calibrated and\nlow probability/con\ufb01dence often indicates a", "start_char_idx": 0, "end_char_idx": 3556, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b48194d5-d11d-4f9a-bf0f-599bbd487609": {"__data__": {"id_": "b48194d5-d11d-4f9a-bf0f-599bbd487609", "embedding": null, "metadata": {"page_label": "2", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "51559604-c485-4ab4-b411-fdd6b07403f0", "node_type": null, "metadata": {"page_label": "2", "file_name": "2305.06983.pdf"}, "hash": "d3439b9b9f5469059e1743b5866fbd1c1f9da99b1acdb93b0b162df726fdf8bc"}, "2": {"node_id": "05477283-841c-443c-8f86-ebfa3b5c7b98", "node_type": null, "metadata": {"page_label": "2", "file_name": "2305.06983.pdf"}, "hash": "4a65c273e93a5c88c4ba2a12edb57c70a05db8b236f6c10d0056535991864ef9"}}, "hash": "624fb3570204eeda9964c6c276a8dfc158a3df2a47c51cd3e65dbbdc2eebf5a2", "text": "and\nlow probability/con\ufb01dence often indicates a lack\nof knowledge (Jiang et al., 2021; Kadavath et al.,\n2022), we adopt an active retrieval strategy that\nonly retrieves when LMs generate low-probability\ntokens. When deciding what to retrieve , we argue", "start_char_idx": 3509, "end_char_idx": 3761, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f94e9797-7fd0-4702-9962-35075371ee67": {"__data__": {"id_": "f94e9797-7fd0-4702-9962-35075371ee67", "embedding": null, "metadata": {"page_label": "3", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "81b1ed45-53ec-4d4f-964e-c8b3710c74f4", "node_type": null, "metadata": {"page_label": "3", "file_name": "2305.06983.pdf"}, "hash": "efa3140bf1b13c7b48aec1ddb4d48b5419d48e09dd8185172d5deec95847563d"}, "3": {"node_id": "7a391145-e9c3-4c3c-8444-4040a3386554", "node_type": null, "metadata": {"page_label": "3", "file_name": "2305.06983.pdf"}, "hash": "69b562afdea52998740b99bbaeb9c71d99cd7ff64651b96bf66079be72033741"}}, "hash": "e2d2affe1c98e932aea1da0680cc82f8813ca4da498e087f51019846cdd8b468", "text": "that it is important to consider what LMs intend to\ngenerate in the future, as the goal of active retrieval\nis to bene\ufb01t future generations. Therefore, we pro-\npose anticipating the future by generating a tempo-\nrary next sentence, using it as a query to retrieve\nrelevant documents, and then regenerating the next\nsentence conditioning on the retrieved documents.\nCombining the two aspects, we propose Forward-\nLooking Active REtrieval augmented generation\n(FLARE ), as illustrated in Figure 1. FLARE iter-\natively generates a temporary next sentence , use\nit as the query to retrieve relevant documents if it\ncontains low-probability tokens and regenerate the\nnext sentence until reaches the end.\nFLARE is applicable to any existing LMs at\ninference time without additional training. Con-\nsidering the impressive performance achieved by\nGPT-3.5 (Ouyang et al., 2022) on a variety of\ntasks, we examine the effectiveness of our meth-\nods on text-davinci-003 . We evaluate FLARE\non 4 diverse tasks/datasets involving generating\nlong outputs, including multihop QA (2WikiMul-\ntihopQA), commonsense reasoning (StrategyQA),\nlong-form QA (ASQA), and open-domain summa-\nrization (WikiAsp) (Ho et al., 2020; Geva et al.,\n2021; Stelmakh et al., 2022; Hayashi et al., 2021).\nOver all tasks, FLARE achieves superior or com-\npetitive performance compared to single-time and\nmulti-time retrieval baselines, demonstrating the\neffectiveness and generalizability of our method.\n2 Retrieval-Augmented Generation\nIn this section, we formally de\ufb01ne single-time\nretrieval-augmented generation and propose the\nframework of active retrieval augmented generation\nthat decides when and what to retrieve throughout\nthe generation.\n2.1 Notations and De\ufb01nitions\nGiven a user input xand a document corpus D=\nfdigjDj\ni=1(such as all Wikipedia articles), the goal of\nretrieval-augmented LMs is to generate the answer\ny= [s1;s2;:::;sm] = [w1;w2;:::;w n]containing\nmsentences or ntokens leveraging information\nretrieved from the corpus.\nIn retrieval-augmented LM, the LM typically\npairs with a retriever that can retrieve a list of\ndocumentsDq=ret(q)for a query q; the LM\nconditions on both the user input xand retrieved\ndocumentsDqto generate the answer. Since we\nfocus on examining various methods of determin-ing when and what to retrieve, we follow exist-\ning methods (Ram et al., 2023; Trivedi et al.,\n2022) to prepend the retrieved documents before\nthe user input to aid future generation for both\nbaselines and our method for fair comparisons:\ny=LM([Dq;x]), where [\u0001;\u0001]is concatenation fol-\nlowing the speci\ufb01ed order.\n2.2 Single-time Retrieval-Augmented\nGeneration\nThe most common choice is to directly use the user\ninput as the query for retrieval and generate the\ncomplete answer at once y=LM([Dx;x])(Chen\net al., 2017; Guu et al., 2020; Lewis et al., 2020;\nIzacard and Grave, 2021; Sachan et al., 2021; Lee\net al., 2021; Jiang et al., 2022; Izacard et al., 2022;\nShi et al., 2023).\n2.3 Active Retrieval Augmented Generation\nTo aid long-form generation with retrieval, we pro-\npose active retrieval augmented generation. It is a\ngeneric framework that actively decides when and\nwhat to retrieve through the generation process,\nresulting in the interleaving of retrieval and", "start_char_idx": 0, "end_char_idx": 3251, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7a391145-e9c3-4c3c-8444-4040a3386554": {"__data__": {"id_": "7a391145-e9c3-4c3c-8444-4040a3386554", "embedding": null, "metadata": {"page_label": "3", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "81b1ed45-53ec-4d4f-964e-c8b3710c74f4", "node_type": null, "metadata": {"page_label": "3", "file_name": "2305.06983.pdf"}, "hash": "efa3140bf1b13c7b48aec1ddb4d48b5419d48e09dd8185172d5deec95847563d"}, "2": {"node_id": "f94e9797-7fd0-4702-9962-35075371ee67", "node_type": null, "metadata": {"page_label": "3", "file_name": "2305.06983.pdf"}, "hash": "e2d2affe1c98e932aea1da0680cc82f8813ca4da498e087f51019846cdd8b468"}}, "hash": "69b562afdea52998740b99bbaeb9c71d99cd7ff64651b96bf66079be72033741", "text": "retrieve through the generation process,\nresulting in the interleaving of retrieval and genera-\ntion. Formally, at step t(t\u00151), the retrieval query\nqtis formulated based on both the user input xand\npreviously generated output y<t= [y0;:::;yt\u00001]:\nqt=qry(x;y<t);\nwhere qry(\u0001)is the query formulation function. At\nthe start of the generation ( t= 1), the previous\ngeneration is empty ( y<1=;), and the user input\nis used as the initial query ( q1=x). Given the re-\ntrieved documents Dqt, LMs continually generate\nthe answer until the next retrieval is triggered or\nreaches the end:\nyt=LM([Dqt;x;y<t]);\nwhere ytrepresents the generated tokens at the\ncurrent step t, and the input to LMs is the concate-\nnation of the retrieved documents Dqt, the user\ninput x, and the previous generation y<t. At each\nstep, we discard previously retrieved documents\n[t0<tDqt0and only use the retrieved documents\nfrom the current step to condition the next gener-\nation to prevent reaching the input length limit of\nLMs.\n3 FLARE: Forward-Looking Active\nREtrieval Augmented Generation\nOur intuition is that (1) LMs should only retrieve\ninformation when they do not have the necessary", "start_char_idx": 3164, "end_char_idx": 4324, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e1caf5fa-9447-440c-b5ce-0b98853dc981": {"__data__": {"id_": "e1caf5fa-9447-440c-b5ce-0b98853dc981", "embedding": null, "metadata": {"page_label": "4", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "87559ecc-656a-4dc5-92c0-148f8822b7a6", "node_type": null, "metadata": {"page_label": "4", "file_name": "2305.06983.pdf"}, "hash": "7fce9723b4b566e3056c25595642bdaf5b8f64933ee18b5b4c2774fddb50be8e"}, "3": {"node_id": "eb87dc4d-65df-44ee-85ba-ddf448529c95", "node_type": null, "metadata": {"page_label": "4", "file_name": "2305.06983.pdf"}, "hash": "f3242af34cf741b00c17edffe3a66dda102195eed5633945a8157e56bb84435b"}}, "hash": "95aeaa6ad98d2d899f746c4036a262fd20cd6a2a9c828cb331bee77469efc764", "text": "knowledge to avoid unnecessary or inappropriate\nretrieval, and (2) the retrieval queries should re-\n\ufb02ect the intents of future generations. Therefore,\nWe propose two forward-looking active retrieval\naugmented generation (FLARE) methods to im-\nplement the active retrieval augmented generation\nframework. Inspired by Toolformer (Schick et al.,\n2023), the \ufb01rst method prompts the LM to generate\nretrieval queries when necessary while generating\nthe answer using retrieval-encouraging instructions,\ndenoted as FLARE instruct . The second method di-\nrectly uses the LM\u2019s generation as search queries,\ndenoted as FLARE direct, which iteratively gener-\nates the next sentence to gain insight into the future\ntopic, and if uncertain tokens are present, retrieves\nrelevant documents to regenerate the next sentence.\n3.1 FLARE with Retrieval Instructions\nA straightforward way of expressing information\nneeds for retrieval is to generate \u201c[Search(query)]\u201d\nwhen additional information is needed (Schick\net al., 2023), e.g., \u201cThe colors on the \ufb02ag of\nGhana have the following meanings. Red is for\n[Search(Ghana \ufb02ag red meaning)] the blood of mar-\ntyrs, ...\u201d When working with GPT-3.5 models that\noffer only API access, we elicit such behavior by\nfew-shot prompting (Brown et al., 2020).\nSpeci\ufb01cally, for a downstream task, we place\nthe search-related instruction and exemplars at the\nbeginning as skill 1, followed by the instruction and\nexemplars of the downstream task as skill 2. Given\na test case, we ask LMs to combine skills 1 and 2 to\ngenerate search queries while performing the task.\nThe structure of the prompt is shown in Prompt 3.1,\nand further details can be found in Prompt C.1.\nPrompt 3.1: retrieval instructions\nSkill 1. An instruction to guide LMs to generate search\nqueries.\nSeveral search-related exemplars.\nSkill 2. An instruction to guide LMs to perform a\nspeci\ufb01c downstream task (e.g., multihop QA).\nSeveral task-related exemplars.\nAn instruction to guide LMs to combine skills 1\nand 2 for the test case.\nThe input of the test case.\nAs shown in Figure 2, when the LM generates\n\u201c[Search(query)]\u201d (shown in gray italic ), we stop\nthe generation and use the query terms to retrieve\nrelevant documents, which are prepended before\nthe user input to aid future generation until the next\nsearch query is generated or reaches the end.\nSearch results:   !![1]: \u2026[2]: \u2026Joe Biden attended\nSearch results:   !\"![1]: \u2026[2]: \u2026Search results:   !\"\"[1]: \u2026[2]: \u2026[Search(Joe Biden University)][Search(Joe Biden degree)]the University of Pennsylvania, where he earneda law degree.Generate a summary about Joe Biden.Input$&$&#%$&%%%GenerationRetriever$%$%%Figure 2: An illustration of forward-looking active re-\ntrieval augmented generation with retrieval instructions\n(FLARE instruct ). It iteratively generates search queries\n(shown in gray italic ) to retrieve relevant information\nto aid future generations.\nWe found that LMs can effectively combine the\ntwo skills and generate meaningful search queries\nwhile performing the task. However, there are\ntwo issues: (1) LMs tend to generate fewer search\nqueries than necessary. (2) Generating excessive\nsearch queries can disrupt answer generation and\nadversely affect performance. We address these\nissues using two methods respectively. First, we\nincrease the logit of the token \u201c[\u201d by 2.0 to improve\nthe chances of LMs generating \u201c[Search(query)]\u201d.\nSecond, whenever LMs generate a search query in\nFigure 2), we use it to", "start_char_idx": 0, "end_char_idx": 3462, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "eb87dc4d-65df-44ee-85ba-ddf448529c95": {"__data__": {"id_": "eb87dc4d-65df-44ee-85ba-ddf448529c95", "embedding": null, "metadata": {"page_label": "4", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "87559ecc-656a-4dc5-92c0-148f8822b7a6", "node_type": null, "metadata": {"page_label": "4", "file_name": "2305.06983.pdf"}, "hash": "7fce9723b4b566e3056c25595642bdaf5b8f64933ee18b5b4c2774fddb50be8e"}, "2": {"node_id": "e1caf5fa-9447-440c-b5ce-0b98853dc981", "node_type": null, "metadata": {"page_label": "4", "file_name": "2305.06983.pdf"}, "hash": "95aeaa6ad98d2d899f746c4036a262fd20cd6a2a9c828cb331bee77469efc764"}}, "hash": "f3242af34cf741b00c17edffe3a66dda102195eed5633945a8157e56bb84435b", "text": "whenever LMs generate a search query in\nFigure 2), we use it to retrieve relevant information,\npromptly remove it from the generation, and gen-\nerate the next few tokens while forbidding \u201c[\u201d by\nadding a large negative value to the logit of \u201c[\u201d.\n3.2 Direct FLARE\nSince we cannot \ufb01ne-tune black-box LMs, we\nfound queries generated by FLARE instruct through\nretrieval instructions might not be reliable. There-\nfore, we propose a more direct way of forward-\nlooking active retrieval that uses the next sentence\nto decide when and what to retrieve.\n3.2.1 Con\ufb01dence-based Active Retrieval\nAs shown in Figure 1, at step t, we \ufb01rst generate a\ntemporary next sentence ^st=LM([x;y<t])with-\nout conditioning on retrieved documents. Then we\ndecide whether to trigger retrieval and formulate\nqueries based on ^st. If the LM is con\ufb01dent about ^st,\nwe accept it without retrieving additional informa-\ntion; if not, we use ^stto formulate search queries\nqtto retrieve relevant documents, and then regen-", "start_char_idx": 3399, "end_char_idx": 4387, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9e018c06-d969-4f39-b6bd-798d297e6f40": {"__data__": {"id_": "9e018c06-d969-4f39-b6bd-798d297e6f40", "embedding": null, "metadata": {"page_label": "5", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "06586e8a-8a6a-4e03-ae7c-2d8df7de7c1e", "node_type": null, "metadata": {"page_label": "5", "file_name": "2305.06983.pdf"}, "hash": "878d4533539c619c78f01aa544383fbc6e663f8891a612aa20885b3836d364e5"}, "3": {"node_id": "6ddcb469-5551-4223-8cdd-b61e862b8319", "node_type": null, "metadata": {"page_label": "5", "file_name": "2305.06983.pdf"}, "hash": "e3bb5db6d0a34712676afd4916f21b828bf225e9973f822be7e44b078e28d7fd"}}, "hash": "ce577d915d55becbb03b95057fd21d8c1e117ab39863c1bbba3ca43fdbc1972b", "text": "erate the next sentence st. The reason we utilize\nsentences as the basis of our iteration is due to their\nsigni\ufb01cance as semantic units that are neither too\nshort nor too lengthy like phrases and paragraphs.\nHowever, it is worth noting that our approach can\nalso be employed using phrases, paragraphs, or\n\ufb01xed-size windows as the basis.\nSince LMs tend to be well-calibrated that low\nprobability/con\ufb01dence often indicates a lack of\nknowledge (Kadavath et al., 2022; Jiang et al.,\n2021), we actively trigger retrieval if any token\nof^sthas a probability lower than a threshold\n\u00122[0;1].\u0012= 0 means that retrieval is never\ntriggered, while \u0012= 1triggers retrieval for every\nsentence.\nyt=(\n^st if all tokens of ^sthave probs\u0015\u0012\nst=LM([Dqt;x;y<t]) otherwise\nwhere the query qtis formulated based on ^st.\n3.2.2 Con\ufb01dence-based Query Formulation\nOne way to perform retrieval is to directly use the\nnext sentence ^stas the query qt. This shares a sim-\nilar spirit with existing methods that use generated\nhypothetical titles or paragraphs (Gao et al., 2022;\nSun et al., 2022) from LMs instead of the origi-\nnal input question as the retrieval query (Gao et al.,\n2022; Mao et al., 2021). We transfer and generalize\nsuch techniques to long-form generation scenarios\nwhere active information access is essential.\nEmpirically, we found retrieving with the next\nsentence achieves signi\ufb01cantly better results than\nwith the previous context, as to be shown later in\nsubsection 6.2. However, it has a risk of perpetuat-\ning errors contained in it. For example, if the LM\nproduces the sentence \u201cJoe Biden attended the Uni-\nversity of Pennsylvania\u201d instead of the correct fact\nthat he attended the University of Delaware, using\nthis erroneous sentence as a query could prompt the\nretriever to retrieve irrelevant information, which\ncould potentially mislead future generations. We\npropose two simple methods to overcome this issue\nas illustrated in Figure 3.\nMasked sentences as implicit queries. The \ufb01rst\nmethod masks out low-con\ufb01dence tokens in ^stwith\nprobabilities below a threshold \f2[0;1], where a\nhigher\fresults in more aggressive masking. This\nremoves potential distractions from the sentence to\nimprove retrieval accuracy.\nJoe Biden attended the University of Pennsylvania, where he earned a law degree.Ask a question to which the answer is \u201cthe University of Pennsylvania\u201dAsk a question to which the answer is \u201ca law degree\u201dWhat university did Joe Biden attend?What degree did Joe Biden earn?implicit query by maskingexplicit query by question generationJoe Biden attended  , where he earned  .LM such as ChatGPTFigure 3: Implicit the explicit query formulation. To-\nkens with low probabilities are marked with underlines .\nGenerated questions as explicit queries. An-\nother method is to generate explicit questions that\ntarget the low-con\ufb01dent span in ^st. For example, if\nthe LM is uncertain about \u201cthe University of Penn-\nsylvania\u201d, a question like \u201cWhich university did Joe\nBiden attend?\u201d can help retrieve relevant informa-\ntion. Self-ask (Press et al., 2022) achieved this by\nmanually inserting follow-up questions into down-\nstream task exemplars as shown later in Prompt 4.1,\nwhich requires task-speci\ufb01c annotation efforts. In-\nstead, we developed a universal approach that gen-\nerates questions for low-con\ufb01dence spans without\nadditional annotation. Speci\ufb01cally, We \ufb01rst", "start_char_idx": 0, "end_char_idx": 3367, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6ddcb469-5551-4223-8cdd-b61e862b8319": {"__data__": {"id_": "6ddcb469-5551-4223-8cdd-b61e862b8319", "embedding": null, "metadata": {"page_label": "5", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "06586e8a-8a6a-4e03-ae7c-2d8df7de7c1e", "node_type": null, "metadata": {"page_label": "5", "file_name": "2305.06983.pdf"}, "hash": "878d4533539c619c78f01aa544383fbc6e663f8891a612aa20885b3836d364e5"}, "2": {"node_id": "9e018c06-d969-4f39-b6bd-798d297e6f40", "node_type": null, "metadata": {"page_label": "5", "file_name": "2305.06983.pdf"}, "hash": "ce577d915d55becbb03b95057fd21d8c1e117ab39863c1bbba3ca43fdbc1972b"}}, "hash": "e3bb5db6d0a34712676afd4916f21b828bf225e9973f822be7e44b078e28d7fd", "text": "annotation. Speci\ufb01cally, We \ufb01rst extract\nall spans from ^stwith probabilities below \f. For\neach extracted span z, we prompt gpt-3.5-turbo\nto generate a question qt;zthat can be answered\nwith the span, using the following prompt:\nPrompt 3.2: zero-shot question generation\nUser input x.\nGenerated output so far y\u0014t.\nGiven the above passage, ask a question to which\nthe answer is the term/entity/phrase \u201c z\u201d.\nWe retrieve using each generated question and\ninterleave the returned documents into a single\nranking list to aid future generations. In summary,\nqueries qtare formulated based on ^stas follows:\nqt=(\n; if all tokens of ^sthave probs\u0015\u0012\nmask(^st)or qgen (^st) otherwise\n3.3 Implementation Details\nWe validate our method using one of the most ad-\nvanced GPT-3.5 LMs text-davinci-003 by itera-\ntively querying their API.2\n2https://api.openai.com/v1/completions in April\n2023.", "start_char_idx": 3335, "end_char_idx": 4212, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1746a0f2-5303-4a83-be16-181a530a3aaa": {"__data__": {"id_": "1746a0f2-5303-4a83-be16-181a530a3aaa", "embedding": null, "metadata": {"page_label": "6", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7fc5ec28-604b-4ff6-afcd-f7b8669324cf", "node_type": null, "metadata": {"page_label": "6", "file_name": "2305.06983.pdf"}, "hash": "346130275e6e6a094576a4225623adfb479cb2db7d610cffa15d3cd66e634738"}, "3": {"node_id": "1711ac87-e7fc-4dc0-a3af-3ee7036a5773", "node_type": null, "metadata": {"page_label": "6", "file_name": "2305.06983.pdf"}, "hash": "6c287ab920fc0f36fbd1f9bde6907d480f795c7b028c9fe19b12cdfc2e79f249"}}, "hash": "1c2dd49795eca639166f6d668b906fea01d59cbbb210674fcaaa4418ee8da12b", "text": "The initial query. FLARE starts with the user\ninput xas the initial query to retrieve documents\nto generate the \ufb01rst sentence ^s1=LM([Dx;x])\nto bootstrap the iterative generation process. For\nthe following steps, the temporary forward-looking\nsentence is generated without retrieved documents.\nSentence tokenization. For each step t, we gen-\nerate 64 tokens which are longer than most sen-\ntences, and use NLTK sentence tokenizer3to ex-\ntract the \ufb01rst sentence and discard the rest.\nDocument corpus and retrievers. Since we fo-\ncus on the integration of retrieval and generation in\nthis paper, we use off-the-shelf retrievers that take\nqueries as inputs and return a list of relevant docu-\nments. For datasets that mainly rely on knowledge\nfrom Wikipedia, we use the Wikipedia dump from\nKarpukhin et al. (2020) where articles are divided\ninto 100-token passages as the document corpus\nand employ BM25 (Robertson and Zaragoza, 2009)\nas the retriever. For datasets that rely on knowledge\nfrom the open web, we use the Bing search engine\nas our retriever.4\nRetrieved document formatting. Multiple re-\ntrieved documents are linearized according to their\nranking and then added to the beginning of the user\ninput using the following format:\nPrompt 3.3: document formatting\nSearch results:\n[1]Document 1\n[2]Document 2\n...\nThe user input x\nEf\ufb01ciency As shown later in subsection 6.2, on\naverage retrieval is triggered for 30%\u001860% of\nsentences depending on downstream tasks. In\ncomparision, KNN-LM (Khandelwal et al., 2020)\nretrieves for every token, RETRO or IC-RALM\n(Borgeaud et al., 2022; Ram et al., 2023) retriev-\nersevery 4\u001832 tokens, and IRCoT (Trivedi et al.,\n2022) retrieves for every sentence. Compared\nto single-time retrieval, however, interleaving re-\ntrieval and generation with a naive implementation\nindeed increases overheads, which we will discuss\nin the limitation section (section 8).\n3https://www.nltk.org/api/nltk.tokenize.\nPunktSentenceTokenizer.html\n4https://www.microsoft.com/en-us/bing/apis/\nbing-web-search-api4 Multi-time Retrieval Baselines\nExisting passive multi-time retrieval-augmented\nLMs (Khandelwal et al., 2020; Ram et al., 2023;\nTrivedi et al., 2022; Press et al., 2022; Yao et al.,\n2022) can also be formulated using our framework\n(subsection 2.3). In this section, we formally in-\ntroduce three baseline categories based on when\nand what to retrieve. These baselines are not exact\nreproductions of the corresponding paper because\nmany design choices differ among previous works\nwhich makes direct comparisons impossible. We\nexcluded irrelevant designs and ensured that we\nimplemented them using the same settings, with\nthe only variation being when and what to retrieve.\nPrevious-window approaches trigger retrieval\neveryltokens, where lrepresents the window size.\nGenerated tokens from the previous window are\nused as the query:\nqt=yt\u00001(t\u00152);\nyt= [w(t\u00001)l+1;:::;w tl]:\nSome existing methods in this category are RETRO\n(Borgeaud et al., 2022), IC-RALM (Ram et al.,\n2023), which retrieve every few tokens, and KNN-\nLM (Khandelwal et al., 2020), which retrieves ev-\nery token.5\nPrevious-sentence approaches trigger retrieval\nevery sentence and use the previous sentence as", "start_char_idx": 0, "end_char_idx": 3201, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1711ac87-e7fc-4dc0-a3af-3ee7036a5773": {"__data__": {"id_": "1711ac87-e7fc-4dc0-a3af-3ee7036a5773", "embedding": null, "metadata": {"page_label": "6", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7fc5ec28-604b-4ff6-afcd-f7b8669324cf", "node_type": null, "metadata": {"page_label": "6", "file_name": "2305.06983.pdf"}, "hash": "346130275e6e6a094576a4225623adfb479cb2db7d610cffa15d3cd66e634738"}, "2": {"node_id": "1746a0f2-5303-4a83-be16-181a530a3aaa", "node_type": null, "metadata": {"page_label": "6", "file_name": "2305.06983.pdf"}, "hash": "1c2dd49795eca639166f6d668b906fea01d59cbbb210674fcaaa4418ee8da12b"}}, "hash": "6c287ab920fc0f36fbd1f9bde6907d480f795c7b028c9fe19b12cdfc2e79f249", "text": "approaches trigger retrieval\nevery sentence and use the previous sentence as the\nquery:\nqt=yt\u00001(t\u00152);\nyt=st:\nIRCoT (Trivedi et al., 2022) belongs to this cate-\ngory.\nQuestion decomposition approaches manually\nannotated task-speci\ufb01c exemplars to guide LMs\nto generate decomposed sub-questions while pro-\nducing outputs. For example, self-ask (Press et al.,\n2022), a method in this category, manually inserts\nfollow-up questions in exemplars:\n5Since KNN-LM uses the contextualized representation\ncorresponding to the current decoding position to retrieve rel-\nevant information which encodes all previous tokens. Strictly\nspeaking, qtshould be y<t.", "start_char_idx": 3125, "end_char_idx": 3771, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6b8ca492-29db-4816-bd92-42b8463a8d9d": {"__data__": {"id_": "6b8ca492-29db-4816-bd92-42b8463a8d9d", "embedding": null, "metadata": {"page_label": "7", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4eafe54c-fd90-4aa0-9076-ef9c2a0b8e7c", "node_type": null, "metadata": {"page_label": "7", "file_name": "2305.06983.pdf"}, "hash": "cf40b62adb3b555306979d4a28478e0f5f107e50e4696b2955cf60a2b7745bc2"}, "3": {"node_id": "fbb33a9b-c3cd-4b10-b323-414adbda9687", "node_type": null, "metadata": {"page_label": "7", "file_name": "2305.06983.pdf"}, "hash": "134b0d96f1e01618ae22363f1b0b52e322b3e39b7813ce7967120ff2e5a590fd"}}, "hash": "5e89231d9eb53a38d66b5b86ff544b33b2c25fa16b9c2233810090e5205ef76e", "text": "Prompt 4.1: multihop QA with self-ask\nQuestion: Who lived longer, Theodor Haecker or Harry\nVaughan Watkins?\nAre follow up questions needed here: Yes.\nFollow up: How old was Theodor Haecker when he died?\nIntermediate answer: Theodor Haecker was 65 years old\nwhen he died.\nFollow up: How old was Harry Vaughan Watkins when he\ndied?\nIntermediate answer: Harry Vaughan Watkins was 69 years\nold when he died.\nSo the \ufb01nal answer is: Harry Vaughan Watkins.\nFor the test case, retrieval is triggered dynami-\ncally whenever the model generates a sub-question\n(e.g., \u201cfollow up\u201d in self-ask).\nThe aforementioned three approaches are capa-\nble of retrieving additional information while gen-\nerating. However, they have notable drawbacks:\n(1) \ufb01xed-interval approaches use previously gener-\nated tokens as queries which might not re\ufb02ect what\nLMs intend to generate in the future. (2) Retriev-\ning information at a \ufb01xed interval can be inef\ufb01cient\nbecause it might occur at inappropriate points. (3)\nQuestion decomposition approaches require task-\nspeci\ufb01c prompt engineering, which restricts their\ngeneralizability in new tasks.\n5 Experimental Setup\nWe evaluate the effectiveness of FLARE on 4 di-\nverse knowledge-intensive tasks using few-shot in-\ncontext learning (Radford et al., 2019; Brown et al.,\n2020), as summarized in Table 6 of Appendix A.\nTo ensure fair head-to-head comparisons, we com-\npare the results of FLARE with baselines using\nthe same setting, namely, the same in-context ex-\nemplars, prompt format, retriever, and document\ncorpus. We follow previous works (Trivedi et al.,\n2022) to sub-sample at most 500 examples from\neach dataset due to the cost of running experi-\nments. The hyperparameters of FLARE are se-\nlected based on the development set and listed in\nTable 8. FLARE refers to FLARE direct if not specif-\nically stated. For previous-window approaches,\nwe follow Ram et al. (2023) to use a window size\nl= 16 in our experiments.\n5.1 Multihop QA\nDataset The goal of multihop QA is to answer\ncomplex questions through a process of informa-\ntion retrieval and reasoning (Yang et al., 2018; Ho\net al., 2020). For instance, to answer \u201cWhy did\nthe founder of Versus die?\u201d, we must \ufb01rst identify\nwho founded Versus and subsequently determinethe cause of their death. Multihop QA also uni\ufb01es\ninto long-form generation when solved with the\nstate-of-the-art CoT methods (Wei et al., 2022).\nWe use 2WikiMultihopQA (Ho et al., 2020)\nwhich contains 2-hop complex questions sourced\nfrom Wikipedia articles that require composition,\ncomparison, or inference.\nSettings We follow Wang et al. (2022) to gen-\nerate both the chain-of-thought reasoning process\nand the \ufb01nal answer. For the above case, the output\nwe aim to generate is \u201cThe founder of Versus was\nGianni Versace. Gianni Versace was shot and killed\non the steps of his Miami Beach mansion on July\n15, 1997. So the answer is shot.\u201d We use 8 exem-\nplars from Trivedi et al. (2022) listed in Prompt C.2\nfor in-context learning, BM25 as the retriever, and\nWikipedia articles as the retrieval corpus. Similar to\nthe observation in Trivedi et al. (2022), we found\nincorporating retrieval results for exemplars im-\nproves the performance, we use the input xof each\nexemplar to retrieve several documents and", "start_char_idx": 0, "end_char_idx": 3257, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "fbb33a9b-c3cd-4b10-b323-414adbda9687": {"__data__": {"id_": "fbb33a9b-c3cd-4b10-b323-414adbda9687", "embedding": null, "metadata": {"page_label": "7", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4eafe54c-fd90-4aa0-9076-ef9c2a0b8e7c", "node_type": null, "metadata": {"page_label": "7", "file_name": "2305.06983.pdf"}, "hash": "cf40b62adb3b555306979d4a28478e0f5f107e50e4696b2955cf60a2b7745bc2"}, "2": {"node_id": "6b8ca492-29db-4816-bd92-42b8463a8d9d", "node_type": null, "metadata": {"page_label": "7", "file_name": "2305.06983.pdf"}, "hash": "5e89231d9eb53a38d66b5b86ff544b33b2c25fa16b9c2233810090e5205ef76e"}}, "hash": "134b0d96f1e01618ae22363f1b0b52e322b3e39b7813ce7967120ff2e5a590fd", "text": "we use the input xof each\nexemplar to retrieve several documents and then\nadd them using the format in Prompt 3.3. We found\nincreasing the number of retrieval documents often\nincreases performance. Therefore, we use the max-\nimum number of documents that can \ufb01t within the\ninput length limit of text-davinci-003 , which is\n2 for 2WikiMultihopQA.\nEvaluation We use regular expressions to extract\nthe \ufb01nal answer (i.e., \u201cshot\u201d in the above example)\nfrom the generated output and compare it with the\nreference answer using answer-level exact match\n(EM), and token-level F 1, precision, and recall.\n5.2 Commonsense Reasoning\nDataset Commonsense reasoning requires sys-\ntems to utilize both world and commonsense knowl-\nedge to generate an answer (Talmor et al., 2019;\nGeva et al., 2021). For example, to answer \u201cWould\na pear sink in water?\u201d, we must have the common-\nsense understanding that we need to consider their\ndensity. We use StrategyQA (Geva et al., 2021) as\nthe testbed which is a collection of crowdsourced\nyes/no questions that require multi-step reasoning.\nSettings We follow Wei et al. (2022) to generate\nboth the chain-of-thought reasoning process and\nthe \ufb01nal yes/no answer, which for the above case is\n\u201cThe density of a pear is about 0.6g/cm3, which is\nless than water. Objects less dense than water \ufb02oat.\nThus, a pear would \ufb02oat. So the \ufb01nal answer is no.\u201d\nWe use 6 exemplars from Wei et al. (2022) listed", "start_char_idx": 3189, "end_char_idx": 4608, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6b82165a-ca1d-40d3-8a74-d9d81e1228c2": {"__data__": {"id_": "6b82165a-ca1d-40d3-8a74-d9d81e1228c2", "embedding": null, "metadata": {"page_label": "8", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "21697785-e327-41c2-b03a-a63076741202", "node_type": null, "metadata": {"page_label": "8", "file_name": "2305.06983.pdf"}, "hash": "c263403a73555e1c95bd3fa2a1edb65e34071d244c03a8af9fcf8a641aa1c900"}, "3": {"node_id": "a8826a7f-f45b-4dd6-99d5-15b3ef486087", "node_type": null, "metadata": {"page_label": "8", "file_name": "2305.06983.pdf"}, "hash": "d51804883e482b4d488772f5eef2a4b8ebc05110bbe3bbfeb5d2cefae7df3ab0"}}, "hash": "41358c92d9e131c71ad6a1d093744e89010a9f1d44536d1f9f917df1791bdfcc", "text": "in Prompt C.3, BM25 over the Wikipedia corpus,\nand 3 retrieved documents to run experiments.\nEvaluation We extract the yes/no answer and\nmatch it against the gold answer using exact match.\n5.3 Long-form QA\nDataset Long-form QA aims to generate compre-\nhensive answers to questions seeking complex in-\nformation (Fan et al., 2019; Stelmakh et al., 2022).\nThe following question \u201cWhere do the Philadelphia\nEagles play their home games?\u201d could be asking\nabout the city, sports complex, or stadium of their\nhome games. We use ASQA (Stelmakh et al., 2022)\nas our testbed where inputs are ambiguous ques-\ntions with multiple interpretations, and outputs are\ncomprehensive answers covering all.\nSetting To answer ambiguous questions, systems\nmust \ufb01rst identify possible interpretations and then\nprovide answers for each of them, which for the\nabove case is \u201cWe need to consider the different\npossible locations or venues that could be con-\nsidered the home \ufb01eld of the Philadelphia Eagles.\nThese include the city, the sports complex, or the\nstadium. Therefore, this question has 3 interpreta-\ntions and the answers are: (1) The city is Philadel-\nphia. (2) The sports complex is the South Philadel-\nphia Sports Complex. (3) The stadium is the Lin-\ncoln Financial Field stadium.\u201d We found that in\nmany cases, it is challenging even for humans to\nidentify which aspect of the original question is\nambiguous. Therefore, we created another setting\nwhere we provide a brief and generic hint to guide\nLMs to stay on track when generating interpreta-\ntions and corresponding answers. The hint for the\nabove case is \u201cThis question is ambiguous in terms\nof which speci\ufb01c location or venue is being referred\nto.\u201d For both the original setting (ASQA) and the\nsetting with hints (ASQA-hint), we manually anno-\ntate 8 exemplars (Prompt C.4 and C.6), use BM25\nover the Wikipedia corpus, and 3 retrieved docu-\nments to run experiments.\nEvaluation We use all metrics from Stelmakh\net al. (2022), including EM, soft match us-\ning a RoBERTa-based QA model (Disambig-F 1),\nROUGE (Lin, 2004), and an overall score combin-\ning Disambig-F 1and ROUGE (DR).\n5.4 Open-domain Summarization\nDataset The goal of open-domain summarization\nis to generate a comprehensive summary about aspeci\ufb01c topic by gathering information from the\nopen web (Giorgi et al., 2022), e.g., \u201cGenerate a\nsummary about Echo School (Oregon) including\nthe following aspects: academics, history\u201d. We\nuse WikiAsp (Hayashi et al., 2021) as our testbed\nwhich aims to generate aspect-based summaries\nabout entities from 20 domains in Wikipedia.\nSetting The original WikiAsp dataset is designed\nfor multi-document summarization and provides a\nlist of references to systems. We converted it into\nthe open-domain setting by removing the associ-\nated references and instead gathering information\nfrom the open web. For the above case, the output\nwe aim to generate is \u201c# Academics. In 2008, 91%\nof the school\u2019s seniors received their high school\ndiploma... # History. The class of 2008 was the\n100th class in the school\u2019s history.\u201d where # is used\nto indicate aspects. We manually annotate 4 exem-\nplars (Prompt C.8), and use the Bing search engine\nto retrieve 5 documents from the open web.6\nEvaluation We compare system outputs with the\ngold summary using ROUGE, named entity-based\nF1, and UniEval (Zhong et al., 2022) which", "start_char_idx": 0, "end_char_idx": 3356, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a8826a7f-f45b-4dd6-99d5-15b3ef486087": {"__data__": {"id_": "a8826a7f-f45b-4dd6-99d5-15b3ef486087", "embedding": null, "metadata": {"page_label": "8", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "21697785-e327-41c2-b03a-a63076741202", "node_type": null, "metadata": {"page_label": "8", "file_name": "2305.06983.pdf"}, "hash": "c263403a73555e1c95bd3fa2a1edb65e34071d244c03a8af9fcf8a641aa1c900"}, "2": {"node_id": "6b82165a-ca1d-40d3-8a74-d9d81e1228c2", "node_type": null, "metadata": {"page_label": "8", "file_name": "2305.06983.pdf"}, "hash": "41358c92d9e131c71ad6a1d093744e89010a9f1d44536d1f9f917df1791bdfcc"}}, "hash": "d51804883e482b4d488772f5eef2a4b8ebc05110bbe3bbfeb5d2cefae7df3ab0", "text": "and UniEval (Zhong et al., 2022) which mea-\nsures factual consistency based on prediction proba-\nbility of a \ufb01ne-tuned T5 model (Raffel et al., 2020).\n6 Experimental Results\nWe \ufb01rst report overall results across 4 tasks/datasets\nand compare the performance of FLARE with all\nthe baselines introduced in section 4. We then\nrun ablation experiments to study the ef\ufb01cacy of\nvarious design choices of our method.\n6.1 Comparison with Baselines\nOverall results. The overall performance of\nFLARE and baseline across all tasks/datasets are\nreported in Figure 4. FLARE outperforms all base-\nline on all tasks/datasets, indicating that FLARE\nis a generic method that can effectively retrieve\nadditional information throughout the generation.\nAmong various tasks and datasets, multihop QA\nshows the most signi\ufb01cant improvement. This is\nlargely due to the task\u2019s clear de\ufb01nition and speci\ufb01c\nobjective of producing the \ufb01nal answer through a\n2-hop reasoning process, which makes it easier\nfor LMs to generate on-topic output. In contrast,\nASQA and WikiAsp are less clearly de\ufb01ned and\nmore open-ended, which increases the dif\ufb01culty of\n6To avoid leaking, we exclude several Wikipedia-related\ndomains listed in Table 7 from Bing\u2019s search results.", "start_char_idx": 3318, "end_char_idx": 4547, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f470a065-f1dc-48c8-b92a-6d81bcd8bdc8": {"__data__": {"id_": "f470a065-f1dc-48c8-b92a-6d81bcd8bdc8", "embedding": null, "metadata": {"page_label": "9", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1603ca4d-306c-4cc8-a474-c53a6acaca15", "node_type": null, "metadata": {"page_label": "9", "file_name": "2305.06983.pdf"}, "hash": "62f1b02d960ae3b18280f83440630860d0bfacfbc079246225ca15d4d3704f3b"}, "3": {"node_id": "7717a054-7765-4f3b-a93d-d9fb974f63fb", "node_type": null, "metadata": {"page_label": "9", "file_name": "2305.06983.pdf"}, "hash": "221fa363b24a2a31d87c077a4e8246934d63b93f594f36584985e3904f742ae9"}}, "hash": "96a36ee65440ce891985761f69632484824f51b520bcf2d212475bcc6741eb5b", "text": "0.020.040.060.080.0\n2WikiMultihopQA StrategyQA ASQA ASQA-hint WikiAspNo ret. Single-time ret. Previous-window ret. Forward-Looking Active REtrieval augmented generation (FLARE)Figure 4: Comparision between FLARE and baselines across all tasks/datasets. We report the primary metric for\neach dataset: EM for 2WikiMultihopQA, StrategyQA, and ASQA, and UniEval for WikiAsp.\nboth generation and evaluation. The improvement\non ASQA-hint is larger than that of ASQA because\nidentifying ambiguous aspects is challenging even\nfor humans in many cases, and providing a generic\nhint helps LMs to stay on topic.\nThorough comparisons with baselines. The\nperformance of all baselines discussed in section 4\non 2WikiMultihopQA are reported in Table 1.\nFLARE outperforms all baselines by a large mar-\ngin, which con\ufb01rms that forward-looking active re-\ntrieval is highly effective. Most multi-time retrieval-\naugmented approaches outperform single-time re-\ntrieval but with different margins. The improve-\nment of retrieving using the previous sentence is\nrelatively small which we hypothesize is mainly\nbecause the previous sentence often describes en-\ntities or relations that differ from those in the next\nsentence in 2WikiMultihopQA. While the previous-\nwindow approach might use the \ufb01rst half of a sen-\ntence as queries to retrieve information potentially\nhelpful for generating the second half. Among all\nbaselines, the question decomposition approach\n(Press et al., 2022) achieves the best performance.\nThis is not surprising since the in-context exem-\nplars manually annotated with decomposed sub-\nquestions (Prompt 4.1) guide LMs to generate suit-\nable sub-questions that align with the topic/intent\nof future generations. FLARE outperforms this\nbaseline, indicating that manual exemplar anno-\ntation is not necessary for effective future-aware\nretrieval. The gap between FLARE instruct and ques-\ntion decomposition is large, indicating that teaching\nLMs to generate search queries using task-generic\nretrieval instructions and exemplars is challenging.\nWe report all metrics for the other datasets in Ta-\nble 2. Again, FLARE outperforms baselines with\nrespect to all metrics. Retrieval using the previ-\nous window underperforms single-time retrieval on\n%steps/sentences with retrieval0.020.040.060.080.0\n0.0 25.0 50.0 75.0 100.02WikiMultihopQA StrategyQAFigure 5: Performance (EM) of FLARE with respect\nto the percentage of steps/sentences with retrieval on\n2WikiMultihopQA and StrategyQA.\nASQA, which we hypothesize is because the previ-\nous window does not accurately re\ufb02ect the user\u2019s\nfuture intent. Since we focus on evaluating the\nfactuality of the generation, metrics with an empha-\nsis on factual content (such as EM, Disambig-F 1,\nUniEval) are more reliable than metrics computed\nover all tokens (ROUGE-L).\n6.2 Ablation Study\nWe study the ef\ufb01cacy of various design choices\nthrough ablation experiments.\nImportance of forward-looking retrieval. We\n\ufb01rst validate our hypothesis that forward-looking\nretrieval is indeed more powerful than past-context-\nbased retrieval. We run ablation experiments on\n2WikiMultihopQA and ASQA-hint datasets com-\nparing retrieval using the previous versus the next\nsentence, by ensuring both methods are identical\nexcept for the query used for retrieval. Speci\ufb01-\ncally, both methods retrieve every sentence and\ndirectly use the complete", "start_char_idx": 0, "end_char_idx": 3367, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7717a054-7765-4f3b-a93d-d9fb974f63fb": {"__data__": {"id_": "7717a054-7765-4f3b-a93d-d9fb974f63fb", "embedding": null, "metadata": {"page_label": "9", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1603ca4d-306c-4cc8-a474-c53a6acaca15", "node_type": null, "metadata": {"page_label": "9", "file_name": "2305.06983.pdf"}, "hash": "62f1b02d960ae3b18280f83440630860d0bfacfbc079246225ca15d4d3704f3b"}, "2": {"node_id": "f470a065-f1dc-48c8-b92a-6d81bcd8bdc8", "node_type": null, "metadata": {"page_label": "9", "file_name": "2305.06983.pdf"}, "hash": "96a36ee65440ce891985761f69632484824f51b520bcf2d212475bcc6741eb5b"}}, "hash": "221fa363b24a2a31d87c077a4e8246934d63b93f594f36584985e3904f742ae9", "text": "both methods retrieve every sentence and\ndirectly use the complete sentence (without mask-\ning or question generation) for retrieval. As shown\nin Table 3, on both datasets, using the next sentence\nto retrieve is clearly better than using the previous\nsentence, con\ufb01rming our hypothesis.", "start_char_idx": 3301, "end_char_idx": 3587, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b0d91fca-a784-46df-98b6-7d524c01fc4b": {"__data__": {"id_": "b0d91fca-a784-46df-98b6-7d524c01fc4b", "embedding": null, "metadata": {"page_label": "10", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ea0c0693-a8e8-41fe-b791-f41b93751783", "node_type": null, "metadata": {"page_label": "10", "file_name": "2305.06983.pdf"}, "hash": "082032475ec74f16744b3a8b829b5bbc20ef76850ab5fb33c0cc5c6154a05645"}, "3": {"node_id": "a6b2a505-336d-410c-93a5-ac1a38b9545b", "node_type": null, "metadata": {"page_label": "10", "file_name": "2305.06983.pdf"}, "hash": "e35f507595dd118c186939cf78cecde8828497a1474a13d0c79d406c39607f91"}}, "hash": "bf48ae9979f39afca0d1bcc31e70edde96b4e6b1c304d368806295e71d0f6bc9", "text": "Methods EM F 1 Prec. Rec.\nNo retrieval 28.2 36.8 36.5 38.6\nSingle-time retrieval 39.4 48.8 48.6 51.5\nMulti-time retrieval\nPrevious-window (Borgeaud et al., 2022; Ram et al., 2023)\u000343.2 52.3 51.7 54.5\nPrevious-sentence (Trivedi et al., 2022)\u000339.0 49.2 48.9 51.8\nQuestion decomposition (Press et al., 2022; Yao et al., 2022)\u000347.8 56.4 56.1 58.6\nFLARE instruct (ours) 42.4 49.8 49.1 52.5\nFLARE direct (ours) 51.0 59.7 59.1 62.6\nTable 1: Comparisons between FLARE and baselines on 2WikiMultihopQA.\u0003Reimplemented for fair compar-\nisons.\nDatasets StrategyQA ASQA ASQA-hint WikiAsp\nMetrics EM EM D-F 1R-L DR EM D-F 1R-L DR UniEval E-F 1R-L\nNo retrieval 72.9 33.8 24.2 33.3 28.4 40.1 32.5 36.4 34.4 47.1 14.1 26.4\nSingle-time retrieval 68.6 40.0 27.1 34.0 30.4 43.2 34.8 37.4 36.0 52.4 17.4 26.9\nMulti-time retrieval\nPrevious-window 71.2 39.9 27.0 34.3 30.4 43.7 35.7 37.5 36.6 51.8 18.1 27.3\nFLARE (ours) 77.3 41.3 28.2 34.3 31.1 46.2 36.7 37.7 37.2 53.4 18.9 27.6\nTable 2: Comparison between FLARE and baselines on StrategyQA, ASQA, ASQA-hint, WikiAsp wrt. corre-\nsponding metrics. D-F 1is Disambig-F 1, R-L is ROUGE-L, and E-F 1is named entity-based F 1.\n2WikiMultihopQA ASQA-hint\nEM F 1Prec. Rec. EM D-F 1R-L DR\nPrevious 39.0 49.2 48.9 51.8 42.5 34.1 36.9 35.5\nNext 48.8 57.6 57.1 60.5 45.9 35.7 37.5 36.6\nTable 3: A head-to-head comparison between using the\nprevious sentence and the next sentence for retrieval.\nImportance of active retrieval. Next, we inves-\ntigate the relationship between performance and\nthe active retrieval threshold \u0012. To alter our method\nfrom not retrieving anything to retrieving every sen-\ntence, we adjusted the con\ufb01dence threshold \u0012used\nto determine when to trigger retrieval from 0 to\n1. We calculate the percentage of steps/sentences\nwhere retrieval is triggered for every threshold and\ndisplay the performance based on the percentage\nof retrieval. As shown in Figure 5, on 2WikiMul-\ntihopQA, the performance plateaus when the re-\ntrieval percentage exceeds 60%, indicating that re-\ntrieval when LMs are con\ufb01dent is not necessary.\nOn StrategyQA, the performance drops with a re-\ntrieval percentage above 50%, suggesting that the\nuse of high-con\ufb01dence sentences for retrieval can\nintroduce noise and impede the original genera-\f EM F 1 Prec. Rec.\n0.0 0.488 0.576 0.571 0.605\n0.2 0.498 0.588 0.582 0.616\n0.4 0.510 0.597 0.591 0.627\n0.6 0.506 0.593 0.586 0.622\nTable 4: Performance of FLARE with respect to the\nmasking threshold \fon 2WikiMultihopQA.\nASQA-hint WikiAsp\nEM D-F 1R-L DR", "start_char_idx": 0, "end_char_idx": 2507, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a6b2a505-336d-410c-93a5-ac1a38b9545b": {"__data__": {"id_": "a6b2a505-336d-410c-93a5-ac1a38b9545b", "embedding": null, "metadata": {"page_label": "10", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ea0c0693-a8e8-41fe-b791-f41b93751783", "node_type": null, "metadata": {"page_label": "10", "file_name": "2305.06983.pdf"}, "hash": "082032475ec74f16744b3a8b829b5bbc20ef76850ab5fb33c0cc5c6154a05645"}, "2": {"node_id": "b0d91fca-a784-46df-98b6-7d524c01fc4b", "node_type": null, "metadata": {"page_label": "10", "file_name": "2305.06983.pdf"}, "hash": "bf48ae9979f39afca0d1bcc31e70edde96b4e6b1c304d368806295e71d0f6bc9"}}, "hash": "e35f507595dd118c186939cf78cecde8828497a1474a13d0c79d406c39607f91", "text": "WikiAsp\nEM D-F 1R-L DR UniEval E-F 1R-L\nImplicit 45.7 36.9 37.7 37.3 53.4 18.8 27.7\nExplicit 46.2 36.7 37.7 37.2 53.4 18.9 27.6\nTable 5: A comparison between implicit and explicit\nquery formulation methods in FLARE.\ntion process. Depending on the tasks/datasets, we\nfound on average triggering retrieval for 40%-60%\nof sentences usually leads to a good performance.\nEffectiveness of different query formulation\nmethods Last, we study implicit query forma-\ntion by masking and explicit query formulation\nthrough question generation. In Table 4, we com-\npare the performance of FLARE with different", "start_char_idx": 2485, "end_char_idx": 3081, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "59fc7953-5d16-49bd-876f-bc12fb632852": {"__data__": {"id_": "59fc7953-5d16-49bd-876f-bc12fb632852", "embedding": null, "metadata": {"page_label": "11", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "76cd22bb-5e22-4f4b-a2b8-6a3aedfc1251", "node_type": null, "metadata": {"page_label": "11", "file_name": "2305.06983.pdf"}, "hash": "977aa1a535f0c54a3e5faaf4f3519400a1c31b4dd56dafbd95ad3ef7aa22b432"}, "3": {"node_id": "b0195244-309c-4d0b-bb6e-7123ce608d59", "node_type": null, "metadata": {"page_label": "11", "file_name": "2305.06983.pdf"}, "hash": "b764e7492e39234b4457f2bfee33c1c7f5f1a74763a30db289ef1e136f6aa885"}}, "hash": "2e673707fdd2783f04f07fc804d80a04966624c5f3930f7be0e6d56ef68f1ccf", "text": "masking thresholds \f. Retrieving directly with the\ncomplete sentence ( \f= 0) is worse than masking\ntokens with low probabilities, con\ufb01rming our hy-\npothesis that low-con\ufb01dence erroneous tokens can\ndistract retrievers. We also compare implicit and\nexplicit query formulation methods in Table 5. Per-\nformances of both methods are similar, indicating\nthat both methods can effectively re\ufb02ect informa-\ntion needs.\n7 Conclusion\nTo aid long-form generation with retrieval aug-\nmentation, we propose an active retrieval aug-\nmented generation framework that decides when\nand what to retrieve during generation. We imple-\nment this framework with forward-looking active\nretrieval that iteratively uses the upcoming sentence\nto retrieve relevant information if it contains low-\ncon\ufb01dence tokens and regenerates the next sen-\ntence. Experimental results on 4 tasks/datasets\ndemonstrate the effectiveness of our methods. Fu-\nture directions include better alternatives for active\nretrieval and developing LM architectures for ef\ufb01-\ncient active retrieval augmentation.\n8 Limitation\nWe also performed preliminary experiments on\nWizard of Wikipedia (Dinan et al., 2019) and ELI5\n(Fan et al., 2019), and found that FLARE did not\nprovide signi\ufb01cant gains. Wizard of Wikipedia is\na knowledge-intensive dialogue generation dataset\nwhere the output is relatively short ( \u001820 tokens\non average) so retrieving multiple disparate pieces\nof information might not be necessary. ELI5 (Fan\net al., 2019) is a long-form QA dataset requiring\nin-depth answers to open-ended questions. Due to\nissues mentioned in Krishna et al. (2021) such as\ndif\ufb01culties of grounding generation in retrieval and\nevaluation, both single-time retrieval and FLARE\ndid not provide signi\ufb01cant gains over not using\nretrieval. From an engineering perspective, inter-\nleaving generation with retrieval with a naive im-\nplementation increases both overheads and the cost\nof generation. The LM needs to be activated mul-\ntiple times (once for each retrieval) and a caching-\nfree implementation will also require recomputing\nthe previous activation each time after a retrieval.\nThis issue can be potentially alleviated with spe-\ncial architectural designs that encode the retrieved\ndocumentsDqtand the input/generation ( x/y<t)\nindependently.Acknowledgements\nThis work was supported in part by a grant\nfrom the Singapore Defence Science and Technol-\nogy Agency and the IBM PhD Fellowship. We\nthank Chunting Zhou, Amanda Bertsch, Uri Alon,\nHiroaki Hayashi, Harsh Trivedi, Patrick Lewis,\nKaixin Ma, Shuyan Zhou, and Songwei Ge for\ntheir insightful discussions and help with the exper-\niments.\nReferences\nSebastian Borgeaud, Arthur Mensch, Jordan Hoff-\nmann, Trevor Cai, Eliza Rutherford, Katie Millican,\nGeorge van den Driessche, Jean-Baptiste Lespiau,\nBogdan Damoc, Aidan Clark, Diego de Las Casas,\nAurelia Guy, Jacob Menick, Roman Ring, Tom Hen-\nnigan, Saffron Huang, Loren Maggiore, Chris Jones,\nAlbin Cassirer, Andy Brock, Michela Paganini, Ge-\noffrey Irving, Oriol Vinyals, Simon Osindero, Karen\nSimonyan, Jack W. Rae, Erich Elsen, and Laurent\nSifre. 2022. Improving language models by retriev-\ning from trillions of tokens. In International Confer-\nence on Machine Learning, ICML 2022, 17-23 July\n2022, Baltimore, Maryland, USA , volume 162 of\nProceedings of Machine Learning Research ,", "start_char_idx": 0, "end_char_idx": 3334, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b0195244-309c-4d0b-bb6e-7123ce608d59": {"__data__": {"id_": "b0195244-309c-4d0b-bb6e-7123ce608d59", "embedding": null, "metadata": {"page_label": "11", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "76cd22bb-5e22-4f4b-a2b8-6a3aedfc1251", "node_type": null, "metadata": {"page_label": "11", "file_name": "2305.06983.pdf"}, "hash": "977aa1a535f0c54a3e5faaf4f3519400a1c31b4dd56dafbd95ad3ef7aa22b432"}, "2": {"node_id": "59fc7953-5d16-49bd-876f-bc12fb632852", "node_type": null, "metadata": {"page_label": "11", "file_name": "2305.06983.pdf"}, "hash": "2e673707fdd2783f04f07fc804d80a04966624c5f3930f7be0e6d56ef68f1ccf"}}, "hash": "b764e7492e39234b4457f2bfee33c1c7f5f1a74763a30db289ef1e136f6aa885", "text": "Baltimore, Maryland, USA , volume 162 of\nProceedings of Machine Learning Research , pages\n2206\u20132240. PMLR.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen,\nEric Sigler, Mateusz Litwin, Scott Gray, Benjamin\nChess, Jack Clark, Christopher Berner, Sam Mc-\nCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. 2020. Language models are few-shot learn-\ners. In Advances in Neural Information Processing\nSystems 33: Annual Conference on Neural Informa-\ntion Processing Systems 2020, NeurIPS 2020, De-\ncember 6-12, 2020, virtual .\nDanqi Chen, Adam Fisch, Jason Weston, and Antoine\nBordes. 2017. Reading wikipedia to answer open-\ndomain questions. In Proceedings of the 55th An-\nnual Meeting of the Association for Computational\nLinguistics, ACL 2017, Vancouver, Canada, July 30 -\nAugust 4, Volume 1: Long Papers , pages 1870\u20131879.\nAssociation for Computational Linguistics.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng", "start_char_idx": 3251, "end_char_idx": 4820, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9a705649-f52b-4351-8ba8-9c2ba0e30be1": {"__data__": {"id_": "9a705649-f52b-4351-8ba8-9c2ba0e30be1", "embedding": null, "metadata": {"page_label": "12", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a82967b8-0af1-420b-b31a-69e5926056af", "node_type": null, "metadata": {"page_label": "12", "file_name": "2305.06983.pdf"}, "hash": "f3d92f3e0d1896d4bf78383e38cca0e9ed1f65221684674f5c0a73b6effb08e3"}, "3": {"node_id": "a34b6df1-536f-4cac-9ccd-621177d91adf", "node_type": null, "metadata": {"page_label": "12", "file_name": "2305.06983.pdf"}, "hash": "27b73832ec209737c8f3c8d49e9076f46bab5f1f588d36cfeac174e881f51167"}}, "hash": "fad5a2cf73bd6922172b237f73837d610098442397e71a92475b34937e01c69f", "text": "Yin, Toju Duke, Anselm Levskaya, Sanjay Ghe-\nmawat, Sunipa Dev, Henryk Michalewski, Xavier\nGarcia, Vedant Misra, Kevin Robinson, Liam Fe-\ndus, Denny Zhou, Daphne Ippolito, David Luan,\nHyeontaek Lim, Barret Zoph, Alexander Spiridonov,\nRyan Sepassi, David Dohan, Shivani Agrawal, Mark\nOmernick, Andrew M. Dai, Thanumalayan Sankara-\nnarayana Pillai, Marie Pellat, Aitor Lewkowycz,\nErica Moreira, Rewon Child, Oleksandr Polozov,\nKatherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-\nnan Saeta, Mark Diaz, Orhan Firat, Michele Catasta,\nJason Wei, Kathy Meier-Hellstern, Douglas Eck,\nJeff Dean, Slav Petrov, and Noah Fiedel. 2022.\nPalm: Scaling language modeling with pathways.\nCoRR , abs/2204.02311.\nNachshon Cohen, Oren Kalinsky, Yftah Ziser, and\nAlessandro Moschitti. 2021. Wikisum: Coher-\nent summarization dataset for ef\ufb01cient human-\nevaluation. In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguis-\ntics and the 11th International Joint Conference on\nNatural Language Processing, ACL/IJCNLP 2021,\n(Volume 2: Short Papers), Virtual Event, August 1-\n6, 2021 , pages 212\u2013219. Association for Computa-\ntional Linguistics.\nEmily Dinan, Stephen Roller, Kurt Shuster, Angela\nFan, Michael Auli, and Jason Weston. 2019. Wizard\nof wikipedia: Knowledge-powered conversational\nagents. In 7th International Conference on Learn-\ning Representations, ICLR 2019, New Orleans, LA,\nUSA, May 6-9, 2019 . OpenReview.net.\nAngela Fan, Yacine Jernite, Ethan Perez, David Grang-\nier, Jason Weston, and Michael Auli. 2019. ELI5:\nlong form question answering. In Proceedings of\nthe 57th Conference of the Association for Compu-\ntational Linguistics, ACL 2019, Florence, Italy, July\n28- August 2, 2019, Volume 1: Long Papers , pages\n3558\u20133567. Association for Computational Linguis-\ntics.\nLuyu Gao, Xueguang Ma, Jimmy Lin, and Jamie\nCallan. 2022. Precise zero-shot dense retrieval with-\nout relevance labels. CoRR , abs/2212.10496.\nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot,\nDan Roth, and Jonathan Berant. 2021. Did aristotle\nuse a laptop? a question answering benchmark with\nimplicit reasoning strategies. Transactions of the As-\nsociation for Computational Linguistics , 9:346\u2013361.\nJohn M. Giorgi, Luca Soldaini, Bo Wang, Gary D.\nBader, Kyle Lo, Lucy Lu Wang, and Arman Co-\nhan. 2022. Exploring the challenges of open\ndomain multi-document summarization. CoRR ,\nabs/2212.10526.\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-\npat, and Ming-Wei Chang. 2020. REALM: retrieval-\naugmented language model pre-training. CoRR ,\nabs/2002.08909.\nHiroaki Hayashi, Prashant Budania, Peng Wang, Chris\nAckerson, Raj Neervannan, and Graham Neubig.2021. Wikiasp: A dataset for multi-domain aspect-\nbased summarization. Trans. Assoc. Comput. Lin-\nguistics , 9:211\u2013225.\nDan Hendrycks, Collin", "start_char_idx": 0, "end_char_idx": 2790, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a34b6df1-536f-4cac-9ccd-621177d91adf": {"__data__": {"id_": "a34b6df1-536f-4cac-9ccd-621177d91adf", "embedding": null, "metadata": {"page_label": "12", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a82967b8-0af1-420b-b31a-69e5926056af", "node_type": null, "metadata": {"page_label": "12", "file_name": "2305.06983.pdf"}, "hash": "f3d92f3e0d1896d4bf78383e38cca0e9ed1f65221684674f5c0a73b6effb08e3"}, "2": {"node_id": "9a705649-f52b-4351-8ba8-9c2ba0e30be1", "node_type": null, "metadata": {"page_label": "12", "file_name": "2305.06983.pdf"}, "hash": "fad5a2cf73bd6922172b237f73837d610098442397e71a92475b34937e01c69f"}}, "hash": "27b73832ec209737c8f3c8d49e9076f46bab5f1f588d36cfeac174e881f51167", "text": ", 9:211\u2013225.\nDan Hendrycks, Collin Burns, Steven Basart, Andy\nZou, Mantas Mazeika, Dawn Song, and Jacob Stein-\nhardt. 2020. Measuring massive multitask language\nunderstanding. CoRR , abs/2009.03300.\nXanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara,\nand Akiko Aizawa. 2020. Constructing A multi-hop\nQA dataset for comprehensive evaluation of reason-\ning steps. In Proceedings of the 28th International\nConference on Computational Linguistics, COLING\n2020, Barcelona, Spain (Online), December 8-13,\n2020 , pages 6609\u20136625. International Committee on\nComputational Linguistics.\nGautier Izacard and Edouard Grave. 2021. Leveraging\npassage retrieval with generative models for open\ndomain question answering. In Proceedings of the\n16th Conference of the European Chapter of the As-\nsociation for Computational Linguistics: Main Vol-\nume, EACL 2021, Online, April 19 - 23, 2021 , pages\n874\u2013880. Association for Computational Linguis-\ntics.\nGautier Izacard, Patrick S. H. Lewis, Maria Lomeli,\nLucas Hosseini, Fabio Petroni, Timo Schick, Jane\nDwivedi-Yu, Armand Joulin, Sebastian Riedel, and\nEdouard Grave. 2022. Few-shot learning with\nretrieval augmented language models. CoRR ,\nabs/2208.03299.\nZhengbao Jiang, Jun Araki, Haibo Ding, and Graham\nNeubig. 2021. How can we know When language\nmodels know? on the calibration of language mod-\nels for question answering. Trans. Assoc. Comput.\nLinguistics , 9:962\u2013977.\nZhengbao Jiang, Luyu Gao, Jun Araki, Haibo Ding,\nZhiruo Wang, Jamie Callan, and Graham Neubig.\n2022. Retrieval as attention: End-to-end learning\nof retrieval and reading within a single transformer.\nCoRR , abs/2212.02027.\nZhengbao Jiang, Frank F. Xu, Jun Araki, and Graham\nNeubig. 2020. How can we know what language\nmodels know. Trans. Assoc. Comput. Linguistics ,\n8:423\u2013438.\nMandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke\nZettlemoyer. 2017. Triviaqa: A large scale distantly\nsupervised challenge dataset for reading comprehen-\nsion. In Proceedings of the 55th Annual Meeting of\nthe Association for Computational Linguistics, ACL\n2017, Vancouver, Canada, July 30 - August 4, Vol-\nume 1: Long Papers , pages 1601\u20131611. Association\nfor Computational Linguistics.\nSaurav Kadavath, Tom Conerly, Amanda Askell, Tom\nHenighan, Dawn Drain, Ethan Perez, Nicholas\nSchiefer, Zac Hat\ufb01eld-Dodds, Nova DasSarma, Eli\nTran-Johnson, Scott Johnston, Sheer El Showk,\nAndy Jones, Nelson Elhage, Tristan Hume, Anna", "start_char_idx": 2756, "end_char_idx": 5158, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "487e4822-1caa-4da9-bdf7-78e0ca55bc58": {"__data__": {"id_": "487e4822-1caa-4da9-bdf7-78e0ca55bc58", "embedding": null, "metadata": {"page_label": "13", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d65469f0-18ad-4463-b3cd-efc7458b2ae2", "node_type": null, "metadata": {"page_label": "13", "file_name": "2305.06983.pdf"}, "hash": "260c3b24ba2d6f0e9cd4e4cafdd8547eb58133efa72e48eda4d0349b5c5c95cb"}, "3": {"node_id": "5a305d34-b402-47cb-ba8c-e22e3be75b4f", "node_type": null, "metadata": {"page_label": "13", "file_name": "2305.06983.pdf"}, "hash": "626b2d9f3901675e3d446dc438393fb6debbf7df684e3ec4cc3698507d2fe5d2"}}, "hash": "cfd364d41beed96b53d65cdcfca9596a4c0555c6683316dd1dbabb35ee2fcec6", "text": "Chen, Yuntao Bai, Sam Bowman, Stanislav Fort,\nDeep Ganguli, Danny Hernandez, Josh Jacobson,\nJackson Kernion, Shauna Kravec, Liane Lovitt, Ka-\nmal Ndousse, Catherine Olsson, Sam Ringer, Dario\nAmodei, Tom Brown, Jack Clark, Nicholas Joseph,\nBen Mann, Sam McCandlish, Chris Olah, and Jared\nKaplan. 2022. Language models (mostly) know\nwhat they know. CoRR , abs/2207.05221.\nVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\nS. H. Lewis, Ledell Wu, Sergey Edunov, Danqi\nChen, and Wen-tau Yih. 2020. Dense passage re-\ntrieval for open-domain question answering. In Pro-\nceedings of the 2020 Conference on Empirical Meth-\nods in Natural Language Processing, EMNLP 2020,\nOnline, November 16-20, 2020 , pages 6769\u20136781.\nAssociation for Computational Linguistics.\nUrvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke\nZettlemoyer, and Mike Lewis. 2020. Generaliza-\ntion through memorization: Nearest neighbor lan-\nguage models. In 8th International Conference on\nLearning Representations, ICLR 2020, Addis Ababa,\nEthiopia, April 26-30, 2020 . OpenReview.net.\nOmar Khattab, Keshav Santhanam, Xiang Lisa Li,\nDavid Hall, Percy Liang, Christopher Potts, and\nMatei Zaharia. 2022. Demonstrate-search-predict:\nComposing retrieval and language models for\nknowledge-intensive NLP. CoRR , abs/2212.14024.\nTushar Khot, Harsh Trivedi, Matthew Finlayson, Yao\nFu, Kyle Richardson, Peter Clark, and Ashish Sab-\nharwal. 2022. Decomposed prompting: A mod-\nular approach for solving complex tasks. CoRR ,\nabs/2210.02406.\nKalpesh Krishna, Aurko Roy, and Mohit Iyyer. 2021.\nHurdles to progress in long-form question answer-\ning. In North American Association for Computa-\ntional Linguistics .\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\n\ufb01eld, Michael Collins, Ankur P. Parikh, Chris Al-\nberti, Danielle Epstein, Illia Polosukhin, Jacob De-\nvlin, Kenton Lee, Kristina Toutanova, Llion Jones,\nMatthew Kelcey, Ming-Wei Chang, Andrew M. Dai,\nJakob Uszkoreit, Quoc Le, and Slav Petrov. 2019.\nNatural questions: a benchmark for question answer-\ning research. Trans. Assoc. Comput. Linguistics ,\n7:452\u2013466.\nHaejun Lee, Akhil Kedia, Jongwon Lee, Ashwin Paran-\njape, Christopher D. Manning, and Kyoung-Gu Woo.\n2021. You only need one model for open-domain\nquestion answering. CoRR , abs/2112.07381.\nPatrick S. H. Lewis, Ethan Perez, Aleksandra Pik-\ntus, Fabio Petroni, Vladimir Karpukhin, Naman\nGoyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih,\nTim Rockt\u00e4schel, Sebastian Riedel, and Douwe\nKiela. 2020. Retrieval-augmented generation for\nknowledge-intensive NLP tasks. In Advances in\nNeural Information Processing Systems 33: AnnualConference on Neural Information Processing Sys-\ntems 2020, NeurIPS 2020, December 6-12, 2020,\nvirtual .\nChin-Yew Lin. 2004. ROUGE: A package for auto-\nmatic evaluation of summaries. In Text Summariza-\ntion Branches Out , pages 74\u201381, Barcelona, Spain.\nAssociation for", "start_char_idx": 0, "end_char_idx": 2865, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5a305d34-b402-47cb-ba8c-e22e3be75b4f": {"__data__": {"id_": "5a305d34-b402-47cb-ba8c-e22e3be75b4f", "embedding": null, "metadata": {"page_label": "13", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d65469f0-18ad-4463-b3cd-efc7458b2ae2", "node_type": null, "metadata": {"page_label": "13", "file_name": "2305.06983.pdf"}, "hash": "260c3b24ba2d6f0e9cd4e4cafdd8547eb58133efa72e48eda4d0349b5c5c95cb"}, "2": {"node_id": "487e4822-1caa-4da9-bdf7-78e0ca55bc58", "node_type": null, "metadata": {"page_label": "13", "file_name": "2305.06983.pdf"}, "hash": "cfd364d41beed96b53d65cdcfca9596a4c0555c6683316dd1dbabb35ee2fcec6"}}, "hash": "626b2d9f3901675e3d446dc438393fb6debbf7df684e3ec4cc3698507d2fe5d2", "text": "Branches Out , pages 74\u201381, Barcelona, Spain.\nAssociation for Computational Linguistics.\nYuning Mao, Pengcheng He, Xiaodong Liu, Yelong\nShen, Jianfeng Gao, Jiawei Han, and Weizhu Chen.\n2021. Generation-augmented retrieval for open-\ndomain question answering. In Proceedings of the\n59th Annual Meeting of the Association for Compu-\ntational Linguistics and the 11th International Joint\nConference on Natural Language Processing, ACL/I-\nJCNLP 2021, (Volume 1: Long Papers), Virtual\nEvent, August 1-6, 2021 , pages 4089\u20134100. Associ-\nation for Computational Linguistics.\nJoshua Maynez, Shashi Narayan, Bernd Bohnet, and\nRyan McDonald. 2020. On faithfulness and factu-\nality in abstractive summarization. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics , pages 1906\u20131919, On-\nline. Association for Computational Linguistics.\nOpenAI. 2023. GPT-4 technical report. CoRR ,\nabs/2303.08774.\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-\nroll L. Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, John\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,\nMaddie Simens, Amanda Askell, Peter Welinder,\nPaul F. Christiano, Jan Leike, and Ryan Lowe.\n2022. Training language models to follow instruc-\ntions with human feedback. CoRR , abs/2203.02155.\nFabio Petroni, Tim Rockt\u00e4schel, Sebastian Riedel,\nPatrick S. H. Lewis, Anton Bakhtin, Yuxiang Wu,\nand Alexander H. Miller. 2019. Language mod-\nels as knowledge bases? In Proceedings of the\n2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing,\nEMNLP-IJCNLP 2019, Hong Kong, China, Novem-\nber 3-7, 2019 , pages 2463\u20132473. Association for\nComputational Linguistics.\nO\ufb01r Press, Muru Zhang, Sewon Min, Ludwig Schmidt,\nNoah A Smith, and Mike Lewis. 2022. Measuring\nand narrowing the compositionality gap in language\nmodels. arXiv preprint arXiv:2210.03350 .\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nBlog , 1(8).\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2020. Exploring the limits\nof transfer learning with a uni\ufb01ed text-to-text trans-\nformer. J. Mach. Learn. Res. , 21:140:1\u2013140:67.", "start_char_idx": 2804, "end_char_idx": 5185, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "efbf24c8-a732-4a96-a908-67eb778b1e3b": {"__data__": {"id_": "efbf24c8-a732-4a96-a908-67eb778b1e3b", "embedding": null, "metadata": {"page_label": "14", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f99ee3d8-306f-46f5-8127-9c130e41f98b", "node_type": null, "metadata": {"page_label": "14", "file_name": "2305.06983.pdf"}, "hash": "6b966144dd8a602b059a58fe790c965e887b57cd96618e8d5e545f8daa28fbd1"}, "3": {"node_id": "c4066044-45e0-485b-a89e-a1c4eea953e5", "node_type": null, "metadata": {"page_label": "14", "file_name": "2305.06983.pdf"}, "hash": "a14800ac906772bdb09716cff8454653d9a584bf18d832817c4c786b51549e12"}}, "hash": "d273a6f1b5816f281f759d537dfd94e621138c31d554258b8d7bb74546ce5898", "text": "Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay,\nAmnon Shashua, Kevin Leyton-Brown, and Yoav\nShoham. 2023. In-context retrieval-augmented lan-\nguage models. arXiv preprint arXiv:2302.00083 .\nAdam Roberts, Colin Raffel, and Noam Shazeer. 2020.\nHow much knowledge can you pack into the pa-\nrameters of a language model? In Proceedings of\nthe 2020 Conference on Empirical Methods in Nat-\nural Language Processing, EMNLP 2020, Online,\nNovember 16-20, 2020 , pages 5418\u20135426. Associ-\nation for Computational Linguistics.\nStephen E. Robertson and Hugo Zaragoza. 2009. The\nprobabilistic relevance framework: BM25 and be-\nyond. Found. Trends Inf. Retr. , 3(4):333\u2013389.\nDevendra Singh Sachan, Siva Reddy, William L.\nHamilton, Chris Dyer, and Dani Yogatama. 2021.\nEnd-to-end training of multi-document reader and\nretriever for open-domain question answering. In\nAdvances in Neural Information Processing Systems\n34: Annual Conference on Neural Information Pro-\ncessing Systems 2021, NeurIPS 2021, December 6-\n14, 2021, virtual , pages 25968\u201325981.\nTimo Schick, Jane Dwivedi-Yu, Roberto Dess\u00ec,\nRoberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\nNicola Cancedda, and Thomas Scialom. 2023. Tool-\nformer: Language models can teach themselves to\nuse tools.\nWeijia Shi, Sewon Min, Michihiro Yasunaga, Min-\njoon Seo, Rich James, Mike Lewis, Luke Zettle-\nmoyer, and Wen-tau Yih. 2023. REPLUG: retrieval-\naugmented black-box language models. CoRR ,\nabs/2301.12652.\nIvan Stelmakh, Yi Luan, Bhuwan Dhingra, and Ming-\nWei Chang. 2022. ASQA: factoid questions meet\nlong-form answers. In Proceedings of the 2022 Con-\nference on Empirical Methods in Natural Language\nProcessing, EMNLP 2022, Abu Dhabi, United Arab\nEmirates, December 7-11, 2022 , pages 8273\u20138288.\nAssociation for Computational Linguistics.\nZhiqing Sun, Xuezhi Wang, Yi Tay, Yiming Yang, and\nDenny Zhou. 2022. Recitation-augmented language\nmodels. CoRR , abs/2210.01296.\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and\nJonathan Berant. 2019. Commonsenseqa: A ques-\ntion answering challenge targeting commonsense\nknowledge. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, NAACL-HLT 2019, Minneapolis, MN,\nUSA, June 2-7, 2019, Volume 1 (Long and Short Pa-\npers) , pages 4149\u20134158. Association for Computa-\ntional Linguistics.\nJames Thorne, Andreas Vlachos, Christos\nChristodoulopoulos, and Arpit Mittal. 2018.\nFEVER: a large-scale dataset for fact extraction\nand veri\ufb01cation. In Proceedings of the 2018Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, NAACL-HLT 2018, New\nOrleans, Louisiana, USA, June 1-6, 2018, Volume\n1 (Long Papers) , pages 809\u2013819. Association for\nComputational Linguistics.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix,\nBaptiste Rozi\u00e8re, Naman", "start_char_idx": 0, "end_char_idx": 2933, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c4066044-45e0-485b-a89e-a1c4eea953e5": {"__data__": {"id_": "c4066044-45e0-485b-a89e-a1c4eea953e5", "embedding": null, "metadata": {"page_label": "14", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f99ee3d8-306f-46f5-8127-9c130e41f98b", "node_type": null, "metadata": {"page_label": "14", "file_name": "2305.06983.pdf"}, "hash": "6b966144dd8a602b059a58fe790c965e887b57cd96618e8d5e545f8daa28fbd1"}, "2": {"node_id": "efbf24c8-a732-4a96-a908-67eb778b1e3b", "node_type": null, "metadata": {"page_label": "14", "file_name": "2305.06983.pdf"}, "hash": "d273a6f1b5816f281f759d537dfd94e621138c31d554258b8d7bb74546ce5898"}}, "hash": "a14800ac906772bdb09716cff8454653d9a584bf18d832817c4c786b51549e12", "text": "Timoth\u00e9e Lacroix,\nBaptiste Rozi\u00e8re, Naman Goyal, Eric Hambro,\nFaisal Azhar, Aur\u00e9lien Rodriguez, Armand Joulin,\nEdouard Grave, and Guillaume Lample. 2023.\nLlama: Open and ef\ufb01cient foundation language mod-\nels.CoRR , abs/2302.13971.\nHarsh Trivedi, Niranjan Balasubramanian, Tushar\nKhot, and Ashish Sabharwal. 2022. Interleav-\ning retrieval with chain-of-thought reasoning for\nknowledge-intensive multi-step questions. CoRR ,\nabs/2212.10509.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V .\nLe, Ed H. Chi, and Denny Zhou. 2022. Self-\nconsistency improves chain of thought reasoning in\nlanguage models. CoRR , abs/2203.11171.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed H. Chi, Quoc Le, and Denny Zhou. 2022.\nChain of thought prompting elicits reasoning in large\nlanguage models. CoRR , abs/2201.11903.\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-\ngio, William W. Cohen, Ruslan Salakhutdinov, and\nChristopher D. Manning. 2018. Hotpotqa: A dataset\nfor diverse, explainable multi-hop question answer-\ning. In Proceedings of the 2018 Conference on\nEmpirical Methods in Natural Language Process-\ning, Brussels, Belgium, October 31 - November 4,\n2018 , pages 2369\u20132380. Association for Computa-\ntional Linguistics.\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak\nShafran, Karthik Narasimhan, and Yuan Cao. 2022.\nReact: Synergizing reasoning and acting in language\nmodels. CoRR , abs/2210.03629.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher De-\nwan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mi-\nhaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel\nSimig, Punit Singh Koura, Anjali Sridhar, Tianlu\nWang, and Luke Zettlemoyer. 2022. Opt: Open\npre-trained transformer language models. ArXiv ,\nabs/2205.01068.\nMing Zhong, Yang Liu, Da Yin, Yuning Mao, Yizhu\nJiao, Pengfei Liu, Chenguang Zhu, Heng Ji, and\nJiawei Han. 2022. Towards a uni\ufb01ed multi-\ndimensional evaluator for text generation. In Pro-\nceedings of the 2022 Conference on Empirical Meth-\nods in Natural Language Processing, EMNLP 2022,\nAbu Dhabi, United Arab Emirates, December 7-11,\n2022 , pages 2023\u20132038. Association for Computa-\ntional Linguistics.", "start_char_idx": 2892, "end_char_idx": 5064, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b4261d8f-28da-401b-a2ee-d06496b2b169": {"__data__": {"id_": "b4261d8f-28da-401b-a2ee-d06496b2b169", "embedding": null, "metadata": {"page_label": "15", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d2ce21d7-2cd9-4304-8a1f-56c51e5ae0ec", "node_type": null, "metadata": {"page_label": "15", "file_name": "2305.06983.pdf"}, "hash": "6870675d016b187470f9153c8e717e3897f11c35aec4b73b5b301d3bbecca98b"}}, "hash": "6870675d016b187470f9153c8e717e3897f11c35aec4b73b5b301d3bbecca98b", "text": "Chunting Zhou, Graham Neubig, Jiatao Gu, Mona\nDiab, Francisco Guzm\u00e1n, Luke Zettlemoyer, and\nMarjan Ghazvininejad. 2021. Detecting halluci-\nnated content in conditional neural sequence gener-\nation. In Findings of the Association for Computa-\ntional Linguistics: ACL-IJCNLP 2021 , pages 1393\u2013\n1404, Online. Association for Computational Lin-\nguistics.A Datasets and Settings\nDatasets and experimental settings are summarized\nin Table 6. Wikipedia-related domains excluded\nfrom Bing\u2019s search results are listed in Table 7.\nB Hyperparameters\nHyperparameters of FLARE on different datasets\nare listed in Table 8.\nC Prompts and Few-shot exemplars\nPrompts and exemplars of different tasks/datasets\nare shown in Prompt C.1, C.2, C.3, C.4, C.6, and\nC.8, respectively.", "start_char_idx": 0, "end_char_idx": 759, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7565716e-580d-4be1-aacb-d68019f1ee23": {"__data__": {"id_": "7565716e-580d-4be1-aacb-d68019f1ee23", "embedding": null, "metadata": {"page_label": "16", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "79dccfb0-80b7-442d-b0a0-f6389d3e3b26", "node_type": null, "metadata": {"page_label": "16", "file_name": "2305.06983.pdf"}, "hash": "0860023c67f922b5cb75949c1c77d1dfee9a278a8b88e45698f2528b7a27c65f"}}, "hash": "0860023c67f922b5cb75949c1c77d1dfee9a278a8b88e45698f2528b7a27c65f", "text": "Settings 2WikiMultihopQA StrategyQA ASQA WikiAsp\n(Ho et al., 2020) (Geva et al., 2021) (Stelmakh et al., 2022) (Hayashi et al., 2021)\nDataset statistics\nTask multihop QA commonsense QA long-form QA open-domain summarization\n#Examples 500 229 500 500\nEvaluation settings\nMetrics EM, F 1, Prec., Rec. EM EM, Disambig-F 1, ROUGE, DR UniEval, entity-F 1, ROUGE\nRetrieval settings\nCorpus Wikipedia Wikipedia Wikipedia open web\nRetriever BM25 BM25 BM25 Bing\nTop-k 2 3 3 5\nPrompt format\n#Exemplars 8 6 8 4\nRet. for exemplars 3 7 7 7\nTable 6: Statistics and experimental settings of different tasks/datasets.\nwikipedia.org\nwikiwand.com\nwiki2.org\nwikimedia.org\nTable 7: Wikipedia-related domains excluded from Bing\u2019s search results.\nDataset \u0012 \f Query formulation Combine single- & multi-time retrieval\n2WikiMultihopQA 0.8 0.4 implicit 7\nStrategyQA 0.4 0.4 implicit 7\nASQA & ASQA-hint 0.8 0.4 explicit 3\nWikiAsp 0.8 0.4 explicit 3\nTable 8: Statistics and experimental settings of different tasks/datasets.", "start_char_idx": 0, "end_char_idx": 995, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d24f858d-bec1-4ba5-bb52-b13f7bf13bcc": {"__data__": {"id_": "d24f858d-bec1-4ba5-bb52-b13f7bf13bcc", "embedding": null, "metadata": {"page_label": "17", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3b40464a-3690-4528-96d9-71883a115406", "node_type": null, "metadata": {"page_label": "17", "file_name": "2305.06983.pdf"}, "hash": "4899390925f6c0c544f0b94cf5013fc4b66b37d333c4370a5e29a86ee299a974"}, "3": {"node_id": "3fbaf8ce-f2f4-46b6-9743-754e40985125", "node_type": null, "metadata": {"page_label": "17", "file_name": "2305.06983.pdf"}, "hash": "8df3e30f0ae9a5aca835eb37a5f1dcf77ebde3f384ce20e2b1eebe9b269b1894"}}, "hash": "dc58ef62a2fc2a3c0dd597da8979db5813876f3f5ed2697321c2e9d7bfece076", "text": "Prompt C.1: retrieval instructions for 2WikiMultihopQA\nSkill 1. Use the Search API to look up relevant information by writing \u201c[Search(term)]\u201d where \u201cterm\u201d is the search term you\nwant to look up. For example:\nQuestion: But what are the risks during production of nanomaterials?\nAnswer (with Search): [Search(nanomaterial production risks)] Some nanomaterials may give rise to various kinds of lung\ndamage.\nQuestion: The colors on the \ufb02ag of Ghana have the following meanings.\nAnswer (with Search): Red is for [Search(Ghana \ufb02ag red meaning)] the blood of martyrs, green for forests, and gold for\nmineral wealth.\nQuestion: Metformin is the \ufb01rst-line drug for what?\nAnswer (with Search): [Search(Metformin \ufb01rst-line drug)] patients with type 2 diabetes and obesity.\nSkill 2. Answer questions by thinking step-by-step. First, write out the reasoning steps, then draw the conclu-\nsion. For example:\nQuestion: When did the director of \ufb01lm Hypocrite (Film) die?\nAnswer (with step-by-step): The \ufb01lm Hypocrite was directed by Miguel Morayta. Miguel Morayta died on 19 June 2013. So\nthe answer is 19 June 2013.\nQuestion: Are both Kurram Garhi and Trojkrsti located in the same country?\nAnswer (with step-by-step): Kurram Garhi is located in the country of Pakistan. Trojkrsti is located in the country of\nRepublic of Macedonia. Thus, they are not in the same country. So the answer is no.\nQuestion: Do director of \ufb01lm Coolie No. 1 (1995 Film) and director of \ufb01lm The Sensational Trial have the same\nnationality?\nAnswer (with step-by-step): Coolie No. 1 (1995 \ufb01lm) was directed by David Dhawan. The Sensational Trial was directed by\nKarl Freund. David Dhawan\u2019s nationality is India. Karl Freund\u2019s nationality is Germany. Thus, they do not have the same\nnationality. So the answer is no.\nQuestion: Who is Boraqchin (Wife Of \u00d6gedei)\u2019s father-in-law?\nAnswer (with step-by-step): Boraqchin is married to \u00d6gedei Khan. \u00d6gedei Khan\u2019s father is Genghis Khan. Thus, Boraqchin\u2019s\nfather-in-law is Genghis Khan. So the answer is Genghis Khan.\nQuestion: Who was born \ufb01rst out of Martin Hodge and Ivania Martinich?\nAnswer (with step-by-step): Martin Hodge was born on 4 February 1959. Ivania Martinich was born on 25 July 1995. Thus,\nMartin Hodge was born \ufb01rst. So the answer is Martin Hodge.\nQuestion: When did the director of \ufb01lm Laughter In Hell die?\nAnswer (with step-by-step): The \ufb01lm Laughter In Hell was directed by Edward L. Cahn. Edward L. Cahn died on August 25,\n1963. So the answer is August 25, 1963.\nQuestion: Which \ufb01lm has the director died later, The Gal Who Took the West or Twenty Plus Two?\nAnswer (with step-by-step): The \ufb01lm Twenty Plus Two was directed by Joseph M. Newman. The Gal Who Took\nthe West was directed by Frederick de Cordova. Joseph M. Newman died on January 23, 2006. Fred de Cordova\ndied on September 15, 2001. Thus, the person to die later from the two is Twenty Plus Two. So the answer is Twenty Plus Two.\nQuestion: Who is the grandchild of Krishna Shah (Nepalese Royal)?\nAnswer (with step-by-step): Krishna Shah has a child named Rudra Shah. Rudra Shah has a child named Prithvipati Shah.\nThus, Krishna Shah has a grandchild named Prithvipati Shah. So the", "start_char_idx": 0, "end_char_idx": 3167, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3fbaf8ce-f2f4-46b6-9743-754e40985125": {"__data__": {"id_": "3fbaf8ce-f2f4-46b6-9743-754e40985125", "embedding": null, "metadata": {"page_label": "17", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3b40464a-3690-4528-96d9-71883a115406", "node_type": null, "metadata": {"page_label": "17", "file_name": "2305.06983.pdf"}, "hash": "4899390925f6c0c544f0b94cf5013fc4b66b37d333c4370a5e29a86ee299a974"}, "2": {"node_id": "d24f858d-bec1-4ba5-bb52-b13f7bf13bcc", "node_type": null, "metadata": {"page_label": "17", "file_name": "2305.06983.pdf"}, "hash": "dc58ef62a2fc2a3c0dd597da8979db5813876f3f5ed2697321c2e9d7bfece076"}}, "hash": "8df3e30f0ae9a5aca835eb37a5f1dcf77ebde3f384ce20e2b1eebe9b269b1894", "text": "Krishna Shah has a grandchild named Prithvipati Shah. So the answer is Prithvipati Shah.\nNow, combine the aforementioned two skills. First, write out the reasoning steps, then draw the conclusion,\nwhere the reasoning steps should also utilize the Search API \u201c[Search(term)]\u201d whenever possible.\nQuestion: Where did Minbyauk Thihapate\u2019s wife die?\nAnswer (with step-by-step & Search):", "start_char_idx": 3107, "end_char_idx": 3488, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6547c014-35c6-41e0-beb2-1a4b0a085596": {"__data__": {"id_": "6547c014-35c6-41e0-beb2-1a4b0a085596", "embedding": null, "metadata": {"page_label": "18", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1d454cf8-bb93-49fb-bddb-9418a839d7a2", "node_type": null, "metadata": {"page_label": "18", "file_name": "2305.06983.pdf"}, "hash": "424cdef82163da654fbb2187224f3df67feebb7970074d412e8f47b7196b5143"}}, "hash": "424cdef82163da654fbb2187224f3df67feebb7970074d412e8f47b7196b5143", "text": "Prompt C.2: exemplars of 2WikiMultihopQA\nQuestion: When did the director of \ufb01lm Hypocrite (Film) die?\nAnswer: The \ufb01lm Hypocrite was directed by Miguel Morayta. Miguel Morayta died on 19 June 2013. So the answer is 19\nJune 2013.\nQuestion: Are both Kurram Garhi and Trojkrsti located in the same country?\nAnswer: Kurram Garhi is located in the country of Pakistan. Trojkrsti is located in the country of Republic of Macedonia.\nThus, they are not in the same country. So the answer is no.\nQuestion: Do director of \ufb01lm Coolie No. 1 (1995 Film) and director of \ufb01lm The Sensational Trial have the same\nnationality?\nAnswer: Coolie No. 1 (1995 \ufb01lm) was directed by David Dhawan. The Sensational Trial was directed by Karl Freund. David\nDhawan\u2019s nationality is India. Karl Freund\u2019s nationality is Germany. Thus, they do not have the same nationality. So the\nanswer is no.\nQuestion: Who is Boraqchin (Wife Of \u00d6gedei)\u2019s father-in-law?\nAnswer: Boraqchin is married to \u00d6gedei Khan. \u00d6gedei Khan\u2019s father is Genghis Khan. Thus, Boraqchin\u2019s father-in-law is\nGenghis Khan. So the answer is Genghis Khan.\nQuestion: Who was born \ufb01rst out of Martin Hodge and Ivania Martinich?\nAnswer: Martin Hodge was born on 4 February 1959. Ivania Martinich was born on 25 July 1995. Thus, Martin Hodge was\nborn \ufb01rst. So the answer is Martin Hodge.\nQuestion: When did the director of \ufb01lm Laughter In Hell die?\nAnswer: The \ufb01lm Laughter In Hell was directed by Edward L. Cahn. Edward L. Cahn died on August 25, 1963. So the\nanswer is August 25, 1963.\nQuestion: Which \ufb01lm has the director died later, The Gal Who Took the West or Twenty Plus Two?\nAnswer: The \ufb01lm Twenty Plus Two was directed by Joseph M. Newman. The Gal Who Took the West was directed by\nFrederick de Cordova. Joseph M. Newman died on January 23, 2006. Fred de Cordova died on September 15, 2001. Thus,\nthe person to die later from the two is Twenty Plus Two. So the answer is Twenty Plus Two.\nQuestion: Who is the grandchild of Krishna Shah (Nepalese Royal)?\nAnswer: Krishna Shah has a child named Rudra Shah. Rudra Shah has a child named Prithvipati Shah. Thus, Krishna Shah\nhas a grandchild named Prithvipati Shah. So the answer is Prithvipati Shah.\nQuestion: Which country the director of \ufb01lm Citizen Mavzik is from?\nAnswer:", "start_char_idx": 0, "end_char_idx": 2258, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "50c866ab-b5d5-41bb-89e2-0b273215addc": {"__data__": {"id_": "50c866ab-b5d5-41bb-89e2-0b273215addc", "embedding": null, "metadata": {"page_label": "19", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "39be01c2-7f61-4b70-b6d6-3e5c3e2b177a", "node_type": null, "metadata": {"page_label": "19", "file_name": "2305.06983.pdf"}, "hash": "085c5e6f490e6080f12e8da3f67fd3a14439b1fd552d45b6a4c0395f96ad1922"}}, "hash": "085c5e6f490e6080f12e8da3f67fd3a14439b1fd552d45b6a4c0395f96ad1922", "text": "Prompt C.3: exemplars of StrategyQA\nGenerate a yes or no answer to the following question.\nQuestion: Do hamsters provide food for any animals?\nAnswer: Hamsters are prey animals. Prey are food for predators. Thus, hamsters provide food for some animals. So the \ufb01nal\nanswer is yes.\nGenerate a yes or no answer to the following question.\nQuestion: Could Brooke Shields succeed at University of Pennsylvania?\nAnswer: Brooke Shields went to Princeton University. Princeton University is about as academically rigorous as the Uni-\nversity of Pennsylvania. Thus, Brooke Shields could also succeed at the University of Pennsylvania. So the \ufb01nal answer is yes.\nGenerate a yes or no answer to the following question.\nQuestion: Hydrogen\u2019s atomic number squared exceeds number of Spice Girls?\nAnswer: Hydrogen has an atomic number of 1. 1 squared is 1. There are 5 Spice Girls. Thus, Hydrogen\u2019s atomic number\nsquared is less than 5. So the \ufb01nal answer is no.\nGenerate a yes or no answer to the following question.\nQuestion: Is it common to see frost during some college commencements?\nAnswer: College commencement ceremonies can happen in December, May, and June. December is in the winter, so there\ncan be frost. Thus, there could be frost at some commencements. So the \ufb01nal answer is yes.\nGenerate a yes or no answer to the following question.\nQuestion: Could a llama birth twice during War in Vietnam (1945-46)?\nAnswer: The War in Vietnam was 6 months. The gestation period for a llama is 11 months, which is more than 6 months.\nThus, a llama could not give birth twice during the War in Vietnam. So the \ufb01nal answer is no.\nGenerate a yes or no answer to the following question.\nQuestion: Would a pear sink in water?\nAnswer: The density of a pear is about 0.6g/cm3, which is less than water. Objects less dense than water \ufb02oat. Thus, a pear\nwould \ufb02oat. So the \ufb01nal answer is no.\nGenerate a yes or no answer to the following question.\nQuestion: Did Spiderman \ufb01ght against Falcon in the MCU?\nAnswer:", "start_char_idx": 0, "end_char_idx": 1987, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "fb8eecb3-edd1-462e-9c2b-d3725e0ddb5a": {"__data__": {"id_": "fb8eecb3-edd1-462e-9c2b-d3725e0ddb5a", "embedding": null, "metadata": {"page_label": "20", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9ff247bb-d7c2-4131-87b6-136a0185fc9a", "node_type": null, "metadata": {"page_label": "20", "file_name": "2305.06983.pdf"}, "hash": "aa47377971eaba438fada69fc5e7adb86f577971d5cdb117e6ae06340d36033d"}, "3": {"node_id": "257ed513-2bac-45b2-9539-fd2ec9f43218", "node_type": null, "metadata": {"page_label": "20", "file_name": "2305.06983.pdf"}, "hash": "61d752178febdb8f3ec23da40bb265f6c5041082c6b9c8a9f8391e1539e946e0"}}, "hash": "a4dcfe8ec84d4a298b499eaf20933107ac4c4a510c67daef227eb707b11af252", "text": "Prompt C.4: exemplars of ASQA\nGiven an ambiguous question, \ufb01gure out its interpretations and answer them one by one.\nQuestion: Who played bonnie in gone with the wind?\nAnswer: This question is ambiguous in terms of which version or adaptation of Gone with the Wind is being referred to. In\norder to \ufb01gure out its interpretations, we need to consider different versions or adaptations of Gone with the Wind. Gone with\nthe Wind has two versions or adaptations: the 1939 \ufb01lm Gone with the Wind or the 2008 musical Gone with the Wind.\nTherefore, this question has 2 interpretations: (1) Who played Bonnie in the 1939 \ufb01lm Gone with the Wind? (2) Who played\nBonnie in the 2008 musical Gone with the Wind? The answers to all interpretations are: (1) The 1939 \ufb01lm Gone with the\nWind\u2019s character Bonnie was played by Eleanore Cammack \"Cammie\" King. (2) The 2008 musical Gone with the Wind\u2019s\ncharacter Bonnie was played by Leilah de Meza.\nGiven an ambiguous question, \ufb01gure out its interpretations and answer them one by one.\nQuestion: What is the second largest city in the usa?\nAnswer: This question is ambiguous in terms of the criteria being used to determine the second largest city in the USA.\nIn order to \ufb01gure out its interpretations, we need to consider different criteria to determine a city\u2019s size. City size can be\nmeasured by two criteria: population or area. Therefore, this question has 2 interpretations: (1) What is the second largest\ncity in the USA by population? (2) What is the second largest city in the USA by area? The answers to all interpretations are:\n(1) The second largest city in the USA by population is Los Angeles, California. (2) The second largest city in the USA by\narea is Juneau, Alaska.\nGiven an ambiguous question, \ufb01gure out its interpretations and answer them one by one.\nQuestion: When was bohemian rhapsody released as a single?\nAnswer: This question is ambiguous in terms of which country\u2019s release of the single is being referred to. In order to \ufb01gure\nout its interpretations, we need to consider different countries where Bohemian Rhapsody is released. Bohemian Rhapsody\nwas released in the United Kingdom and in the United States on different dates. Therefore, this question has 2 interpretations:\n(1) When was Bohemian Rhapsody released as a single in the United Kingdom? (2) When was Bohemian Rhapsody released\nas a single in the United States? The answers to all interpretations are: (1) Bohemian Rhapsody was released as a single in the\nUnited Kingdom on 31 October 1975. (2) Bohemian Rhapsody was released as a single in the United States on December 1975.\nGiven an ambiguous question, \ufb01gure out its interpretations and answer them one by one.\nQuestion: Where do the philadelphia eagles play their home games?\nAnswer: This question is ambiguous in terms of which speci\ufb01c location or venue is being referred to. In order to \ufb01gure out its\ninterpretations, we need to consider the different possible locations or venues that could be considered the home \ufb01eld of the\nPhiladelphia Eagles. These include the city, the sports complex, or the stadium. Therefore, this question has 3 interpretations:\n(1) What city do the Philadelphia Eagles play their home games? (2) In what sports complex do the Philadelphia Eagles play\ntheir home games? (3) What stadium do the Philadelphia Eagles play their home games? The answers to all interpretations\nare: (1) Philadelphia Eagles play their home games in the city Philadelphia. (2) Philadelphia Eagles play their home games in\nthe South Philadelphia Sports Complex. (3) Philadelphia Eagles play their home games in the Lincoln Financial Field stadium.\nGiven an ambiguous question, \ufb01gure out its interpretations and answer them one by one.\nQuestion: When did xbox one come out in australia?\nAnswer: This question is ambiguous in terms of which", "start_char_idx": 0, "end_char_idx": 3818, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "257ed513-2bac-45b2-9539-fd2ec9f43218": {"__data__": {"id_": "257ed513-2bac-45b2-9539-fd2ec9f43218", "embedding": null, "metadata": {"page_label": "20", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9ff247bb-d7c2-4131-87b6-136a0185fc9a", "node_type": null, "metadata": {"page_label": "20", "file_name": "2305.06983.pdf"}, "hash": "aa47377971eaba438fada69fc5e7adb86f577971d5cdb117e6ae06340d36033d"}, "2": {"node_id": "fb8eecb3-edd1-462e-9c2b-d3725e0ddb5a", "node_type": null, "metadata": {"page_label": "20", "file_name": "2305.06983.pdf"}, "hash": "a4dcfe8ec84d4a298b499eaf20933107ac4c4a510c67daef227eb707b11af252"}}, "hash": "61d752178febdb8f3ec23da40bb265f6c5041082c6b9c8a9f8391e1539e946e0", "text": "come out in australia?\nAnswer: This question is ambiguous in terms of which speci\ufb01c version of the Xbox One is being referred to. In order to\n\ufb01gure out its interpretations, we need to consider the different versions of the Xbox One that have been released. Xbox One\nhas two versions: the Xbox One video game console or the Xbox One X high-end model. Therefore, this question has 2\ninterpretations: (1) When did the Xbox One release in Australia? (2) When did the Xbox One X release in Australia? The\nanswers to all interpretations are: (1) The Xbox One video game console was released in Australia on November 22, 2013.\n(2) The Xbox One X video game console was released in Australia on November 7, 2017.\nGiven an ambiguous question, \ufb01gure out its interpretations and answer them one by one.\nQuestion: When does the movie summer of 84 come out?\nAnswer: This question is ambiguous in terms of which release of the movie is being referred to. In order to \ufb01gure out its\ninterpretations, we need to consider different releases of the movie Summer of \u201984. The movie Summer of \u201984 is \ufb01rst released\nat the Sundance Festival before it\u2019s released throughout the US. Therefore, this question has 2 interpretations: (1) When\ndid the movie Summer of \u201984 \ufb01rst release at the Sundance Festival? (2) When did the movie Summer of \u201984 \ufb01rst release\nthroughout the US? The answers to all interpretations are: (1) Summer of \u201984 was released at the Sundance Festival on\nJanuary 22, 2018. (2) Summer of \u201984 was released throughout the US on August 10, 2018.", "start_char_idx": 3743, "end_char_idx": 5278, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "df51b3cf-6a98-4392-8ecc-f121bc091627": {"__data__": {"id_": "df51b3cf-6a98-4392-8ecc-f121bc091627", "embedding": null, "metadata": {"page_label": "21", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e34b4270-d575-49f6-be14-28025f4ca4cf", "node_type": null, "metadata": {"page_label": "21", "file_name": "2305.06983.pdf"}, "hash": "5fe9a068ef78355a13182b65877dcbeccae0ff5ef2297af7615274cf5261027d"}}, "hash": "5fe9a068ef78355a13182b65877dcbeccae0ff5ef2297af7615274cf5261027d", "text": "Prompt C.5: exemplars of ASQA (cont.)\nGiven an ambiguous question, \ufb01gure out its interpretations and answer them one by one.\nQuestion: What was roy orbison\u2019s \ufb01rst number one hit?\nAnswer: This question is ambiguous in terms of which speci\ufb01c chart or region is being referred to. In order to \ufb01gure out its\ninterpretations, we need to consider the different charts and regions where Roy Orbison\u2019s music was popular. Roy Orbison is\npopular in both the US Hot 100 and Canada, and the UK and Ireland. Therefore, this question has 2 interpretations: (1) What\nwas Roy Orbison\u2019s \ufb01rst number one hit in the US Hot 100 and Canada? (2) What was Roy Orbison\u2019s \ufb01rst number one hit in\nthe UK and Ireland? The answers to all interpretations are: (1) Running Scared was the \ufb01rst number one hit for Roy Orbison\nin the US Hot 100 and Canada. (2) Only the Lonely (Know the Way I Feel) was the \ufb01rst number one hit for Roy Orbison in\nthe UK and Ireland.\nGiven an ambiguous question, \ufb01gure out its interpretations and answer them one by one.\nQuestion: What is the criminal\u2019s name in the breakfast club?\nAnswer: This question is ambiguous in terms of which speci\ufb01c name is being referred to - the character\u2019s name or the actor\u2019s\nname. In order to \ufb01gure out its interpretations, we need to consider both possibilities: the character\u2019s name or the actor\u2019s\nname. Therefore, this question has 2 interpretations: (1) What is the criminal\u2019s character name in The Breakfast Club? (2)\nWhat is the the name of the actor who played the criminal in The Breakfast Club? The answers to all interpretations are: (1)\nJohn Bender was the name of the criminal\u2019s character in The Breakfast Club. (2) Judd Nelson was the actor of the criminal in\nThe Breakfast Club.\nGiven an ambiguous question, \ufb01gure out its interpretations and answer them one by one.\nQuestion: How many state parks are there in virginia?\nAnswer:", "start_char_idx": 0, "end_char_idx": 1871, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6d2856e2-c2fb-4b34-b3c3-263ec767fe06": {"__data__": {"id_": "6d2856e2-c2fb-4b34-b3c3-263ec767fe06", "embedding": null, "metadata": {"page_label": "22", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fbb92196-11e5-4708-9624-f8fffae173c7", "node_type": null, "metadata": {"page_label": "22", "file_name": "2305.06983.pdf"}, "hash": "a59af4a29ee6465c355ceb9f8fa3d197cda50b885f74e2deb578646763353c20"}, "3": {"node_id": "87598038-a9b1-4891-a603-53c0dff65563", "node_type": null, "metadata": {"page_label": "22", "file_name": "2305.06983.pdf"}, "hash": "6e2760c27b3993e97e08b4be2d0c71c319526403f39f1e7f5872c0685ffb4a1e"}}, "hash": "7f67ab3fe183282bdcd0d6454b3aec5081b31e4943c16a84107232c7ae1a27e6", "text": "Prompt C.6: exemplars of ASQA-hint\nGiven an ambiguous question and a hint on which aspect of the question is ambiguous, \ufb01gure out its interpretations and\nanswer them one by one.\nQuestion: Who played bonnie in gone with the wind?\nHint: This question is ambiguous in terms of which version or adaptation of Gone with the Wind is being referred to.\nAnswer: In order to \ufb01gure out its interpretations, we need to consider different versions or adaptations of Gone with the Wind.\nGone with the Wind has two versions or adaptations: the 1939 \ufb01lm Gone with the Wind or the 2008 musical Gone with the\nWind. Therefore, this question has 2 interpretations: (1) Who played Bonnie in the 1939 \ufb01lm Gone with the Wind? (2) Who\nplayed Bonnie in the 2008 musical Gone with the Wind? The answers to all interpretations are: (1) The 1939 \ufb01lm Gone with\nthe Wind\u2019s character Bonnie was played by Eleanore Cammack \"Cammie\" King. (2) The 2008 musical Gone with the Wind\u2019s\ncharacter Bonnie was played by Leilah de Meza.\nGiven an ambiguous question and a hint on which aspect of the question is ambiguous, \ufb01gure out its interpreta-\ntions and answer them one by one.\nQuestion: What is the second largest city in the usa?\nHint: This question is ambiguous in terms of the criteria being used to determine the second largest city in the USA.\nAnswer: In order to \ufb01gure out its interpretations, we need to consider different criteria to determine a city\u2019s size. City size can\nbe measured by two criteria: population or area. Therefore, this question has 2 interpretations: (1) What is the second largest\ncity in the USA by population? (2) What is the second largest city in the USA by area? The answers to all interpretations are:\n(1) The second largest city in the USA by population is Los Angeles, California. (2) The second largest city in the USA by\narea is Juneau, Alaska.\nGiven an ambiguous question and a hint on which aspect of the question is ambiguous, \ufb01gure out its interpreta-\ntions and answer them one by one.\nQuestion: When was bohemian rhapsody released as a single?\nHint: This question is ambiguous in terms of which country\u2019s release of the single is being referred to.\nAnswer: In order to \ufb01gure out its interpretations, we need to consider different countries where Bohemian Rhapsody is\nreleased. Bohemian Rhapsody was released in the United Kingdom and in the United States on different dates. Therefore,\nthis question has 2 interpretations: (1) When was Bohemian Rhapsody released as a single in the United Kingdom? (2) When\nwas Bohemian Rhapsody released as a single in the United States? The answers to all interpretations are: (1) Bohemian\nRhapsody was released as a single in the United Kingdom on 31 October 1975. (2) Bohemian Rhapsody was released as a\nsingle in the United States on December 1975.\nGiven an ambiguous question and a hint on which aspect of the question is ambiguous, \ufb01gure out its interpreta-\ntions and answer them one by one.\nQuestion: Where do the philadelphia eagles play their home games?\nHint: This question is ambiguous in terms of which speci\ufb01c location or venue is being referred to.\nAnswer: In order to \ufb01gure out its interpretations, we need to consider the different possible locations or venues that could be\nconsidered the home \ufb01eld of the Philadelphia Eagles. These include the city, the sports complex, or the stadium. Therefore,\nthis question has 3 interpretations: (1) What city do the Philadelphia Eagles play their home games? (2) In what sports\ncomplex do the Philadelphia Eagles play their home games? (3) What stadium do the Philadelphia Eagles play their home\ngames? The answers to all interpretations are: (1) Philadelphia Eagles play their home games in the city Philadelphia. (2)\nPhiladelphia Eagles play their", "start_char_idx": 0, "end_char_idx": 3747, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "87598038-a9b1-4891-a603-53c0dff65563": {"__data__": {"id_": "87598038-a9b1-4891-a603-53c0dff65563", "embedding": null, "metadata": {"page_label": "22", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fbb92196-11e5-4708-9624-f8fffae173c7", "node_type": null, "metadata": {"page_label": "22", "file_name": "2305.06983.pdf"}, "hash": "a59af4a29ee6465c355ceb9f8fa3d197cda50b885f74e2deb578646763353c20"}, "2": {"node_id": "6d2856e2-c2fb-4b34-b3c3-263ec767fe06", "node_type": null, "metadata": {"page_label": "22", "file_name": "2305.06983.pdf"}, "hash": "7f67ab3fe183282bdcd0d6454b3aec5081b31e4943c16a84107232c7ae1a27e6"}}, "hash": "6e2760c27b3993e97e08b4be2d0c71c319526403f39f1e7f5872c0685ffb4a1e", "text": "Eagles play their home games in the city Philadelphia. (2)\nPhiladelphia Eagles play their home games in the South Philadelphia Sports Complex. (3) Philadelphia Eagles play their\nhome games in the Lincoln Financial Field stadium.\nGiven an ambiguous question and a hint on which aspect of the question is ambiguous, \ufb01gure out its interpreta-\ntions and answer them one by one.\nQuestion: When did xbox one come out in australia?\nHint: This question is ambiguous in terms of which speci\ufb01c version of the Xbox One is being referred to.\nAnswer: In order to \ufb01gure out its interpretations, we need to consider the different versions of the Xbox One that have been\nreleased. Xbox One has two versions: the Xbox One video game console or the Xbox One X high-end model. Therefore, this\nquestion has 2 interpretations: (1) When did the Xbox One release in Australia? (2) When did the Xbox One X release\nin Australia? The answers to all interpretations are: (1) The Xbox One video game console was released in Australia on\nNovember 22, 2013. (2) The Xbox One X video game console was released in Australia on November 7, 2017.\nGiven an ambiguous question and a hint on which aspect of the question is ambiguous, \ufb01gure out its interpreta-\ntions and answer them one by one.\nQuestion: When does the movie summer of 84 come out?\nHint: This question is ambiguous in terms of which release of the movie is being referred to.\nAnswer: In order to \ufb01gure out its interpretations, we need to consider different releases of the movie Summer of \u201984. The\nmovie Summer of \u201984 is \ufb01rst released at the Sundance Festival before it\u2019s released throughout the US. Therefore, this question\nhas 2 interpretations: (1) When did the movie Summer of \u201984 \ufb01rst release at the Sundance Festival? (2) When did the movie\nSummer of \u201984 \ufb01rst release throughout the US? The answers to all interpretations are: (1) Summer of \u201984 was released at the\nSundance Festival on January 22, 2018. (2) Summer of \u201984 was released throughout the US on August 10, 2018.", "start_char_idx": 3658, "end_char_idx": 5665, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5d667156-26f3-438b-9c53-9ebcede322d7": {"__data__": {"id_": "5d667156-26f3-438b-9c53-9ebcede322d7", "embedding": null, "metadata": {"page_label": "23", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f9d7a343-51ea-433b-bc71-f74e8acca8a1", "node_type": null, "metadata": {"page_label": "23", "file_name": "2305.06983.pdf"}, "hash": "0f170954cd6e72e24b0467177f684394ff4793c144e4ed867dba5eaf674a43a4"}}, "hash": "0f170954cd6e72e24b0467177f684394ff4793c144e4ed867dba5eaf674a43a4", "text": "Prompt C.7: exemplars of ASQA-hint (cont.)\nGiven an ambiguous question and a hint on which aspect of the question is ambiguous, \ufb01gure out its interpretations and\nanswer them one by one.\nQuestion: What was roy orbison\u2019s \ufb01rst number one hit?\nHint: This question is ambiguous in terms of which speci\ufb01c chart or region is being referred to.\nAnswer: In order to \ufb01gure out its interpretations, we need to consider the different charts and regions where Roy Orbison\u2019s\nmusic was popular. Roy Orbison is popular in both the US Hot 100 and Canada, and the UK and Ireland. Therefore, this\nquestion has 2 interpretations: (1) What was Roy Orbison\u2019s \ufb01rst number one hit in the US Hot 100 and Canada? (2) What\nwas Roy Orbison\u2019s \ufb01rst number one hit in the UK and Ireland? The answers to all interpretations are: (1) Running Scared\nwas the \ufb01rst number one hit for Roy Orbison in the US Hot 100 and Canada. (2) Only the Lonely (Know the Way I Feel) was\nthe \ufb01rst number one hit for Roy Orbison in the UK and Ireland.\nGiven an ambiguous question and a hint on which aspect of the question is ambiguous, \ufb01gure out its interpreta-\ntions and answer them one by one.\nQuestion: What is the criminal\u2019s name in the breakfast club?\nHint: This question is ambiguous in terms of which speci\ufb01c name is being referred to - the character\u2019s name or the actor\u2019s\nname.\nAnswer: In order to \ufb01gure out its interpretations, we need to consider both possibilities: the character\u2019s name or the actor\u2019s\nname. Therefore, this question has 2 interpretations: (1) What is the criminal\u2019s character name in The Breakfast Club? (2)\nWhat is the the name of the actor who played the criminal in The Breakfast Club? The answers to all interpretations are: (1)\nJohn Bender was the name of the criminal\u2019s character in The Breakfast Club. (2) Judd Nelson was the actor of the criminal in\nThe Breakfast Club.\nGiven an ambiguous question and a hint on which aspect of the question is ambiguous, \ufb01gure out its interpreta-\ntions and answer them one by one.\nQuestion: How many state parks are there in virginia?\nHint: This question is ambiguous in terms of the time frame or period being referred to.\nAnswer: In order to \ufb01gure out its interpretations,", "start_char_idx": 0, "end_char_idx": 2192, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "67e044ac-6f53-449c-997f-738182179214": {"__data__": {"id_": "67e044ac-6f53-449c-997f-738182179214", "embedding": null, "metadata": {"page_label": "24", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5711c4a1-b557-47c1-bc7c-0813fbc488f2", "node_type": null, "metadata": {"page_label": "24", "file_name": "2305.06983.pdf"}, "hash": "da6bc42ccd3dd49f8d57b3a2671949077a67231c026922026e9b75ff13596e75"}, "3": {"node_id": "235f97ed-81f1-4fe0-8555-869c816eb649", "node_type": null, "metadata": {"page_label": "24", "file_name": "2305.06983.pdf"}, "hash": "9834119bd2792710f205a73f28c086ffb8320c8ebd824dcc0c24aa7c78ed3ff9"}}, "hash": "16ac984bd48765ef80973e5ad2a35186bd94e6eb3a0461874a45bc7c599f8fa4", "text": "Prompt C.8: exemplars of WikiAsp\nGenerate a summary about Aslanhane Mosque including the following aspects: location, history with one aspect per line.\n# Location\nThe mosque is in the old quarter of ankara next to ankara castle. With an altitude of 947 metres (3,107 ft) it overlooks ankara\nat 39\u00b056\u201912\"N 32\u00b051\u201955\"E.\n# History\nThe mosque is one of the oldest mosques in Turkey still standing. It was built during the reign of Mesud II of the Anatolian\nSeljuks in 1290. Its architect was Ebubekir Mehmet. It was commissioned by two Ahi leaders named H\u00fcsamettin and\nHasaneddin. However, in 1330, it was repaired by another Ahi leader named \u00b8 Serafettin after whom the mosque was named.\nAfter several minor repairs the mosque was restored by the directorate general of foundations in 2010-2013 term.\nGenerate a summary about Untold Legends: The Warrior\u2019s Code including the following aspects: reception,\ngameplay, development with one aspect per line.\n# Reception\nThe game received \"mixed or average reviews\" according to video game review aggregator Metacritic.\n# Gameplay\nThe warrior\u2019s code is a hack n\u2019 slash action role-playing game, which concentrates on action-oriented combat.\n# Development\nAs a pre-order bonus, the game was shipped with a small action \ufb01gure of the Guardian class.\nGenerate a summary about Raid on St. Augustine including the following aspects: aftermath, background with\none aspect per line.\n# Aftermath\nOnce the English had gone Men\u00e9ndez and the rest of the Spanish settlers returned to \ufb01nd a smoldering ruins and very little\nleft. He soon and begged for help from the viceroy of Cuba and the settlement took a while to build itself back up. The\ndestroyed fort was replaced with the present day Castillo de San Marcos.\n# Background\nWar had already been unof\ufb01cially declared by Philip II of Spain after the Treaty of Nonsuch in which Elizabeth I had\noffered her support to the rebellious Protestant Dutch rebels. The Queen through Francis Walsingham ordered Sir Francis\nDrake to lead an expedition to attack the Spanish New World in a kind of preemptive strike. Sailing from Plymouth,\nEngland, he struck \ufb01rst at Santiago in November 1585 then across the Atlantic at the Spanish new world city of Santo\nDomingo of which was captured and ransomed on 1 January 1586 and following that successfully attacked the important\ncity of Cartagena on 19 February. Drake wanted to strike at another Spanish city on the Main before \ufb01nally visiting and\nreplenishing Sir Walter Raleigh\u2019s new colony of Roanoke Colony on the American East Coast. Then after this he hoped\nto make the Transatlantic crossing back to England. The \ufb02eet headed north, and in late April Drake put into the Spanish\nCuban mainland and his men dug wells in search of fresh water and gathered supplies to help counter an outbreak of\ndysentery after which he moved on. The \ufb02eet traveled north within sight of land on the Florida peninsula sailing past\nthe West coast. On 27 May 1586 as they approached further north a small fort was spotted on the shore, with a small\ninlet close by. This was the location of St Augustine, the most northerly town in Spain\u2019s New World Empire, and the\noldest permanent colonial settlement in North America. Drake knew of the place and was also aware of the fact that\nthe spanish under Pedro Men\u00e9ndez de Avil\u00e9s had ordered all of the French Huguenot colonists that had tried to settle\nin the area executed. Drake decided on one \ufb01nal opportunity to raid and plunder, and a chance to avenge his fellow Protestants.\nGenerate a summary about Lakewood (Livingston, Alabama) including the following aspects:", "start_char_idx": 0, "end_char_idx": 3610, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "235f97ed-81f1-4fe0-8555-869c816eb649": {"__data__": {"id_": "235f97ed-81f1-4fe0-8555-869c816eb649", "embedding": null, "metadata": {"page_label": "24", "file_name": "2305.06983.pdf"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5711c4a1-b557-47c1-bc7c-0813fbc488f2", "node_type": null, "metadata": {"page_label": "24", "file_name": "2305.06983.pdf"}, "hash": "da6bc42ccd3dd49f8d57b3a2671949077a67231c026922026e9b75ff13596e75"}, "2": {"node_id": "67e044ac-6f53-449c-997f-738182179214", "node_type": null, "metadata": {"page_label": "24", "file_name": "2305.06983.pdf"}, "hash": "16ac984bd48765ef80973e5ad2a35186bd94e6eb3a0461874a45bc7c599f8fa4"}}, "hash": "9834119bd2792710f205a73f28c086ffb8320c8ebd824dcc0c24aa7c78ed3ff9", "text": "a summary about Lakewood (Livingston, Alabama) including the following aspects: architecture, his-\ntory with one aspect per line.\n# Architecture\nThe house has a plan that is relatively rare in early Alabama architecture. The plan features a brick ground \ufb02oor that is topped\nby one-and-a-half-stories of wood-frame construction. The ground \ufb02oor originally contained domestic spaces, with the\nformal rooms on the principle \ufb02oor and bedrooms on the upper \ufb02oor. A central hallway is present on all levels. The facade is\n\ufb01ve bays wide, with central entrance doors on the ground and principle \ufb02oors. The bays are divided by two-story Doric\npilasters, with the middle third of the facade occupied by a two-tiered tetrastyle Doric portico. Two curved wrought iron\nstaircases ascend from ground level to the front center of the upper portico, leading to the formal entrance.\n# History\nLakewood was built for Joseph lake, a native of North Carolina, by Hiram W. Bardwell, a master builder. Construction\nwas completed in 1840. Located adjacent to the University of West Alabama, Julia Strudwick Tutwiler, a Lake relative,\nperiodically resided in the house from 1881 to 1910 while she served as president of the university. It was then known as\nLivingston Normal College. The house was extensively photographed by Alex Bush for the Historic American Buildings\nSurvey in November and December 1936. Lakewood has continued to be owned by descendants of the Lake family to the\ncurrent day. The house and its surviving 10 acres (4.0 ha) of grounds were listed on the Places in Peril in 2012 due to the\nimmediate threat of its acquisition by developers.\nGenerate a summary about Carlos Moedas including the following aspects: biography, early life, political career\nwith one aspect per line.", "start_char_idx": 3531, "end_char_idx": 5305, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}}, "docstore/ref_doc_info": {"4c867a15-7333-4433-8660-75a9971a48d0": {"node_ids": ["ccb4ab73-f4cf-4728-8c7e-8d31ee1688b0", "8f37f7ab-bc1f-4112-8ea3-4a3cb9ebcc08"], "metadata": {"page_label": "1", "file_name": "2210.03629.pdf"}}, "9eecf876-8edd-4976-942d-f267b8e272cd": {"node_ids": ["e79a93c4-cba1-43a2-b714-8a7881352d11", "58d4fa7c-d448-49da-a6b8-a5372bc336c6", "a4f9ec63-d393-45d7-8f25-26856a884f9a", "53791395-7c37-4fb1-81f4-35d52e297ca3"], "metadata": {"page_label": "2", "file_name": "2210.03629.pdf"}}, "39c7e2a6-7dad-4643-ad5b-631d01345809": {"node_ids": ["85923b04-5b0f-4d9d-aa26-04168ac9b8f3", "16cde075-4c30-4361-b0c0-1c2405bd7236"], "metadata": {"page_label": "3", "file_name": "2210.03629.pdf"}}, "ffec7c77-c935-4014-8123-9f14cae9e412": {"node_ids": ["422b49d4-44c0-432c-8868-0a3ae51bf76c", "9eb9889a-cd93-45e4-b8c0-5d370e6161eb"], "metadata": {"page_label": "4", "file_name": "2210.03629.pdf"}}, "9b31f9b1-8d0d-482e-948b-2873365655ee": {"node_ids": ["0c696ece-b278-4082-9bac-7a2cba011e16", "330f38e4-4d83-4f60-b74e-3e4e9a345ae8"], "metadata": {"page_label": "5", "file_name": "2210.03629.pdf"}}, "ce1e3f57-da81-43f6-b33b-19366426affd": {"node_ids": ["8fb17a11-6d73-4ab3-ad3a-28b9f1f948b7", "33d0cea3-8e84-48f1-b071-80f2fe06638b"], "metadata": {"page_label": "6", "file_name": "2210.03629.pdf"}}, "52b69969-d9a4-4493-9a79-a0fd69886a11": {"node_ids": ["24170805-97f6-460a-9dae-d806d9a8867f", "bfa94f5c-b2d3-4d2a-83da-1a501ebc6c14"], "metadata": {"page_label": "7", "file_name": "2210.03629.pdf"}}, "ec4f7de8-a525-4137-8097-a46db8ccf40b": {"node_ids": ["4c0b1d9e-a335-4225-b57b-70396c168bbc", "a4a161ae-a5a3-4db9-997a-8d5a242f4c7b"], "metadata": {"page_label": "8", "file_name": "2210.03629.pdf"}}, "1b86be2e-ba5a-4cf7-b8d7-656f737199a9": {"node_ids": ["1bde052c-9e9c-433d-a451-eabb12cb61a3", "9b9e6492-51c4-4f50-ae34-beb5a03e22cf"], "metadata": {"page_label": "9", "file_name": "2210.03629.pdf"}}, "02df2dd5-8010-47da-9e0a-8832d599e6c6": {"node_ids": ["5e5695ef-427a-4bbd-aa3f-5433f52f1d35", "df255d4d-3e3f-4ee7-8b8b-2dc3bf375e8e"], "metadata": {"page_label": "10", "file_name": "2210.03629.pdf"}}, "9244f2d2-7882-46d5-95a1-c87ddfdf246a": {"node_ids": ["82171b36-dd0f-47fe-ade1-a51a512af9dd", "9b4dad63-8b6f-4aa6-a130-53d444270946"], "metadata": {"page_label": "11", "file_name": "2210.03629.pdf"}}, "f5e77c29-a785-486d-9081-1a8cf68d1b0a": {"node_ids": ["75ed95ba-39fd-4939-9797-0f6910e64349", "63173a7c-e3e0-4293-a638-cfa868fcc985"], "metadata": {"page_label": "12", "file_name": "2210.03629.pdf"}}, "2d62d1b5-f409-4e2e-86a6-3faed4e22fdb": {"node_ids": ["99eaaee5-5cca-4b6c-b84d-cbc6bffa4424"], "metadata": {"page_label": "13", "file_name": "2210.03629.pdf"}}, "b802cc3f-ede2-4b5b-9bc7-51720a3b84b1": {"node_ids": ["89a6e40b-542c-41f4-a4d1-192b4ed73239", "7b106e53-4279-4fc1-b0f6-28189d4c0b7b", "1e7b4340-7f30-43db-88f1-5b638b793622", "eabc83f4-e161-4fc5-9588-9a73cfce6a7b"], "metadata": {"page_label": "14", "file_name": "2210.03629.pdf"}}, "e1eead87-5cc0-4e45-8604-ff161f28436b": {"node_ids": ["a6940ea4-f77e-43d4-88ba-d6f88b2f8e90", "46033e39-3299-49c0-92c3-155dd1f40bc4", "94db492c-82c1-475f-b794-d39935776411", "e32a3b9e-4ff8-408d-a65b-0294eae9a8a2"], "metadata": {"page_label": "15", "file_name": "2210.03629.pdf"}}, "1be368dc-8171-48d0-9f32-5df4b4621216": {"node_ids": ["5556c5fe-7bf4-451d-afb1-08ab0a2e5bf0"], "metadata": {"page_label": "16", "file_name": "2210.03629.pdf"}}, "9fafd1cc-5dec-484e-80de-d76f4f032286": {"node_ids": ["7ffc471a-ff29-4dc5-bc87-5414f017c679", "bb254241-ad3c-4e10-9538-f1079529729c"], "metadata": {"page_label": "17", "file_name": "2210.03629.pdf"}}, "ed35cb3c-7cc2-4ebe-b442-cc76a3597c09": {"node_ids": ["84ce8a0b-a1d9-48af-b48b-9ffde148b56d", "230db994-13d4-4703-8389-15e8977abd76"], "metadata": {"page_label": "18", "file_name": "2210.03629.pdf"}}, "96e89d07-6776-4a2b-8f25-1495a5d3d9bd": {"node_ids": ["1a7875d2-4f14-4337-b1d8-5b9f22c234a4"], "metadata": {"page_label": "19", "file_name": "2210.03629.pdf"}}, "37742a01-b463-4f05-a75f-69ffff56c3c8": {"node_ids": ["d5eaa846-da0c-4ca1-b0bc-a43ec8be473b"], "metadata": {"page_label": "20", "file_name": "2210.03629.pdf"}}, "13c5b288-b69c-4a12-98d0-2184704a8ffa": {"node_ids": ["97f94ff1-4d90-401e-950f-abd9f8964468"], "metadata": {"page_label": "21", "file_name": "2210.03629.pdf"}}, "771fd1a7-aba3-4cd8-a469-479d8e06d5b0": {"node_ids": ["cd9da190-03cb-4f21-8692-b74130ddb1d8", "baa7cd62-fa8d-44d4-becf-5e21b28227c8"], "metadata": {"page_label": "22", "file_name": "2210.03629.pdf"}}, "874bcad2-0af1-4d4d-bb73-de0a9f650877": {"node_ids": ["790d2455-bfcb-4ef0-8fe5-749e944aca72"], "metadata": {"page_label": "23", "file_name": "2210.03629.pdf"}}, "8bc292b3-b332-4641-a20a-4165264e75cd": {"node_ids": ["ee452ccc-e4e6-459f-af91-2f027131de88"], "metadata": {"page_label": "24", "file_name": "2210.03629.pdf"}}, "9e776274-16bd-4c03-be9e-06951fdd6840": {"node_ids": ["d2cc267d-0857-4b85-8424-7f72dfcc921c"], "metadata": {"page_label": "25", "file_name": "2210.03629.pdf"}}, "bf4015a4-688e-45d5-b06f-848040748b50": {"node_ids": ["3255bb20-0b87-467b-931f-867432d1b6ed"], "metadata": {"page_label": "26", "file_name": "2210.03629.pdf"}}, "d61065d3-5978-4ea2-a71a-800593e6d194": {"node_ids": ["6f9c3c9c-aa65-41a6-8770-948af122fcc7"], "metadata": {"page_label": "27", "file_name": "2210.03629.pdf"}}, "25fd9180-9e92-4751-bf45-67fa2a55fa5b": {"node_ids": ["6e02578c-a8d6-4106-8c49-680424d2b012"], "metadata": {"page_label": "28", "file_name": "2210.03629.pdf"}}, "5b031e53-fc0a-42b0-90a8-7b6af3c7f6fc": {"node_ids": ["e7e672e9-15c1-45d1-b332-c08ca00bb845", "a3e266ae-b709-4f6a-940a-6162370134b7"], "metadata": {"page_label": "29", "file_name": "2210.03629.pdf"}}, "6f3b60b2-cf8b-4e9e-bea3-8b79cbbedc44": {"node_ids": ["8f917f38-bf31-48e4-a709-f49fc3aa13df"], "metadata": {"page_label": "30", "file_name": "2210.03629.pdf"}}, "e51e61dc-4775-4092-89ba-ba106e9ea195": {"node_ids": ["d71b5356-6861-4804-b8d5-d988f6458a72", "01b85b0e-2535-4b86-a458-c9972eaa514b"], "metadata": {"page_label": "31", "file_name": "2210.03629.pdf"}}, "46abce09-9df9-40e1-8e60-79d47fb41249": {"node_ids": ["4b14341c-f212-4b7e-a6bc-dc467e506941"], "metadata": {"page_label": "32", "file_name": "2210.03629.pdf"}}, "e8b9a63a-5f7e-459f-b1e8-f2edf9bf5b13": {"node_ids": ["e88d3de8-7a69-4d76-b8ff-c7c80ac87df3"], "metadata": {"page_label": "33", "file_name": "2210.03629.pdf"}}, "6809b276-7611-49e6-bc9e-fdc5e7be0947": {"node_ids": ["66ddb73e-075c-4912-845f-bdd630210707", "ffdd2dd1-6d94-40ff-95b1-ac2e021c119a"], "metadata": {"page_label": "1", "file_name": "2305.06983.pdf"}}, "51559604-c485-4ab4-b411-fdd6b07403f0": {"node_ids": ["05477283-841c-443c-8f86-ebfa3b5c7b98", "b48194d5-d11d-4f9a-bf0f-599bbd487609"], "metadata": {"page_label": "2", "file_name": "2305.06983.pdf"}}, "81b1ed45-53ec-4d4f-964e-c8b3710c74f4": {"node_ids": ["f94e9797-7fd0-4702-9962-35075371ee67", "7a391145-e9c3-4c3c-8444-4040a3386554"], "metadata": {"page_label": "3", "file_name": "2305.06983.pdf"}}, "87559ecc-656a-4dc5-92c0-148f8822b7a6": {"node_ids": ["e1caf5fa-9447-440c-b5ce-0b98853dc981", "eb87dc4d-65df-44ee-85ba-ddf448529c95"], "metadata": {"page_label": "4", "file_name": "2305.06983.pdf"}}, "06586e8a-8a6a-4e03-ae7c-2d8df7de7c1e": {"node_ids": ["9e018c06-d969-4f39-b6bd-798d297e6f40", "6ddcb469-5551-4223-8cdd-b61e862b8319"], "metadata": {"page_label": "5", "file_name": "2305.06983.pdf"}}, "7fc5ec28-604b-4ff6-afcd-f7b8669324cf": {"node_ids": ["1746a0f2-5303-4a83-be16-181a530a3aaa", "1711ac87-e7fc-4dc0-a3af-3ee7036a5773"], "metadata": {"page_label": "6", "file_name": "2305.06983.pdf"}}, "4eafe54c-fd90-4aa0-9076-ef9c2a0b8e7c": {"node_ids": ["6b8ca492-29db-4816-bd92-42b8463a8d9d", "fbb33a9b-c3cd-4b10-b323-414adbda9687"], "metadata": {"page_label": "7", "file_name": "2305.06983.pdf"}}, "21697785-e327-41c2-b03a-a63076741202": {"node_ids": ["6b82165a-ca1d-40d3-8a74-d9d81e1228c2", "a8826a7f-f45b-4dd6-99d5-15b3ef486087"], "metadata": {"page_label": "8", "file_name": "2305.06983.pdf"}}, "1603ca4d-306c-4cc8-a474-c53a6acaca15": {"node_ids": ["f470a065-f1dc-48c8-b92a-6d81bcd8bdc8", "7717a054-7765-4f3b-a93d-d9fb974f63fb"], "metadata": {"page_label": "9", "file_name": "2305.06983.pdf"}}, "ea0c0693-a8e8-41fe-b791-f41b93751783": {"node_ids": ["b0d91fca-a784-46df-98b6-7d524c01fc4b", "a6b2a505-336d-410c-93a5-ac1a38b9545b"], "metadata": {"page_label": "10", "file_name": "2305.06983.pdf"}}, "76cd22bb-5e22-4f4b-a2b8-6a3aedfc1251": {"node_ids": ["59fc7953-5d16-49bd-876f-bc12fb632852", "b0195244-309c-4d0b-bb6e-7123ce608d59"], "metadata": {"page_label": "11", "file_name": "2305.06983.pdf"}}, "a82967b8-0af1-420b-b31a-69e5926056af": {"node_ids": ["9a705649-f52b-4351-8ba8-9c2ba0e30be1", "a34b6df1-536f-4cac-9ccd-621177d91adf"], "metadata": {"page_label": "12", "file_name": "2305.06983.pdf"}}, "d65469f0-18ad-4463-b3cd-efc7458b2ae2": {"node_ids": ["487e4822-1caa-4da9-bdf7-78e0ca55bc58", "5a305d34-b402-47cb-ba8c-e22e3be75b4f"], "metadata": {"page_label": "13", "file_name": "2305.06983.pdf"}}, "f99ee3d8-306f-46f5-8127-9c130e41f98b": {"node_ids": ["efbf24c8-a732-4a96-a908-67eb778b1e3b", "c4066044-45e0-485b-a89e-a1c4eea953e5"], "metadata": {"page_label": "14", "file_name": "2305.06983.pdf"}}, "d2ce21d7-2cd9-4304-8a1f-56c51e5ae0ec": {"node_ids": ["b4261d8f-28da-401b-a2ee-d06496b2b169"], "metadata": {"page_label": "15", "file_name": "2305.06983.pdf"}}, "79dccfb0-80b7-442d-b0a0-f6389d3e3b26": {"node_ids": ["7565716e-580d-4be1-aacb-d68019f1ee23"], "metadata": {"page_label": "16", "file_name": "2305.06983.pdf"}}, "3b40464a-3690-4528-96d9-71883a115406": {"node_ids": ["d24f858d-bec1-4ba5-bb52-b13f7bf13bcc", "3fbaf8ce-f2f4-46b6-9743-754e40985125"], "metadata": {"page_label": "17", "file_name": "2305.06983.pdf"}}, "1d454cf8-bb93-49fb-bddb-9418a839d7a2": {"node_ids": ["6547c014-35c6-41e0-beb2-1a4b0a085596"], "metadata": {"page_label": "18", "file_name": "2305.06983.pdf"}}, "39be01c2-7f61-4b70-b6d6-3e5c3e2b177a": {"node_ids": ["50c866ab-b5d5-41bb-89e2-0b273215addc"], "metadata": {"page_label": "19", "file_name": "2305.06983.pdf"}}, "9ff247bb-d7c2-4131-87b6-136a0185fc9a": {"node_ids": ["fb8eecb3-edd1-462e-9c2b-d3725e0ddb5a", "257ed513-2bac-45b2-9539-fd2ec9f43218"], "metadata": {"page_label": "20", "file_name": "2305.06983.pdf"}}, "e34b4270-d575-49f6-be14-28025f4ca4cf": {"node_ids": ["df51b3cf-6a98-4392-8ecc-f121bc091627"], "metadata": {"page_label": "21", "file_name": "2305.06983.pdf"}}, "fbb92196-11e5-4708-9624-f8fffae173c7": {"node_ids": ["6d2856e2-c2fb-4b34-b3c3-263ec767fe06", "87598038-a9b1-4891-a603-53c0dff65563"], "metadata": {"page_label": "22", "file_name": "2305.06983.pdf"}}, "f9d7a343-51ea-433b-bc71-f74e8acca8a1": {"node_ids": ["5d667156-26f3-438b-9c53-9ebcede322d7"], "metadata": {"page_label": "23", "file_name": "2305.06983.pdf"}}, "5711c4a1-b557-47c1-bc7c-0813fbc488f2": {"node_ids": ["67e044ac-6f53-449c-997f-738182179214", "235f97ed-81f1-4fe0-8555-869c816eb649"], "metadata": {"page_label": "24", "file_name": "2305.06983.pdf"}}}}